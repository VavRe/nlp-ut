{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = './datasets/preprocessed.pkl'\n",
    "dataset = pd.read_pickle(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size:  14000\n",
      "Test Data size:  1400\n",
      "Train Data size:  12600\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.sample(frac=1, random_state=4)\n",
    "train_data = dataset[:int(len(dataset)*0.9)]\n",
    "test_data = dataset[int(len(dataset)*0.9):]\n",
    "print(\"Dataset size: \", len(dataset))\n",
    "print(\"Test Data size: \", len(test_data))\n",
    "print(\"Train Data size: \", len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8756     None\n",
       "5474     None\n",
       "11242    None\n",
       "7820     None\n",
       "7909     None\n",
       "         ... \n",
       "10142    None\n",
       "8828     None\n",
       "11554    None\n",
       "11609    None\n",
       "904      None\n",
       "Name: comment, Length: 12600, dtype: object"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "vocabulary = set()\n",
    "tf = dict()\n",
    "\n",
    "\n",
    "def make_vocab(sentence):\n",
    "\n",
    "    for word in sentence:\n",
    "         vocabulary.add(word)\n",
    "\n",
    "\n",
    "train_data[\"comment\"].apply(make_vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8756     None\n",
       "5474     None\n",
       "11242    None\n",
       "7820     None\n",
       "7909     None\n",
       "         ... \n",
       "10142    None\n",
       "8828     None\n",
       "11554    None\n",
       "11609    None\n",
       "904      None\n",
       "Name: comment, Length: 12600, dtype: object"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import TfidfVectorizer from scikit-learn\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# train_data[\"comment\"] = train_data[\"comment\"].apply(lambda x: \" \".join(x))\n",
    "# vectorizer = TfidfVectorizer()\n",
    "# vec = vectorizer.fit_transform(train_data[\"comment\"])\n",
    "train_data[\"comment\"].apply(make_vocab)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the difference between the set and dict below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_tf(term,document):\n",
    "#     return document.count(term)/len(document)\n",
    "\n",
    "# train_data = train_data.sort_index()\n",
    "\n",
    "# for index,row in train_data.iterrows() :\n",
    "#     print(index)\n",
    "#     for word in vocabulary: \n",
    "#         for word in row[\"comment\"]:\n",
    "#             train_data[\"tf\"] = compute_tf(word,row[\"comment\"])\n",
    "#     percentage = 100*(index+1)/len(train_data)\n",
    "#     if percentage % 1 == 0:\n",
    "#         print(f\"Processing iteration {index+1}/{len(train_data)} ({percentage:.0f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np \n",
    "\n",
    "# def compute_tf(term, document):\n",
    "#     return document.count(term) / len(document)\n",
    "\n",
    "# # Define a function to calculate inverse document frequency (IDF) of a term in a corpus\n",
    "# def compute_idf(term, corpus):\n",
    "#     N = len(corpus)\n",
    "#     df = sum(1 for document in corpus if term in document)\n",
    "#     return np.log(N / df)\n",
    "\n",
    "# # Load the dataset\n",
    "\n",
    "# # Create a list of all unique words in the dataset\n",
    "# unique_words = list(set(word for document in train_data['comment'] for word in document))\n",
    "\n",
    "# # Calculate the TF-IDF matrix\n",
    "# tfidf_matrix = []\n",
    "\n",
    "# for i,document in enumerate(train_data['comment']):\n",
    "#     tfidf_vector = []\n",
    "#     print(i)\n",
    "#     for term in unique_words:\n",
    "#         tf = compute_tf(term, document)\n",
    "#         idf = compute_idf(term, train_data['comment'])\n",
    "#         tfidf = tf * idf\n",
    "#         tfidf_vector.append(tfidf)\n",
    "#     tfidf_matrix.append(tfidf_vector)\n",
    "\n",
    "# # Convert the TF-IDF matrix to a NumPy array\n",
    "# tfidf_array = np.array(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sk_vocab = set(vectorizer.vocabulary_)\n",
    "# len(vocabulary - sk_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = dict()\n",
    "word_idf = dict()\n",
    "def map_word_index(vocabulary):\n",
    "    for index,word in enumerate(vocabulary):\n",
    "        word_index[word] = index\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processor\t: 0\n",
      "vendor_id\t: GenuineIntel\n",
      "cpu family\t: 6\n",
      "model\t\t: 69\n",
      "model name\t: Intel(R) Core(TM) i7-4510U CPU @ 2.00GHz\n",
      "stepping\t: 1\n",
      "microcode\t: 0xffffffff\n",
      "cpu MHz\t\t: 2593.993\n",
      "cache size\t: 4096 KB\n",
      "physical id\t: 0\n",
      "siblings\t: 4\n",
      "core id\t\t: 0\n",
      "cpu cores\t: 2\n",
      "apicid\t\t: 0\n",
      "initial apicid\t: 0\n",
      "fpu\t\t: yes\n",
      "fpu_exception\t: yes\n",
      "cpuid level\t: 13\n",
      "wp\t\t: yes\n",
      "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology cpuid pni pclmulqdq vmx ssse3 fma cx16 pcid sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single pti ssbd ibrs ibpb stibp tpr_shadow vnmi ept vpid ept_ad fsgsbase bmi1 avx2 smep bmi2 erms invpcid xsaveopt flush_l1d arch_capabilities\n",
      "vmx flags\t: vnmi invvpid ept_x_only ept_ad ept_1gb tsc_offset vtpr ept vpid unrestricted_guest\n",
      "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit srbds\n",
      "bogomips\t: 5187.98\n",
      "clflush size\t: 64\n",
      "cache_alignment\t: 64\n",
      "address sizes\t: 39 bits physical, 48 bits virtual\n",
      "power management:\n",
      "\n",
      "processor\t: 1\n",
      "vendor_id\t: GenuineIntel\n",
      "cpu family\t: 6\n",
      "model\t\t: 69\n",
      "model name\t: Intel(R) Core(TM) i7-4510U CPU @ 2.00GHz\n",
      "stepping\t: 1\n",
      "microcode\t: 0xffffffff\n",
      "cpu MHz\t\t: 2593.993\n",
      "cache size\t: 4096 KB\n",
      "physical id\t: 0\n",
      "siblings\t: 4\n",
      "core id\t\t: 0\n",
      "cpu cores\t: 2\n",
      "apicid\t\t: 1\n",
      "initial apicid\t: 1\n",
      "fpu\t\t: yes\n",
      "fpu_exception\t: yes\n",
      "cpuid level\t: 13\n",
      "wp\t\t: yes\n",
      "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology cpuid pni pclmulqdq vmx ssse3 fma cx16 pcid sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single pti ssbd ibrs ibpb stibp tpr_shadow vnmi ept vpid ept_ad fsgsbase bmi1 avx2 smep bmi2 erms invpcid xsaveopt flush_l1d arch_capabilities\n",
      "vmx flags\t: vnmi invvpid ept_x_only ept_ad ept_1gb tsc_offset vtpr ept vpid unrestricted_guest\n",
      "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit srbds\n",
      "bogomips\t: 5187.98\n",
      "clflush size\t: 64\n",
      "cache_alignment\t: 64\n",
      "address sizes\t: 39 bits physical, 48 bits virtual\n",
      "power management:\n",
      "\n",
      "processor\t: 2\n",
      "vendor_id\t: GenuineIntel\n",
      "cpu family\t: 6\n",
      "model\t\t: 69\n",
      "model name\t: Intel(R) Core(TM) i7-4510U CPU @ 2.00GHz\n",
      "stepping\t: 1\n",
      "microcode\t: 0xffffffff\n",
      "cpu MHz\t\t: 2593.993\n",
      "cache size\t: 4096 KB\n",
      "physical id\t: 0\n",
      "siblings\t: 4\n",
      "core id\t\t: 1\n",
      "cpu cores\t: 2\n",
      "apicid\t\t: 2\n",
      "initial apicid\t: 2\n",
      "fpu\t\t: yes\n",
      "fpu_exception\t: yes\n",
      "cpuid level\t: 13\n",
      "wp\t\t: yes\n",
      "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology cpuid pni pclmulqdq vmx ssse3 fma cx16 pcid sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single pti ssbd ibrs ibpb stibp tpr_shadow vnmi ept vpid ept_ad fsgsbase bmi1 avx2 smep bmi2 erms invpcid xsaveopt flush_l1d arch_capabilities\n",
      "vmx flags\t: vnmi invvpid ept_x_only ept_ad ept_1gb tsc_offset vtpr ept vpid unrestricted_guest\n",
      "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit srbds\n",
      "bogomips\t: 5187.98\n",
      "clflush size\t: 64\n",
      "cache_alignment\t: 64\n",
      "address sizes\t: 39 bits physical, 48 bits virtual\n",
      "power management:\n",
      "\n",
      "processor\t: 3\n",
      "vendor_id\t: GenuineIntel\n",
      "cpu family\t: 6\n",
      "model\t\t: 69\n",
      "model name\t: Intel(R) Core(TM) i7-4510U CPU @ 2.00GHz\n",
      "stepping\t: 1\n",
      "microcode\t: 0xffffffff\n",
      "cpu MHz\t\t: 2593.993\n",
      "cache size\t: 4096 KB\n",
      "physical id\t: 0\n",
      "siblings\t: 4\n",
      "core id\t\t: 1\n",
      "cpu cores\t: 2\n",
      "apicid\t\t: 3\n",
      "initial apicid\t: 3\n",
      "fpu\t\t: yes\n",
      "fpu_exception\t: yes\n",
      "cpuid level\t: 13\n",
      "wp\t\t: yes\n",
      "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology cpuid pni pclmulqdq vmx ssse3 fma cx16 pcid sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single pti ssbd ibrs ibpb stibp tpr_shadow vnmi ept vpid ept_ad fsgsbase bmi1 avx2 smep bmi2 erms invpcid xsaveopt flush_l1d arch_capabilities\n",
      "vmx flags\t: vnmi invvpid ept_x_only ept_ad ept_1gb tsc_offset vtpr ept vpid unrestricted_guest\n",
      "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit srbds\n",
      "bogomips\t: 5187.98\n",
      "clflush size\t: 64\n",
      "cache_alignment\t: 64\n",
      "address sizes\t: 39 bits physical, 48 bits virtual\n",
      "power management:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat /proc/cpuinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13783it [04:00, 57.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing iteration 13783/13783 (100%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "def compute_idf(word,dataset):\n",
    "    count = 0\n",
    "    for comment in dataset[\"comment\"]:\n",
    "        if word in comment:\n",
    "            count += 1\n",
    "    return np.log(len(dataset[\"comment\"])/count)\n",
    "\n",
    "for index, word in tqdm(enumerate(vocabulary)):\n",
    "    # print(index)\n",
    "    word_idf[word] = compute_idf(word,train_data)\n",
    "    percentage = 100*(index+1)/len(vocabulary)\n",
    "    if percentage % 1 == 0:\n",
    "        print(f\"Processing iteration {index+1}/{len(vocabulary)} ({percentage:.0f}%)\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_tf(word,comment):\n",
    "    freq = 0 \n",
    "    for part in comment:        \n",
    "        if word == part:\n",
    "            freq += 1\n",
    "    return freq/len(comment)\n",
    "    \n",
    "\n",
    "def fit_tfidf(comment,index,dataset_len):\n",
    "    vec = np.zeros(len(vocabulary))\n",
    "    for word in comment:\n",
    "        # if word in vocabulary:\n",
    "            tf = compute_tf(word,comment)\n",
    "            vec[word_index[word]] = tf*word_idf[word]\n",
    "    print(index)\n",
    "    \n",
    "    percentage = 100*(index+1)/dataset_len\n",
    "    if percentage % 2 == 0:\n",
    "        print(f\"Processing iteration {index+1}/{dataset_len} ({percentage:.0f}%)\")\n",
    "\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "85\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[199], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m map_word_index(vocabulary)\n\u001b[1;32m      2\u001b[0m train_data \u001b[39m=\u001b[39m train_data\u001b[39m.\u001b[39msort_index()\n\u001b[0;32m----> 3\u001b[0m train_data[\u001b[39m\"\u001b[39m\u001b[39mvectorized\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m train_data\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m row: fit_tfidf(row[\u001b[39m\"\u001b[39;49m\u001b[39mcomment\u001b[39;49m\u001b[39m\"\u001b[39;49m],row\u001b[39m.\u001b[39;49mname,\u001b[39mlen\u001b[39;49m(train_data)),axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/nlp/venv/lib/python3.10/site-packages/pandas/core/frame.py:9433\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9422\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[1;32m   9424\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[1;32m   9425\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   9426\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9431\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[1;32m   9432\u001b[0m )\n\u001b[0;32m-> 9433\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/nlp/venv/lib/python3.10/site-packages/pandas/core/apply.py:678\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[1;32m    676\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[0;32m--> 678\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/nlp/venv/lib/python3.10/site-packages/pandas/core/apply.py:798\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 798\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[1;32m    800\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[1;32m    801\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/nlp/venv/lib/python3.10/site-packages/pandas/core/apply.py:814\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    812\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[1;32m    813\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 814\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(v)\n\u001b[1;32m    815\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    816\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    817\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    818\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[199], line 3\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      1\u001b[0m map_word_index(vocabulary)\n\u001b[1;32m      2\u001b[0m train_data \u001b[39m=\u001b[39m train_data\u001b[39m.\u001b[39msort_index()\n\u001b[0;32m----> 3\u001b[0m train_data[\u001b[39m\"\u001b[39m\u001b[39mvectorized\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m train_data\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m row: fit_tfidf(row[\u001b[39m\"\u001b[39;49m\u001b[39mcomment\u001b[39;49m\u001b[39m\"\u001b[39;49m],row\u001b[39m.\u001b[39;49mname,\u001b[39mlen\u001b[39;49m(train_data)),axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[198], line 22\u001b[0m, in \u001b[0;36mfit_tfidf\u001b[0;34m(comment, index, dataset_len)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m comment:\n\u001b[1;32m     20\u001b[0m     \u001b[39m# if word in vocabulary:\u001b[39;00m\n\u001b[1;32m     21\u001b[0m         tf \u001b[39m=\u001b[39m compute_tf(word,comment)\n\u001b[0;32m---> 22\u001b[0m         idf \u001b[39m=\u001b[39m compute_idf(word)\n\u001b[1;32m     23\u001b[0m         word_idf[word] \u001b[39m=\u001b[39m idf\n\u001b[1;32m     24\u001b[0m         vec[word_index[word]] \u001b[39m=\u001b[39m tf\u001b[39m*\u001b[39midf\n",
      "Cell \u001b[0;32mIn[198], line 4\u001b[0m, in \u001b[0;36mcompute_idf\u001b[0;34m(word)\u001b[0m\n\u001b[1;32m      2\u001b[0m count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m comment \u001b[39min\u001b[39;00m dataset[\u001b[39m\"\u001b[39m\u001b[39mcomment\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m----> 4\u001b[0m     \u001b[39mif\u001b[39;00m word \u001b[39min\u001b[39;00m comment:\n\u001b[1;32m      5\u001b[0m         count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mlog(\u001b[39mlen\u001b[39m(dataset[\u001b[39m\"\u001b[39m\u001b[39mcomment\u001b[39m\u001b[39m\"\u001b[39m])\u001b[39m/\u001b[39mcount)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "map_word_index(vocabulary)\n",
    "train_data = train_data.sort_index()\n",
    "train_data[\"vectorized\"] = train_data.apply(lambda row: fit_tfidf(row[\"comment\"],row.name,len(train_data)),axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hazm-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
