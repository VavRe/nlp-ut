{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "4H2Uff6dWQoZ"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tVCONZIWWV1",
        "outputId": "47aa6de0-98d2-4d18-ec7f-d23da1067ce7"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "bAOPUELXWQob"
      },
      "outputs": [],
      "source": [
        "COLAB_DATASET_PATH = \"/content/drive/MyDrive/NLP/CA2/preprocessed.pkl\"\n",
        "LOCAL_DATASET_PATH = './datasets/preprocessed.pkl'\n",
        "dataset = pd.read_pickle(COLAB_DATASET_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pzlc95M6WQoc",
        "outputId": "44ddf6e8-1006-4c70-8027-a64ab8a33e5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset size:  14000\n",
            "Test Data size:  1400\n",
            "Train Data size:  12600\n"
          ]
        }
      ],
      "source": [
        "dataset = dataset.sample(frac=1, random_state=4)\n",
        "train_data = dataset[:int(len(dataset)*0.9)]\n",
        "test_data = dataset[int(len(dataset)*0.9):]\n",
        "print(\"Dataset size: \", len(dataset))\n",
        "print(\"Test Data size: \", len(test_data))\n",
        "print(\"Train Data size: \", len(train_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raEhvfJxWQod",
        "outputId": "c7ca5d99-16b2-4ab8-f594-b1443e405500"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8756     None\n",
              "5474     None\n",
              "11242    None\n",
              "7820     None\n",
              "7909     None\n",
              "         ... \n",
              "10142    None\n",
              "8828     None\n",
              "11554    None\n",
              "11609    None\n",
              "904      None\n",
              "Name: comment, Length: 12600, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "\n",
        "vocabulary = set()\n",
        "tf = dict()\n",
        "\n",
        "\n",
        "def make_vocab(sentence):\n",
        "\n",
        "    for word in sentence:\n",
        "         vocabulary.add(word)\n",
        "\n",
        "\n",
        "train_data[\"comment\"].apply(make_vocab)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4ivLdAOWQod",
        "outputId": "41dbdb3d-2ee6-4787-bb92-8d6d3c0bd753"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8756     None\n",
              "5474     None\n",
              "11242    None\n",
              "7820     None\n",
              "7909     None\n",
              "         ... \n",
              "10142    None\n",
              "8828     None\n",
              "11554    None\n",
              "11609    None\n",
              "904      None\n",
              "Name: comment, Length: 12600, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "# import TfidfVectorizer from scikit-learn\n",
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# train_data[\"comment\"] = train_data[\"comment\"].apply(lambda x: \" \".join(x))\n",
        "# vectorizer = TfidfVectorizer()\n",
        "# vec = vectorizer.fit_transform(train_data[\"comment\"])\n",
        "train_data[\"comment\"].apply(make_vocab)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agcmlZH6WQoe"
      },
      "source": [
        "Check the difference between the set and dict below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GCXsCn7WQof",
        "outputId": "a9f4e05a-5596-4ec8-dd06-9ffcbcf47fe2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "set"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "type(vocabulary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "cISqtaICWQog"
      },
      "outputs": [],
      "source": [
        "# type(vectorizer.vocabulary_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "Im9vXjecWQoh"
      },
      "outputs": [],
      "source": [
        "# def compute_tf(term,document):\n",
        "#     return document.count(term)/len(document)\n",
        "\n",
        "# train_data = train_data.sort_index()\n",
        "\n",
        "# for index,row in train_data.iterrows() :\n",
        "#     print(index)\n",
        "#     for word in vocabulary: \n",
        "#         for word in row[\"comment\"]:\n",
        "#             train_data[\"tf\"] = compute_tf(word,row[\"comment\"])\n",
        "#     percentage = 100*(index+1)/len(train_data)\n",
        "#     if percentage % 1 == 0:\n",
        "#         print(f\"Processing iteration {index+1}/{len(train_data)} ({percentage:.0f}%)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "5fQA_1lOWQoi"
      },
      "outputs": [],
      "source": [
        "# import numpy as np \n",
        "\n",
        "# def compute_tf(term, document):\n",
        "#     return document.count(term) / len(document)\n",
        "\n",
        "# # Define a function to calculate inverse document frequency (IDF) of a term in a corpus\n",
        "# def compute_idf(term, corpus):\n",
        "#     N = len(corpus)\n",
        "#     df = sum(1 for document in corpus if term in document)\n",
        "#     return np.log(N / df)\n",
        "\n",
        "# # Load the dataset\n",
        "\n",
        "# # Create a list of all unique words in the dataset\n",
        "# unique_words = list(set(word for document in train_data['comment'] for word in document))\n",
        "\n",
        "# # Calculate the TF-IDF matrix\n",
        "# tfidf_matrix = []\n",
        "\n",
        "# for i,document in enumerate(train_data['comment']):\n",
        "#     tfidf_vector = []\n",
        "#     print(i)\n",
        "#     for term in unique_words:\n",
        "#         tf = compute_tf(term, document)\n",
        "#         idf = compute_idf(term, train_data['comment'])\n",
        "#         tfidf = tf * idf\n",
        "#         tfidf_vector.append(tfidf)\n",
        "#     tfidf_matrix.append(tfidf_vector)\n",
        "\n",
        "# # Convert the TF-IDF matrix to a NumPy array\n",
        "# tfidf_array = np.array(tfidf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "y1yoyuSDWQoj"
      },
      "outputs": [],
      "source": [
        "# sk_vocab = set(vectorizer.vocabulary_)\n",
        "# len(vocabulary - sk_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "Qk4le5ZqWQoj"
      },
      "outputs": [],
      "source": [
        "word_index = dict()\n",
        "word_idf = dict()\n",
        "def map_word_index(vocabulary):\n",
        "    for index,word in enumerate(vocabulary):\n",
        "        word_index[word] = index\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blt2Y8rwWQok",
        "outputId": "05cef846-bb0e-4029-c51e-fb3674657c83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processor\t: 0\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 79\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0xffffffff\n",
            "cpu MHz\t\t: 2199.998\n",
            "cache size\t: 56320 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 2\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 1\n",
            "apicid\t\t: 0\n",
            "initial apicid\t: 0\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa mmio_stale_data retbleed\n",
            "bogomips\t: 4399.99\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 1\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 79\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0xffffffff\n",
            "cpu MHz\t\t: 2199.998\n",
            "cache size\t: 56320 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 2\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 1\n",
            "apicid\t\t: 1\n",
            "initial apicid\t: 1\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa mmio_stale_data retbleed\n",
            "bogomips\t: 4399.99\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!cat /proc/cpuinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3s7Tr9gqWQol",
        "outputId": "6b264bf3-acc7-437a-95fb-b663b54cf283"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13783it [03:06, 73.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing iteration 13783/13783 (100%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "def compute_idf(word,dataset_req):\n",
        "    count = 0\n",
        "    for comment in dataset_req[\"comment\"]:\n",
        "        if word in comment:\n",
        "            count += 1\n",
        "    return np.log(len(dataset_req[\"comment\"])/count)\n",
        "\n",
        "for index, word in tqdm(enumerate(vocabulary)):\n",
        "    # print(index)\n",
        "    word_idf[word] = compute_idf(word,train_data)\n",
        "    percentage = 100*(index+1)/len(vocabulary)\n",
        "    if percentage % 1 == 0:\n",
        "        print(f\"Processing iteration {index+1}/{len(vocabulary)} ({percentage:.0f}%)\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "tbPVGTfRWQom"
      },
      "outputs": [],
      "source": [
        "\n",
        "def compute_tf(word,comment):\n",
        "    freq = 0 \n",
        "    for part in comment:        \n",
        "        if word == part:\n",
        "            freq += 1\n",
        "    return freq/len(comment)\n",
        "    \n",
        "\n",
        "def fit_tfidf(comment,index,dataset_len):\n",
        "    vec = np.zeros(len(vocabulary))\n",
        "    for word in comment:\n",
        "        if word in vocabulary:\n",
        "            tf = compute_tf(word,comment)\n",
        "            vec[word_index[word]] = tf*word_idf[word]\n",
        "    \n",
        "    \n",
        "    percentage = 100*(index+1)/dataset_len\n",
        "    if percentage % 2 == 0:\n",
        "        print(f\"Processing iteration {index+1}/{dataset_len} ({percentage:.0f}%)\")\n",
        "\n",
        "    return vec"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "id": "shYn9S63beGJ",
        "outputId": "792fbc79-a2d3-438d-cae9-2da74a710b2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       index                                            comment  label  \\\n",
              "8756   57756  [بسیار, زود, زودتر, زمان, انتظار, ممنون, ., پی...    SAD   \n",
              "5474   27700                     [پیشنهاد, میدم, غذاهاشون, تست]  HAPPY   \n",
              "11242  53635  [یه, برگر, ۱, ساعت, نیم, کشید, بجای, غذا, آمبو...    SAD   \n",
              "7820   36810  [غذا, از, یکساعت, کشید, برسه, پیک, که, رستوران...    SAD   \n",
              "7909   55278  [نونش, واقعا, نا, مناسبه, این, قسمت, دورچین, و...    SAD   \n",
              "...      ...                                                ...    ...   \n",
              "10142  21171  [رستوران, منطقه‌ست, پاستای, خوشمزه, قابل, قبول...    SAD   \n",
              "8828   39351      [واقعا, افتضاح, ., هیچکس, پیشنهاد, نمیکنم, .]    SAD   \n",
              "11554  21938  [اسم, شرینی, کیک, تنوری, هست, ،, قاعدتا, اساس,...    SAD   \n",
              "11609  16224  [واقعا, بد, و, اصلا, شبیه, برند, باماهاس, ۲, ا...    SAD   \n",
              "904    11845           [بجای, بستنی, زعفرانی, وانیلی, ارسال, …]  HAPPY   \n",
              "\n",
              "       label_id  \n",
              "8756          1  \n",
              "5474          0  \n",
              "11242         1  \n",
              "7820          1  \n",
              "7909          1  \n",
              "...         ...  \n",
              "10142         1  \n",
              "8828          1  \n",
              "11554         1  \n",
              "11609         1  \n",
              "904           0  \n",
              "\n",
              "[12600 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cf993ef9-2a15-4f73-9152-b399e4797749\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>comment</th>\n",
              "      <th>label</th>\n",
              "      <th>label_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8756</th>\n",
              "      <td>57756</td>\n",
              "      <td>[بسیار, زود, زودتر, زمان, انتظار, ممنون, ., پی...</td>\n",
              "      <td>SAD</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5474</th>\n",
              "      <td>27700</td>\n",
              "      <td>[پیشنهاد, میدم, غذاهاشون, تست]</td>\n",
              "      <td>HAPPY</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11242</th>\n",
              "      <td>53635</td>\n",
              "      <td>[یه, برگر, ۱, ساعت, نیم, کشید, بجای, غذا, آمبو...</td>\n",
              "      <td>SAD</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7820</th>\n",
              "      <td>36810</td>\n",
              "      <td>[غذا, از, یکساعت, کشید, برسه, پیک, که, رستوران...</td>\n",
              "      <td>SAD</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7909</th>\n",
              "      <td>55278</td>\n",
              "      <td>[نونش, واقعا, نا, مناسبه, این, قسمت, دورچین, و...</td>\n",
              "      <td>SAD</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10142</th>\n",
              "      <td>21171</td>\n",
              "      <td>[رستوران, منطقه‌ست, پاستای, خوشمزه, قابل, قبول...</td>\n",
              "      <td>SAD</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8828</th>\n",
              "      <td>39351</td>\n",
              "      <td>[واقعا, افتضاح, ., هیچکس, پیشنهاد, نمیکنم, .]</td>\n",
              "      <td>SAD</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11554</th>\n",
              "      <td>21938</td>\n",
              "      <td>[اسم, شرینی, کیک, تنوری, هست, ،, قاعدتا, اساس,...</td>\n",
              "      <td>SAD</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11609</th>\n",
              "      <td>16224</td>\n",
              "      <td>[واقعا, بد, و, اصلا, شبیه, برند, باماهاس, ۲, ا...</td>\n",
              "      <td>SAD</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>904</th>\n",
              "      <td>11845</td>\n",
              "      <td>[بجای, بستنی, زعفرانی, وانیلی, ارسال, …]</td>\n",
              "      <td>HAPPY</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12600 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cf993ef9-2a15-4f73-9152-b399e4797749')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cf993ef9-2a15-4f73-9152-b399e4797749 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cf993ef9-2a15-4f73-9152-b399e4797749');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDdne3F8WQom",
        "outputId": "4c3e3a4c-3867-4b53-c65a-ca34e8ab41b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing iteration 252/12600 (2%)\n",
            "Processing iteration 504/12600 (4%)\n",
            "Processing iteration 756/12600 (6%)\n",
            "Processing iteration 1008/12600 (8%)\n",
            "Processing iteration 1260/12600 (10%)\n",
            "Processing iteration 1512/12600 (12%)\n",
            "Processing iteration 1764/12600 (14%)\n",
            "Processing iteration 2016/12600 (16%)\n",
            "Processing iteration 2268/12600 (18%)\n",
            "Processing iteration 2520/12600 (20%)\n",
            "Processing iteration 2772/12600 (22%)\n",
            "Processing iteration 3024/12600 (24%)\n",
            "Processing iteration 3276/12600 (26%)\n",
            "Processing iteration 3528/12600 (28%)\n",
            "Processing iteration 3780/12600 (30%)\n",
            "Processing iteration 4032/12600 (32%)\n",
            "Processing iteration 4284/12600 (34%)\n",
            "Processing iteration 4536/12600 (36%)\n",
            "Processing iteration 4788/12600 (38%)\n",
            "Processing iteration 5040/12600 (40%)\n",
            "Processing iteration 5292/12600 (42%)\n",
            "Processing iteration 5544/12600 (44%)\n",
            "Processing iteration 5796/12600 (46%)\n",
            "Processing iteration 6048/12600 (48%)\n",
            "Processing iteration 6300/12600 (50%)\n",
            "Processing iteration 6552/12600 (52%)\n",
            "Processing iteration 6804/12600 (54%)\n",
            "Processing iteration 7056/12600 (56%)\n",
            "Processing iteration 7308/12600 (58%)\n",
            "Processing iteration 7560/12600 (60%)\n",
            "Processing iteration 7812/12600 (62%)\n",
            "Processing iteration 8064/12600 (64%)\n",
            "Processing iteration 8316/12600 (66%)\n",
            "Processing iteration 8568/12600 (68%)\n",
            "Processing iteration 8820/12600 (70%)\n",
            "Processing iteration 9072/12600 (72%)\n",
            "Processing iteration 9324/12600 (74%)\n",
            "Processing iteration 9576/12600 (76%)\n",
            "Processing iteration 9828/12600 (78%)\n",
            "Processing iteration 10080/12600 (80%)\n",
            "Processing iteration 10332/12600 (82%)\n",
            "Processing iteration 10584/12600 (84%)\n",
            "Processing iteration 10836/12600 (86%)\n",
            "Processing iteration 11088/12600 (88%)\n",
            "Processing iteration 11340/12600 (90%)\n",
            "Processing iteration 11592/12600 (92%)\n",
            "Processing iteration 11844/12600 (94%)\n",
            "Processing iteration 12096/12600 (96%)\n",
            "Processing iteration 12348/12600 (98%)\n",
            "Processing iteration 12600/12600 (100%)\n"
          ]
        }
      ],
      "source": [
        "map_word_index(vocabulary)\n",
        "# train_data = train_data.reset_index().sort_index()\n",
        "train_data[\"vectorized\"] = train_data.apply(lambda row: fit_tfidf(row[\"comment\"],row.name,len(train_data)),axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = test_data.reset_index().sort_index()\n",
        "test_data[\"vectorized\"] = test_data.apply(lambda row: fit_tfidf(row[\"comment\"],row.name,len(test_data)),axis=1)\n"
      ],
      "metadata": {
        "id": "pny7VvdZj3KD",
        "outputId": "84613e7a-92aa-4ac2-b3c4-b2029454ab96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing iteration 28/1400 (2%)\n",
            "Processing iteration 56/1400 (4%)\n",
            "Processing iteration 84/1400 (6%)\n",
            "Processing iteration 112/1400 (8%)\n",
            "Processing iteration 140/1400 (10%)\n",
            "Processing iteration 168/1400 (12%)\n",
            "Processing iteration 196/1400 (14%)\n",
            "Processing iteration 224/1400 (16%)\n",
            "Processing iteration 252/1400 (18%)\n",
            "Processing iteration 280/1400 (20%)\n",
            "Processing iteration 308/1400 (22%)\n",
            "Processing iteration 336/1400 (24%)\n",
            "Processing iteration 364/1400 (26%)\n",
            "Processing iteration 392/1400 (28%)\n",
            "Processing iteration 420/1400 (30%)\n",
            "Processing iteration 448/1400 (32%)\n",
            "Processing iteration 476/1400 (34%)\n",
            "Processing iteration 504/1400 (36%)\n",
            "Processing iteration 532/1400 (38%)\n",
            "Processing iteration 560/1400 (40%)\n",
            "Processing iteration 588/1400 (42%)\n",
            "Processing iteration 616/1400 (44%)\n",
            "Processing iteration 644/1400 (46%)\n",
            "Processing iteration 672/1400 (48%)\n",
            "Processing iteration 700/1400 (50%)\n",
            "Processing iteration 728/1400 (52%)\n",
            "Processing iteration 756/1400 (54%)\n",
            "Processing iteration 784/1400 (56%)\n",
            "Processing iteration 812/1400 (58%)\n",
            "Processing iteration 840/1400 (60%)\n",
            "Processing iteration 868/1400 (62%)\n",
            "Processing iteration 896/1400 (64%)\n",
            "Processing iteration 924/1400 (66%)\n",
            "Processing iteration 952/1400 (68%)\n",
            "Processing iteration 980/1400 (70%)\n",
            "Processing iteration 1008/1400 (72%)\n",
            "Processing iteration 1036/1400 (74%)\n",
            "Processing iteration 1064/1400 (76%)\n",
            "Processing iteration 1092/1400 (78%)\n",
            "Processing iteration 1120/1400 (80%)\n",
            "Processing iteration 1148/1400 (82%)\n",
            "Processing iteration 1176/1400 (84%)\n",
            "Processing iteration 1204/1400 (86%)\n",
            "Processing iteration 1232/1400 (88%)\n",
            "Processing iteration 1260/1400 (90%)\n",
            "Processing iteration 1288/1400 (92%)\n",
            "Processing iteration 1316/1400 (94%)\n",
            "Processing iteration 1344/1400 (96%)\n",
            "Processing iteration 1372/1400 (98%)\n",
            "Processing iteration 1400/1400 (100%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "clf = MultinomialNB()\n",
        "clf.fit(train_data[\"vectorized\"].to_list(),train_data[\"label_id\"].to_list())"
      ],
      "metadata": {
        "id": "QV_9pStZkWyr",
        "outputId": "31cfea8e-013c-463a-ca34-f7b56f07c68e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        }
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = clf.predict(test_data[\"vectorized\"].to_list())"
      ],
      "metadata": {
        "id": "dl6VmxfMnAxy"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_pred,test_data[\"label_id\"].to_list()))\n"
      ],
      "metadata": {
        "id": "n20YBUW-nKTo",
        "outputId": "1f10aa59-226a-4c2e-fa3b-0773b7302916",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.86      0.80       605\n",
            "           1       0.88      0.78      0.83       795\n",
            "\n",
            "    accuracy                           0.82      1400\n",
            "   macro avg       0.82      0.82      0.82      1400\n",
            "weighted avg       0.83      0.82      0.82      1400\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "hazm-venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}