{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "670000 ./raw_data/train.fa\n",
      "670000 ./raw_data/train.en\n",
      "4000 ./raw_data/valid.fa\n",
      "4000 ./raw_data/valid.en\n",
      "10000 ./raw_data/test.fa\n",
      "10000 ./raw_data/test.fa\n"
     ]
    }
   ],
   "source": [
    "## Here, you can see how many lines each file has\n",
    "\n",
    "!wc -l ./raw_data/train.fa\n",
    "!wc -l ./raw_data/train.en\n",
    "!wc -l ./raw_data/valid.fa\n",
    "!wc -l ./raw_data/valid.en\n",
    "!wc -l ./raw_data/test.fa\n",
    "!wc -l ./raw_data/test.fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "مرگ 50 ستیزه جوی دیگر در عملیات وزیرستان شمالی\n",
      "پیشاور - به گزارش جیو نیوز , عملیات ادامه دار ارتش در وزیرستان شمالیمنجر به مرگ دست کم 50 ستیزه جوی مظنون دیگر در روز 17 ژوئن شد .\n",
      "به گزارش رسانه‌ها , نیروی هوایی پاکستان حملات هوایی را علیه مخفیگاه های ستیزه جویی در میرعلی و نواحی دیگر منطقه انجام داد و دست کم هشت مخفیگاه را ویران کرد .\n",
      "North Waziristan operation kills 50 more militants\n",
      "PESHAWAR - The on - goingmilitary operation in North Waziristankilled at least 50 more suspected militants June 17 , Geo News reported .\n",
      "The Pakistani Air Force conducted airstrikes against militant hideouts in Mir Ali and other areas of the agency , destroying at least eight , media reported .\n"
     ]
    }
   ],
   "source": [
    "!head ./raw_data/train.fa -n 3\n",
    "!head ./raw_data/train.en -n 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join all paths to a base path \n",
    "BASE_PATH = \".\"\n",
    "RAW_DATA_PATH = os.path.join(BASE_PATH, \"raw_data\")\n",
    "TOKENIZED_DATA_PATH = os.path.join(BASE_PATH, \"tokenized_data\")\n",
    "VOCAB_SIZE = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m INPUT_TRAIN_FA \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(RAW_DATA_PATH, \u001b[39m\"\u001b[39m\u001b[39mtrain.fa\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m OUTPUT_MODEL_FA \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(TOKENIZED_DATA_PATH, \u001b[39m\"\u001b[39m\u001b[39mm_fa.model\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m spm\u001b[39m.\u001b[39;49mSentencePieceTrainer\u001b[39m.\u001b[39;49mtrain(\u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49mINPUT_TRAIN_FA, model_prefix\u001b[39m=\u001b[39;49mOUTPUT_MODEL_FA, vocab_size\u001b[39m=\u001b[39;49mVOCAB_SIZE, character_coverage\u001b[39m=\u001b[39;49m\u001b[39m1.0\u001b[39;49m, model_type\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mbpe\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/nlp/venv/lib/python3.10/site-packages/sentencepiece/__init__.py:989\u001b[0m, in \u001b[0;36mSentencePieceTrainer.Train\u001b[0;34m(arg, logstream, **kwargs)\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    987\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mTrain\u001b[39m(arg\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, logstream\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    988\u001b[0m   \u001b[39mwith\u001b[39;00m _LogStream(ostream\u001b[39m=\u001b[39mlogstream):\n\u001b[0;32m--> 989\u001b[0m     SentencePieceTrainer\u001b[39m.\u001b[39;49m_Train(arg\u001b[39m=\u001b[39;49marg, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/nlp/venv/lib/python3.10/site-packages/sentencepiece/__init__.py:982\u001b[0m, in \u001b[0;36mSentencePieceTrainer._Train\u001b[0;34m(arg, **kwargs)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[39mreturn\u001b[39;00m SentencePieceTrainer\u001b[39m.\u001b[39m_TrainFromMap2(new_kwargs, sentence_iterator)\n\u001b[1;32m    981\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 982\u001b[0m     \u001b[39mreturn\u001b[39;00m SentencePieceTrainer\u001b[39m.\u001b[39;49m_TrainFromMap(new_kwargs)\n\u001b[1;32m    984\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/nlp/venv/lib/python3.10/site-packages/sentencepiece/__init__.py:927\u001b[0m, in \u001b[0;36mSentencePieceTrainer._TrainFromMap\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    925\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    926\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_TrainFromMap\u001b[39m(args):\n\u001b[0;32m--> 927\u001b[0m     \u001b[39mreturn\u001b[39;00m _sentencepiece\u001b[39m.\u001b[39;49mSentencePieceTrainer__TrainFromMap(args)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Do this only if  m_fa is not created in ./tokenizer\n",
    "\n",
    "INPUT_TRAIN_FA = os.path.join(RAW_DATA_PATH, \"train.fa\")\n",
    "OUTPUT_MODEL_FA = os.path.join(TOKENIZED_DATA_PATH, \"m_fa.model\")\n",
    "\n",
    "spm.SentencePieceTrainer.train(input=INPUT_TRAIN_FA, model_prefix=OUTPUT_MODEL_FA, vocab_size=VOCAB_SIZE, character_coverage=1.0, model_type='bpe')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model already exists\n"
     ]
    }
   ],
   "source": [
    "INPUT_TRAIN_EN = os.path.join(RAW_DATA_PATH, \"train.en\")\n",
    "OUTPUT_MODEL_EN = os.path.join(TOKENIZED_DATA_PATH, \"m_en.model\")\n",
    "\n",
    "\n",
    "spm.SentencePieceTrainer.train(input=INPUT_TRAIN_EN, model_prefix=OUTPUT_MODEL_EN, vocab_size=VOCAB_SIZE, character_coverage=1.0, model_type='bpe')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the length of train_fa is 670000 and the length of train_en is 670000\n"
     ]
    }
   ],
   "source": [
    "# Read all raw files as lists of strings by line break\n",
    "with open(os.path.join(RAW_DATA_PATH, \"train.fa\"), \"r\") as f:\n",
    "    train_fa = f.readlines()\n",
    "with open(os.path.join(RAW_DATA_PATH, \"train.en\"), \"r\") as f:\n",
    "    train_en = f.readlines()\n",
    "with open(os.path.join(RAW_DATA_PATH, \"valid.fa\"), \"r\") as f:\n",
    "    valid_fa = f.readlines()\n",
    "with open(os.path.join(RAW_DATA_PATH, \"valid.en\"), \"r\") as f:\n",
    "    valid_en = f.readlines()\n",
    "with open(os.path.join(RAW_DATA_PATH, \"test.fa\"), \"r\") as f:\n",
    "    test_fa = f.readlines()\n",
    "with open(os.path.join(RAW_DATA_PATH, \"test.en\"), \"r\") as f:\n",
    "    test_en = f.readlines()\n",
    "    \n",
    "print(f\"the length of train_fa is {len(train_fa)} and the length of train_en is {len(train_en)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'مرگ 50 ستیزه جوی دیگر در عملیات وزیرستان شمالی'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fa[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'North Waziristan operation kills 50 more militants'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_en[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_fa = spm.SentencePieceProcessor(model_file=OUTPUT_MODEL_FA)\n",
    "sp_en = spm.SentencePieceProcessor(model_file=OUTPUT_MODEL_EN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoded_fa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m encoded_test_fa \u001b[39m=\u001b[39m sp_fa\u001b[39m.\u001b[39mencode(test_fa, out_type\u001b[39m=\u001b[39m\u001b[39mstr\u001b[39m)\n\u001b[1;32m      6\u001b[0m encoded_test_en \u001b[39m=\u001b[39m sp_en\u001b[39m.\u001b[39mencode(test_en, out_type\u001b[39m=\u001b[39m\u001b[39mstr\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m encoded_fa[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'encoded_fa' is not defined"
     ]
    }
   ],
   "source": [
    "encoded_train_fa = sp_fa.encode(train_fa, out_type=str)\n",
    "encoded_train_en = sp_en.encode(train_en, out_type=str)\n",
    "encoded_valid_fa = sp_fa.encode(valid_fa, out_type=str)\n",
    "encoded_valid_en = sp_en.encode(valid_en, out_type=str)\n",
    "encoded_test_fa = sp_fa.encode(test_fa, out_type=str)\n",
    "encoded_test_en = sp_en.encode(test_en, out_type=str)\n",
    "\n",
    "encoded_train_fa[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁مرگ',\n",
       " '▁50',\n",
       " '▁ستیزه',\n",
       " '▁جوی',\n",
       " '▁دیگر',\n",
       " '▁در',\n",
       " '▁عملیات',\n",
       " '▁وزیرستان',\n",
       " '▁شمالی']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_train_fa[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'▁مرگ ▁50 ▁ستیزه ▁جوی ▁دیگر ▁در ▁عملیات ▁وزیرستان ▁شمالی'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# turn each list of strings into a single string with space as the delimiter\n",
    "encoded_train_fa_str = [' '.join(sent) for sent in encoded_train_fa]\n",
    "encoded_train_en_str = [' '.join(sent) for sent in encoded_train_en]\n",
    "encoded_valid_fa_str = [' '.join(sent) for sent in encoded_valid_fa]\n",
    "encoded_valid_en_str = [' '.join(sent) for sent in encoded_valid_en]\n",
    "encoded_test_fa_str = [' '.join(sent) for sent in encoded_test_fa]\n",
    "encoded_test_en_str = [' '.join(sent) for sent in encoded_test_en]\n",
    "\n",
    "encoded_train_fa_str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write all arrays of last cell to files in ./tokenized_data\n",
    "\n",
    "with open(os.path.join(TOKENIZED_DATA_PATH, \"train.fa\"), \"w\") as f:\n",
    "    f.writelines(encoded_train_fa_str)\n",
    "with open(os.path.join(TOKENIZED_DATA_PATH, \"train.en\"), \"w\") as f:\n",
    "    f.writelines(encoded_train_en_str)\n",
    "with open(os.path.join(TOKENIZED_DATA_PATH, \"valid.fa\"), \"w\") as f:\n",
    "    f.writelines(encoded_valid_fa_str)\n",
    "with open(os.path.join(TOKENIZED_DATA_PATH, \"valid.en\"), \"w\") as f:\n",
    "    f.writelines(encoded_valid_en_str)\n",
    "with open(os.path.join(TOKENIZED_DATA_PATH, \"test.fa\"), \"w\") as f:\n",
    "    f.writelines(encoded_test_fa_str)\n",
    "with open(os.path.join(TOKENIZED_DATA_PATH, \"test.en\"), \"w\") as f:\n",
    "    f.writelines(encoded_test_en_str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▁North ▁Waziristan ▁operation ▁kills ▁50 ▁more ▁militants\n",
      "▁PESHAWAR ▁- ▁The ▁on ▁- ▁going m ilitary ▁operation ▁in ▁North ▁Waziristan k illed ▁at ▁least ▁50 ▁more ▁suspected ▁militants ▁June ▁17 ▁, ▁Geo ▁News ▁reported ▁.\n",
      "▁The ▁Pakistani ▁Air ▁Force ▁conducted ▁air st rik es ▁against ▁militant ▁hideouts ▁in ▁Mir ▁Ali ▁and ▁other ▁areas ▁of ▁the ▁agency ▁, ▁destroying ▁at ▁least ▁eight ▁, ▁media ▁reported ▁.\n",
      "▁A ▁day ▁earlier ▁, ▁at ▁least ▁27 ▁militants ▁were ▁reported ▁dead ▁after ▁j ets ▁p ounded ▁militant ▁hideouts ▁in ▁Sh aw al ▁.\n",
      "▁Meanwhile ▁, ▁a ▁roadside ▁blast ▁on ▁Bang id ar ▁road ▁in ▁the ▁Gh ul lam ▁Khan ▁area ▁June ▁16 ▁killed ▁six ▁security ▁personnel ▁and ▁wounded ▁three ▁others ▁, ▁according ▁to ▁officials ▁.\n",
      "▁مرگ ▁50 ▁ستیزه ▁جوی ▁دیگر ▁در ▁عملیات ▁وزیرستان ▁شمالی\n",
      "▁پیشاور ▁- ▁به ▁گزارش ▁جیو ▁نیوز ▁, ▁عملیات ▁ادامه ▁دار ▁ارتش ▁در ▁وزیرستان ▁شمال یمن جر ▁به ▁مرگ ▁دست ▁کم ▁50 ▁ستیزه ▁جوی ▁مظنون ▁دیگر ▁در ▁روز ▁17 ▁ژوئن ▁شد ▁.\n",
      "▁به ▁گزارش ▁رسانه ▁ها ▁, ▁نیروی ▁هوایی ▁پاکستان ▁حملات ▁هوایی ▁را ▁علیه ▁مخفیگاه ▁های ▁ستیزه ▁جویی ▁در ▁میر علی ▁و ▁نواحی ▁دیگر ▁منطقه ▁انجام ▁داد ▁و ▁دست ▁کم ▁هشت ▁مخفیگاه ▁را ▁ویران ▁کرد ▁.\n",
      "▁یک ▁روز ▁پیشتر ▁گزارش ▁شده ▁بود ▁که ▁دست ▁کم ▁27 ▁ستیزه ▁جو ▁در ▁پی ▁بمباران ▁مخفیگاه ▁های ▁ستیزه ▁جویان ▁در ▁شو ال ▁توسط ▁جت ▁های ▁بمب ▁اف کن ▁, ▁کشته ▁شدند ▁.\n",
      "▁در ▁ضمن ▁, ▁مسئولان ▁گفتند ▁که ▁یک ▁انفجار ▁کنارجاده ▁ای ▁در ▁روز ▁16 ▁ژوئن ▁در ▁خیابان ▁بنگ ید ار ▁ناحیه ▁غلام ▁خان ▁جان ▁شش ▁پرسنل ▁امنیتی ▁را ▁گرفت ▁و ▁سه ▁تن ▁دیگر ▁را ▁زخمی ▁کرد ▁.\n"
     ]
    }
   ],
   "source": [
    "show_tokenized_top_fa_command = f\"head {TOKENIZED_DATA_PATH}/train.fa -n 5\"\n",
    "show_tokenized_top_en_command = f\"head {TOKENIZED_DATA_PATH}/train.en -n 5\"\n",
    "!{show_tokenized_top_en_command}\n",
    "!{show_tokenized_top_fa_command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
