{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VavRe/nlp-ut/blob/main/CA5/Tokenization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhKb3XRr7NEF",
        "outputId": "85710f33-064d-4fc5-8045-f7684dcbbca2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement sacramentos (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for sacramentos\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece\n",
        "!pip install sacramentos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swex_kah7TF3",
        "outputId": "911a12ff-d911-4cb6-c181-08de246008fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:  \n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ZhVjlk257KLd"
      },
      "outputs": [],
      "source": [
        "import sentencepiece as spm\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lq-q4N2x7KLm",
        "outputId": "42f1b439-5b25-4d05-b02f-572947f872f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wc: ./raw_data/train.fa: No such file or directory\n",
            "wc: ./raw_data/train.en: No such file or directory\n",
            "wc: ./raw_data/valid.fa: No such file or directory\n",
            "wc: ./raw_data/valid.en: No such file or directory\n",
            "wc: ./raw_data/test.fa: No such file or directory\n",
            "wc: ./raw_data/test.fa: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "## Here, you can see how many lines each file has using unix\n",
        "\n",
        "!wc -l ./raw_data/train.fa\n",
        "!wc -l ./raw_data/train.en\n",
        "!wc -l ./raw_data/valid.fa\n",
        "!wc -l ./raw_data/valid.en\n",
        "!wc -l ./raw_data/test.fa\n",
        "!wc -l ./raw_data/test.fa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ID-CxwnT7KLp",
        "outputId": "f8d36e20-7e64-4cba-a544-b28716cf3d6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "head: cannot open './raw_data/train.fa' for reading: No such file or directory\n",
            "head: cannot open './raw_data/train.en' for reading: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!head ./raw_data/train.fa -n 3\n",
        "!head ./raw_data/train.en -n 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "vwF3I1SW7KLq"
      },
      "outputs": [],
      "source": [
        "#join all paths to a base path \n",
        "BASE_PATH = \"/content/drive/MyDrive/NLP/CA5\"\n",
        "RAW_DATA_PATH = os.path.join(BASE_PATH, \"raw_data\")\n",
        "TOKENIZED_DATA_PATH = os.path.join(BASE_PATH, \"tokenized_data\")\n",
        "TOKENIZER_PATH = os.path.join(BASE_PATH, \"tokenizer\")\n",
        "VOCAB_SIZE = 10000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "dALTt3-47KLs"
      },
      "outputs": [],
      "source": [
        "# Do this only if  m_fa is not created in ./tokenizer\n",
        "\n",
        "INPUT_TRAIN_FA = os.path.join(RAW_DATA_PATH, \"train.fa\")\n",
        "OUTPUT_MODEL_FA = os.path.join(TOKENIZER_PATH, \"m_fa\")\n",
        "\n",
        "spm.SentencePieceTrainer.train(input=INPUT_TRAIN_FA, model_prefix=OUTPUT_MODEL_FA, vocab_size=VOCAB_SIZE, character_coverage=1.0, model_type='bpe')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Ogk6sltI7KLt"
      },
      "outputs": [],
      "source": [
        "INPUT_TRAIN_EN = os.path.join(RAW_DATA_PATH, \"train.en\")\n",
        "OUTPUT_MODEL_EN = os.path.join(TOKENIZER_PATH, \"m_en\")\n",
        "\n",
        "\n",
        "spm.SentencePieceTrainer.train(input=INPUT_TRAIN_EN, model_prefix=OUTPUT_MODEL_EN, vocab_size=VOCAB_SIZE, character_coverage=1.0, model_type='bpe')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfQTLTGy7KLv",
        "outputId": "49994b83-b8ac-4c0b-d28a-427f7b5dd56f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the length of train_fa is 670000 and the length of train_en is 670000\n"
          ]
        }
      ],
      "source": [
        "# Read all raw files as lists of strings by line break\n",
        "with open(os.path.join(RAW_DATA_PATH, \"train.fa\"), \"r\") as f:\n",
        "    train_fa = f.readlines()\n",
        "with open(os.path.join(RAW_DATA_PATH, \"train.en\"), \"r\") as f:\n",
        "    train_en = f.readlines()\n",
        "with open(os.path.join(RAW_DATA_PATH, \"valid.fa\"), \"r\") as f:\n",
        "    valid_fa = f.readlines()\n",
        "with open(os.path.join(RAW_DATA_PATH, \"valid.en\"), \"r\") as f:\n",
        "    valid_en = f.readlines()\n",
        "with open(os.path.join(RAW_DATA_PATH, \"test.fa\"), \"r\") as f:\n",
        "    test_fa = f.readlines()\n",
        "with open(os.path.join(RAW_DATA_PATH, \"test.en\"), \"r\") as f:\n",
        "    test_en = f.readlines()\n",
        "    \n",
        "print(f\"the length of train_fa is {len(train_fa)} and the length of train_en is {len(train_en)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "sbtSX6Ms7KLw",
        "outputId": "f415efdb-6d8a-4da5-ebe6-c0b28f3a42d5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'مرگ 50 ستیزه جوی دیگر در عملیات وزیرستان شمالی\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "train_fa[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wCZfHkdD7KLy",
        "outputId": "aff8ddb2-cbce-4563-cad5-9c876597387f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'North Waziristan operation kills 50 more militants\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "train_en[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "gbUfnJsa7KL0"
      },
      "outputs": [],
      "source": [
        "sp_fa = spm.SentencePieceProcessor(model_file=f\"{OUTPUT_MODEL_FA}.model\")\n",
        "sp_en = spm.SentencePieceProcessor(model_file=f\"{OUTPUT_MODEL_EN}.model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7pkym927KL2",
        "outputId": "2848be1e-80fb-4e81-8a02-3f298e6a34eb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['▁مرگ',\n",
              " '▁50',\n",
              " '▁ستیزه',\n",
              " '▁جوی',\n",
              " '▁دیگر',\n",
              " '▁در',\n",
              " '▁عملیات',\n",
              " '▁وزیرستان',\n",
              " '▁شمالی']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "encoded_train_fa = sp_fa.encode(train_fa, out_type=str)\n",
        "encoded_train_en = sp_en.encode(train_en, out_type=str)\n",
        "encoded_valid_fa = sp_fa.encode(valid_fa, out_type=str)\n",
        "encoded_valid_en = sp_en.encode(valid_en, out_type=str)\n",
        "encoded_test_fa = sp_fa.encode(test_fa, out_type=str)\n",
        "encoded_test_en = sp_en.encode(test_en, out_type=str)\n",
        "\n",
        "encoded_train_fa[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhvzeYkV7KL3",
        "outputId": "3a5df4d2-5b5d-4cd4-9101-abb068605349"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['▁مرگ',\n",
              " '▁50',\n",
              " '▁ستیزه',\n",
              " '▁جوی',\n",
              " '▁دیگر',\n",
              " '▁در',\n",
              " '▁عملیات',\n",
              " '▁وزیرستان',\n",
              " '▁شمالی']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "encoded_train_fa[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "DmMz9Z427KL5",
        "outputId": "2edf87ad-862f-4ced-abaa-4e65bf6b68f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'▁مرگ ▁50 ▁ستیزه ▁جوی ▁دیگر ▁در ▁عملیات ▁وزیرستان ▁شمالی'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "# turn each list of strings into a single string with space as the delimiter\n",
        "encoded_train_fa_str = [' '.join(sent) for sent in encoded_train_fa]\n",
        "encoded_train_en_str = [' '.join(sent) for sent in encoded_train_en]\n",
        "encoded_valid_fa_str = [' '.join(sent) for sent in encoded_valid_fa]\n",
        "encoded_valid_en_str = [' '.join(sent) for sent in encoded_valid_en]\n",
        "encoded_test_fa_str = [' '.join(sent) for sent in encoded_test_fa]\n",
        "encoded_test_en_str = [' '.join(sent) for sent in encoded_test_en]\n",
        "\n",
        "encoded_train_fa_str[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "2qUzw6et7KL6"
      },
      "outputs": [],
      "source": [
        "# write all arrays of last cell to files in ./tokenized_data\n",
        "\n",
        "with open(os.path.join(TOKENIZED_DATA_PATH, \"train.fa\"), \"w\") as f:\n",
        "    f.writelines(encoded_train_fa_str)\n",
        "with open(os.path.join(TOKENIZED_DATA_PATH, \"train.en\"), \"w\") as f:\n",
        "    f.writelines(encoded_train_en_str)\n",
        "with open(os.path.join(TOKENIZED_DATA_PATH, \"valid.fa\"), \"w\") as f:\n",
        "    f.writelines(encoded_valid_fa_str)\n",
        "with open(os.path.join(TOKENIZED_DATA_PATH, \"valid.en\"), \"w\") as f:\n",
        "    f.writelines(encoded_valid_en_str)\n",
        "with open(os.path.join(TOKENIZED_DATA_PATH, \"test.fa\"), \"w\") as f:\n",
        "    f.writelines(encoded_test_fa_str)\n",
        "with open(os.path.join(TOKENIZED_DATA_PATH, \"test.en\"), \"w\") as f:\n",
        "    f.writelines(encoded_test_en_str)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "yCuGCGfI7KL7"
      },
      "outputs": [],
      "source": [
        "# show_tokenized_top_fa_command = f\"head {TOKENIZED_DATA_PATH}/train.fa -n 5\"\n",
        "# show_tokenized_top_en_command = f\"head {TOKENIZED_DATA_PATH}/train.en -n 5\"\n",
        "# !{show_tokenized_top_en_command} \n",
        "# !{show_tokenized_top_fa_command}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "9VI2zsUK7KL7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}