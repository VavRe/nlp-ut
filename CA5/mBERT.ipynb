{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VavRe/nlp-ut/blob/main/CA5/mBERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install sacremoses\n",
        "!pip install fairseq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOEECzYq-_xG",
        "outputId": "99bfd3de-2d04-4236-f1ff-28266ee9fe79"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.30.1-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m123.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.15.1 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacremoses) (2022.10.31)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sacremoses) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses) (1.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sacremoses) (4.65.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895241 sha256=d5fd5ed62fb89ab8d857ff2ef8617d1da5547ee6bb3818d4634d65a7d6c7dec0\n",
            "  Stored in directory: /root/.cache/pip/wheels/00/24/97/a2ea5324f36bc626e1ea0267f33db6aa80d157ee977e9e42fb\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses\n",
            "Successfully installed sacremoses-0.0.53\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fairseq\n",
            "  Downloading fairseq-0.12.2.tar.gz (9.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.10/dist-packages (from fairseq) (1.15.1)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from fairseq) (0.29.34)\n",
            "Collecting hydra-core<1.1,>=1.0.7 (from fairseq)\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf<2.1 (from fairseq)\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from fairseq) (2022.10.31)\n",
            "Collecting sacrebleu>=1.4.12 (from fairseq)\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from fairseq) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fairseq) (4.65.0)\n",
            "Collecting bitarray (from fairseq)\n",
            "  Downloading bitarray-2.7.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (273 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from fairseq) (2.0.2+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fairseq) (1.22.4)\n",
            "Collecting antlr4-python3-runtime==4.8 (from hydra-core<1.1,>=1.0.7->fairseq)\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq) (6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq) (4.5.0)\n",
            "Collecting portalocker (from sacrebleu>=1.4.12->fairseq)\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq) (0.8.10)\n",
            "Collecting colorama (from sacrebleu>=1.4.12->fairseq)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq) (4.9.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (3.12.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->fairseq) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->fairseq) (16.0.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi->fairseq) (2.21)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->fairseq) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->fairseq) (1.3.0)\n",
            "Building wheels for collected packages: fairseq, antlr4-python3-runtime\n",
            "  Building wheel for fairseq (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairseq: filename=fairseq-0.12.2-cp310-cp310-linux_x86_64.whl size=11170802 sha256=73e8a3032e25533af4c326b4202829bef393243e49ea665549a72b5bd00bff4d\n",
            "  Stored in directory: /root/.cache/pip/wheels/e4/35/55/9c66f65ec7c83fd6fbc2b9502a0ac81b2448a1196159dacc32\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141210 sha256=5ee0a9f34db555f3389c5b2a626db81c287d0f4c2116eace7e184d7b714f7101\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\n",
            "Successfully built fairseq antlr4-python3-runtime\n",
            "Installing collected packages: bitarray, antlr4-python3-runtime, portalocker, omegaconf, colorama, sacrebleu, hydra-core, fairseq\n",
            "Successfully installed antlr4-python3-runtime-4.8 bitarray-2.7.5 colorama-0.4.6 fairseq-0.12.2 hydra-core-1.0.7 omegaconf-2.0.6 portalocker-2.7.0 sacrebleu-2.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ekFFbg_Q8Kkq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:  \n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ihm17vp-3FA",
        "outputId": "216057fc-8aa4-4af7-e1d4-f61fb8aa7e74"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "b-gpkoLA8Kkv"
      },
      "outputs": [],
      "source": [
        "BASE_PATH = \"/content/drive/MyDrive/NLP/CA5\"\n",
        "TOKENIZED_DATA_PATH = os.path.join(BASE_PATH, \"mbert_tokenized_data\")\n",
        "TRAIN_DATA_PATH = os.path.join(TOKENIZED_DATA_PATH, \"train\")\n",
        "VALID_DATA_PATH = os.path.join(TOKENIZED_DATA_PATH, \"valid\")\n",
        "TEST_DATA_PATH = os.path.join(TOKENIZED_DATA_PATH, \"test\")\n",
        "DATA_DIR_PATH = os.path.join(BASE_PATH, \"mbert_data_dir\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217,
          "referenced_widgets": [
            "defa8a7621ea4993967121114c146499",
            "8eb7bd730bb74276859a4f204dae5d17",
            "808de31f902945a1a38c4b16e3d23ffa",
            "ac32f43e197a4b9fa3ac6e30fa1dfbf1",
            "5e6b9def822d4db68b2b2fe920cfaea3",
            "e6a04155a1754a00a54594e5b097c568",
            "dd6e2e4d5f1a44cd832020c789013689",
            "8d8f9ade5daf4a00a299e76d2124135a",
            "e754850b7c694a63908f4491433e56d4",
            "7325c30853364a96aa55753cf906d97f",
            "6c08a212c54c4e9ba4fa8d54ee357be6",
            "b76965f144aa4191b4e2be4d42b9edb4",
            "87645528668642d0a0ba1996877a9021",
            "6caf71546b404003821ab34cfe3c7269",
            "45705017ebfa4983b4ec1db763b5c0f5",
            "542f393ec78341b28d165a82a500a52c",
            "452a862ab95940b8842727c2d5dc6057",
            "4b26dcf3c290411288eff1c46d9e2b9e",
            "313d098bf2bc40c2bd9c10d3924348fa",
            "423464abe96f4496b66a5b9df9c5c490",
            "dba9c07d97214e8c93cc744a2dd4bb7d",
            "f67c3b2585e04ef2882296ea24b87201",
            "4a12f23d11624a09900e04ba76bb9075",
            "a8e5d2f305fc44cfa8fc8eb79b95125f",
            "15e8f0191ceb43f1a94724333ca3e704",
            "0181b9f8c6df476d9552d95549369995",
            "b4cd50f844754bcdbc5ea08d336daf69",
            "a1587849b4ae41fab74ee9968e6104e1",
            "4d983cf96dcb4e599b01814a472fde4a",
            "e5f2bc91d94a4dc2a7776c807ca1acb8",
            "53e5d0dca7d140c8bd5acb48b387b78c",
            "350df379276b41698d80701c2064da4d",
            "1be4633bb2334ae198e9f016df86c5c5",
            "9765a34ded2f4f2fa626d9e73182fc35",
            "d122dfded5b14f4ab01c433151b10b1f",
            "e9af5a4c6bc3464aa7a0a3ec1f70ee08",
            "b7c1be6541324315bdcce2de748c2e4a",
            "c024f6ba398749c7bf347f468a679f0a",
            "bd5a2b907cc14b9dbb7ad515d6c1c572",
            "1352ba20dce54a39b83ad7fab437aa41",
            "68c5b5b0c9d24310bd8adfa4073f5151",
            "d0fbc9e9d0704f1bbc3b2b0da14758da",
            "e8a614e2f6eb4b2a979670929cb5fb20",
            "a0b10cdf93e04b548c8673be804846ef"
          ]
        },
        "id": "cNHmnkMz8Kkw",
        "outputId": "37e0a054-6a82-4def-b5b9-dfd4c61b39bd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "defa8a7621ea4993967121114c146499"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b76965f144aa4191b4e2be4d42b9edb4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a12f23d11624a09900e04ba76bb9075"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9765a34ded2f4f2fa626d9e73182fc35"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "model = BertModel.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "text = \"This is a test\"\n",
        "encoded_input = tokenizer(text, return_tensors='pt')\n",
        "output = model(**encoded_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "MbRbtIbu8Kkx"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ./data_bin"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!fairseq-preprocess   --joined-dictionary\t --source-lang en --target-lang fa \\\n",
        "  --trainpref {TRAIN_DATA_PATH} \\\n",
        "  --validpref {VALID_DATA_PATH} \\\n",
        "  --testpref {TEST_DATA_PATH} \\\n",
        "  --destdir {DATA_DIR_PATH}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sFCeG3g_RQE",
        "outputId": "cfd79879-fcf8-4607-91a7-3b4fe6876fbb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-10 16:03:30.763421: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-06-10 16:03:33 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2023-06-10 16:03:34 | INFO | fairseq_cli.preprocess | Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='translation', source_lang='en', target_lang='fa', trainpref='/content/drive/MyDrive/NLP/CA5/mbert_tokenized_data/train', validpref='/content/drive/MyDrive/NLP/CA5/mbert_tokenized_data/valid', testpref='/content/drive/MyDrive/NLP/CA5/mbert_tokenized_data/test', align_suffix=None, destdir='/content/drive/MyDrive/NLP/CA5/mbert_data_dir', thresholdtgt=0, thresholdsrc=0, tgtdict=None, srcdict=None, nwordstgt=-1, nwordssrc=-1, alignfile=None, dataset_impl='mmap', joined_dictionary=True, only_source=False, padding_factor=8, workers=1, dict_only=False)\n",
            "2023-06-10 16:05:39 | INFO | fairseq_cli.preprocess | [en] Dictionary: 33216 types\n",
            "2023-06-10 16:08:45 | INFO | fairseq_cli.preprocess | [en] /content/drive/MyDrive/NLP/CA5/mbert_tokenized_data/train.en: 670000 sents, 19387235 tokens, 0.0% replaced (by <unk>)\n",
            "2023-06-10 16:08:45 | INFO | fairseq_cli.preprocess | [en] Dictionary: 33216 types\n",
            "2023-06-10 16:08:46 | INFO | fairseq_cli.preprocess | [en] /content/drive/MyDrive/NLP/CA5/mbert_tokenized_data/valid.en: 4000 sents, 61776 tokens, 0.00809% replaced (by <unk>)\n",
            "2023-06-10 16:08:46 | INFO | fairseq_cli.preprocess | [en] Dictionary: 33216 types\n",
            "2023-06-10 16:08:47 | INFO | fairseq_cli.preprocess | [en] /content/drive/MyDrive/NLP/CA5/mbert_tokenized_data/test.en: 10000 sents, 144836 tokens, 0.0255% replaced (by <unk>)\n",
            "2023-06-10 16:08:47 | INFO | fairseq_cli.preprocess | [fa] Dictionary: 33216 types\n",
            "2023-06-10 16:13:15 | INFO | fairseq_cli.preprocess | [fa] /content/drive/MyDrive/NLP/CA5/mbert_tokenized_data/train.fa: 670000 sents, 25281952 tokens, 0.0% replaced (by <unk>)\n",
            "2023-06-10 16:13:15 | INFO | fairseq_cli.preprocess | [fa] Dictionary: 33216 types\n",
            "2023-06-10 16:13:17 | INFO | fairseq_cli.preprocess | [fa] /content/drive/MyDrive/NLP/CA5/mbert_tokenized_data/valid.fa: 4000 sents, 74139 tokens, 0.00135% replaced (by <unk>)\n",
            "2023-06-10 16:13:17 | INFO | fairseq_cli.preprocess | [fa] Dictionary: 33216 types\n",
            "2023-06-10 16:13:19 | INFO | fairseq_cli.preprocess | [fa] /content/drive/MyDrive/NLP/CA5/mbert_tokenized_data/test.fa: 10000 sents, 167543 tokens, 0.0% replaced (by <unk>)\n",
            "2023-06-10 16:13:19 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /content/drive/MyDrive/NLP/CA5/mbert_data_dir\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(os.path.join(DATA_DIR_PATH, \"dict.en.txt\"), \"r\") as f:\n",
        "    mbert_dict = f.read().splitlines()"
      ],
      "metadata": {
        "id": "HZggQh0CCSOI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(mbert_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3PHHsRiN2aB",
        "outputId": "159356c1-c860-4996-d01e-bf6c34ce24f3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33212"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mbert_dict_normalized = {}\n",
        "for index,item in enumerate(mbert_dict):\n",
        "    if item.split()[1].isdigit():\n",
        "        mbert_dict_normalized[item.split()[0]] = item.split()[1]\n",
        "    else:\n",
        "        mbert_dict_normalized[item.split()[1]] = item.split()[0]"
      ],
      "metadata": {
        "id": "Hu42pEAENtoL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(mbert_dict_normalized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1rw875u7SrB",
        "outputId": "9d7bf8fa-1c1a-418e-b55c-0d58cad00743"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33212"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "subset = dict(random.sample(mbert_dict_normalized.items(),100))\n",
        "chosen_set = mbert_dict_normalized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXBjAByI60Bu",
        "outputId": "ffe53750-a17b-4403-fa04-1dc497e1a64f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-7ea466ab00f6>:2: DeprecationWarning: Sampling from a set deprecated\n",
            "since Python 3.9 and will be removed in a subsequent version.\n",
            "  subset = dict(random.sample(mbert_dict_normalized.items(),100))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(chosen_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwNjG-Dz7DPG",
        "outputId": "4f0f9147-c3d0-4744-b415-e0eec48c8dd8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33212"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mbert_dict_embeddings = {}\n",
        "\n",
        "for key in tqdm(chosen_set.keys()):\n",
        "    encoded = tokenizer.encode(key)\n",
        "    input_ids = torch.tensor([encoded])\n",
        "\n",
        "    with torch.no_grad():\n",
        "      embedding = model(input_ids)[0].mean(1)[0].tolist()\n",
        "\n",
        "    mbert_dict_embeddings[key] = embedding\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uu-aaR36eq5-",
        "outputId": "9182b703-fbb7-441e-dba8-23d75386b1cd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33212/33212 [37:05<00:00, 14.92it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_list = []\n",
        "\n",
        "for key,value in mbert_dict_embeddings.items():\n",
        "  embd = ' '.join([str(x) for x in value])\n",
        "  sample = f\"{key} {embd}\"\n",
        "  final_list.append(sample)"
      ],
      "metadata": {
        "id": "675ObV5B8THP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(os.path.join(\".\",\"mbert_dict_embeddings_new.txt\"), 'w') as f:\n",
        "    f.write(str(len(chosen_set)))\n",
        "    f.write(\" \")\n",
        "    f.write(str(len(list(chosen_set.values())[0])))\n",
        "    f.write(\"\\n\")\n",
        "    f.write(\"\\n\".join(final_list))\n"
      ],
      "metadata": {
        "id": "-cC4KzjCfT5b"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('./mbert_dict_embeddings_new.txt',\"r\") as f:\n",
        "  dummy = f.readlines()"
      ],
      "metadata": {
        "id": "5wfkskpX72x-"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dummy[5924]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "5rz8m42H79Av",
        "outputId": "6229063a-5ca2-41a0-b1aa-65b385272689"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Who -0.2196490615606308 -0.17202764749526978 1.3276394605636597 0.326817125082016 -0.939431369304657 0.06769527494907379 -0.34497570991516113 -0.42862558364868164 0.08538702875375748 0.14544257521629333 0.32078075408935547 0.24572698771953583 0.7457945942878723 -0.28421273827552795 -0.4417015314102173 -0.5618670582771301 -0.6064625382423401 1.151857852935791 -0.13414651155471802 -0.004638587590306997 0.1602405309677124 0.1520642191171646 -0.6476603150367737 0.1911998838186264 0.48194265365600586 0.0634564757347107 -0.5599460601806641 0.4333358705043793 0.08870700746774673 -0.462372750043869 0.02980154938995838 -0.15479086339473724 0.04918955639004707 0.19831854104995728 0.006706899497658014 0.027898654341697693 -0.7261903285980225 0.028216667473316193 0.29348206520080566 -0.5757322311401367 -0.49874162673950195 0.14376090466976166 -0.09991160780191422 0.29301905632019043 0.2846504747867584 0.16636912524700165 0.06830549985170364 0.04867468401789665 -0.02325158379971981 -0.6290936470031738 0.3945704400539398 -0.40710124373435974 0.1977875828742981 -0.1868736743927002 -0.5084800720214844 -0.05376178398728371 0.074239581823349 -0.7314569354057312 0.24260850250720978 0.3735944330692291 0.2969914972782135 0.15192252397537231 0.24482333660125732 -0.02183298021554947 -0.6505122184753418 0.2493920773267746 -0.36487770080566406 0.3971163332462311 -0.40839624404907227 0.058345481753349304 0.4694375991821289 -0.2783476412296295 0.5115343928337097 0.34632158279418945 -0.03337462246417999 -0.13483107089996338 0.9244624972343445 0.21343021094799042 -0.3145703375339508 -0.02699861116707325 -0.17337483167648315 0.4036984443664551 -0.49030089378356934 0.16652552783489227 0.27779054641723633 0.10657287389039993 0.4793509244918823 0.13131572306156158 -0.15778978168964386 -0.7367973327636719 -0.4088972508907318 -0.3374582827091217 -0.33360645174980164 0.2173147201538086 -0.7763182520866394 0.5273432731628418 0.09003347903490067 0.6555390357971191 0.2623952329158783 0.14256398379802704 -0.17453402280807495 0.5464896559715271 -0.5804033875465393 -0.15356449782848358 -0.2235269546508789 0.2891819179058075 0.044624149799346924 0.23827512562274933 0.25273045897483826 0.8495389819145203 0.21911431849002838 -0.032431717962026596 0.472285658121109 -0.0180191770195961 0.15878093242645264 -0.45323845744132996 -0.5575859546661377 -1.0548686981201172 -0.0737588107585907 -0.25859391689300537 0.12746858596801758 -0.04730026051402092 0.20047104358673096 -0.2630143165588379 0.3209548890590668 -0.17530472576618195 0.4396041929721832 -0.338334321975708 0.6728584170341492 0.5978474020957947 0.2088521271944046 0.6244021654129028 0.38775110244750977 0.15313027799129486 0.40198907256126404 0.24097640812397003 1.0861176252365112 0.3223018944263458 0.17199306190013885 0.6721035838127136 -0.6242164969444275 0.8152846693992615 -0.9242638945579529 -0.9470951557159424 -0.42085304856300354 0.0019961532671004534 -0.6174556612968445 0.8161544799804688 -0.4526239335536957 0.536001980304718 0.2038239985704422 -0.7547388076782227 0.2588312327861786 0.29819679260253906 0.014847338199615479 0.5061168670654297 0.012113492004573345 -0.3035806119441986 0.6148849129676819 0.34560561180114746 0.6179496645927429 -0.3870573937892914 0.3713189363479614 1.3126684427261353 0.06147469952702522 -0.43732723593711853 -0.4136338233947754 -0.14352606236934662 -0.7938811779022217 0.14037226140499115 -0.35218027234077454 0.33671239018440247 0.43077516555786133 -0.0078092762269079685 -0.2179383486509323 -0.5760498046875 0.0052850134670734406 0.19338904321193695 -0.16802377998828888 0.16288593411445618 0.03905479609966278 0.8506906032562256 -0.3573583662509918 0.2944214642047882 0.2910173833370209 -0.042624205350875854 0.00798193272203207 -0.5900131464004517 -0.5755389928817749 0.41978129744529724 0.2754201591014862 0.17432481050491333 -0.132803812623024 0.13272424042224884 0.0982874259352684 0.5558454394340515 -0.1506684422492981 -0.3779996335506439 -0.295552521944046 -0.174347922205925 -0.28647997975349426 0.43422284722328186 0.21635454893112183 -0.3559468984603882 -0.46467137336730957 1.2680431604385376 0.003963363356888294 -0.5479278564453125 0.3525244891643524 0.23053736984729767 -0.3305835425853729 0.32483580708503723 0.30754682421684265 0.519416332244873 -0.1675754189491272 0.16605331003665924 -0.01856681890785694 0.11034741997718811 0.10265475511550903 -0.6489788293838501 0.3621249496936798 0.16052107512950897 -0.39303407073020935 -0.2840568721294403 -0.9991083741188049 -0.3241572380065918 -0.34231364727020264 0.09470203518867493 0.6267514824867249 -0.2260037660598755 0.10751499980688095 -0.48477253317832947 0.02917959727346897 -0.35233449935913086 -0.10649140924215317 -0.02986445464193821 0.22573137283325195 -0.4276510179042816 -0.5007182955741882 0.13968218863010406 0.33295050263404846 0.5606369376182556 0.2400447577238083 0.10945677012205124 0.33262765407562256 -0.07397982478141785 -0.3395176827907562 0.03831281140446663 -0.0007668609614484012 -0.6236241459846497 0.0704679861664772 0.46822336316108704 0.06552273780107498 -0.19662503898143768 -0.1319923996925354 0.37177029252052307 0.0574154295027256 0.16784925758838654 0.8993377089500427 0.07358206808567047 0.22722460329532623 -1.1170557737350464 -0.6775352358818054 0.4064207375049591 -0.23933176696300507 -0.555850088596344 0.27051791548728943 -0.0034376971889287233 0.07043448835611343 -0.30307015776634216 0.18727703392505646 0.09587510675191879 0.16723251342773438 -0.11842115968465805 0.05356261506676674 0.14949113130569458 0.16777680814266205 0.4417777955532074 -0.13552777469158173 0.11749041825532913 -0.07690124958753586 -0.033410023897886276 -0.030967535451054573 0.8807843327522278 -0.1405325084924698 -0.26715773344039917 0.2896648347377777 -0.15556730329990387 0.6273675560951233 -0.12926264107227325 -0.18576501309871674 -0.016016433015465736 -0.31764674186706543 0.2659805119037628 0.024995505809783936 0.07562334090471268 0.3215768039226532 -0.05829950049519539 0.4619051516056061 -0.03998488560318947 0.6527504324913025 0.8175539970397949 -0.3414112627506256 0.06794005632400513 -0.6363732218742371 0.4423160254955292 -0.3006841838359833 0.010453646071255207 0.7959300875663757 0.9588923454284668 -0.5609785914421082 -0.5423743724822998 -0.3829110860824585 -0.3480219841003418 -0.7150571346282959 0.47847771644592285 -0.0155388368293643 0.6285884380340576 -0.29409343004226685 0.06616126000881195 -0.6110181212425232 0.02387409470975399 -0.5369710326194763 -0.20293734967708588 0.36910009384155273 0.035856589674949646 -0.31834566593170166 -0.2816743552684784 0.14378228783607483 -0.09028225392103195 0.39014914631843567 1.9540268182754517 -0.1397770792245865 -0.2794125974178314 0.2010972946882248 -0.11160216480493546 -0.2733270823955536 -0.20893490314483643 -0.4309111535549164 0.006698252633213997 0.27912405133247375 -0.18111908435821533 0.23922686278820038 -0.23186226189136505 -0.026989808306097984 -0.058294106274843216 -0.10972782224416733 0.2911648452281952 -0.19837965071201324 0.3234926462173462 0.7071433067321777 0.2803305983543396 -0.4041099548339844 0.05087592080235481 0.21248452365398407 0.30855992436408997 -0.2273261696100235 0.4605471193790436 -0.3333633840084076 0.38402652740478516 -0.20709331333637238 0.17863744497299194 0.08331458270549774 0.023097360506653786 -0.5725440979003906 -0.14861640334129333 0.3211571276187897 -0.1152590811252594 -0.021129518747329712 0.6673688888549805 0.535095751285553 1.400793433189392 -0.09373801946640015 -0.3072061836719513 -0.2038925141096115 0.0060903350822627544 -0.13354206085205078 -0.0849652886390686 0.5921022295951843 0.036795955151319504 0.723789393901825 0.0018080236623063684 -0.7632798552513123 0.40474310517311096 0.17222803831100464 -0.43582746386528015 -0.536407470703125 -0.038662925362586975 -0.23379260301589966 -0.0006125022773630917 -0.30276039242744446 -0.0593748576939106 -0.08602573722600937 0.6534421443939209 -0.5200647711753845 0.08398324251174927 -0.27816247940063477 -0.02290070801973343 -0.4603920876979828 -0.03845599666237831 -0.14086586236953735 -0.03348953649401665 -0.17037372291088104 0.6933820843696594 0.36360499262809753 -0.15280555188655853 -0.4319976270198822 -0.036586057394742966 -0.3039276897907257 -0.5260655879974365 -0.4380981922149658 0.06405667960643768 0.11070581525564194 0.32748377323150635 0.15011635422706604 0.8259080052375793 -1.2037795782089233 0.15523426234722137 0.31115612387657166 0.01783389411866665 0.24344205856323242 -0.3577679693698883 -0.1654372364282608 -0.4424706995487213 -0.08748161792755127 -0.06536311656236649 0.9044545292854309 -0.2106747180223465 0.3853336274623871 -0.200449600815773 -0.4865288734436035 0.6247862577438354 0.3780531883239746 -0.2802121937274933 -0.4067382514476776 -0.6256968379020691 -0.2667844593524933 0.07374179363250732 0.09194234758615494 0.2664487957954407 0.40380504727363586 0.3277339041233063 0.02309596538543701 -0.05910691246390343 -0.4776882827281952 0.8733142018318176 0.28104454278945923 0.1726415902376175 0.015143990516662598 0.3132387399673462 0.015206568874418736 -0.7479734420776367 -0.3068734109401703 -0.5448298454284668 0.5646467208862305 -0.03334452584385872 -0.30582287907600403 -0.2239288091659546 0.016996944323182106 0.17884357273578644 0.014034916646778584 -0.246860072016716 0.2972387969493866 0.4109424650669098 0.1857791543006897 -0.4876287877559662 -0.046825483441352844 -0.2262066751718521 -0.33874988555908203 0.0718720480799675 0.2908278703689575 0.0715336948633194 0.14557060599327087 0.3133779764175415 -1.1414422988891602 -0.36894989013671875 0.3753138482570648 0.5074304938316345 -0.2203701138496399 -0.8359982967376709 0.16399382054805756 -0.08790703862905502 0.07182986289262772 -0.5556814670562744 -0.09622979164123535 -0.08952802419662476 0.2862338125705719 0.24077843129634857 -0.4821414649486542 -0.05332411453127861 0.13401289284229279 0.1317226141691208 -0.022984057664871216 -0.19115464389324188 -0.7912359237670898 0.09971127659082413 0.15017427504062653 -0.14705084264278412 0.39489975571632385 0.32305705547332764 0.11253071576356888 0.4673813283443451 0.3869406282901764 0.005544786807149649 0.33781060576438904 -0.6895965933799744 -0.3207355737686157 0.08777425438165665 -0.5420116782188416 -0.3084719181060791 0.16391165554523468 -0.20162944495677948 0.3680539131164551 -0.462497353553772 0.11725926399230957 -0.06089429557323456 -0.054409127682447433 -0.3412587642669678 -0.052262838929891586 0.26576516032218933 -0.548306405544281 0.7550196051597595 -0.04796579107642174 -0.42955517768859863 -0.3690437972545624 -8.021792018553242e-05 0.23955774307250977 -0.553016185760498 -0.1031433716416359 -0.4121302664279938 -0.5463952422142029 -0.02095610462129116 -0.11951329559087753 0.05106375738978386 0.5147860646247864 0.048213135451078415 -0.12231170386075974 -0.3039189875125885 -0.7885844111442566 -0.20723581314086914 -0.37045326828956604 -0.08610180765390396 0.31109264492988586 0.1564594954252243 0.5723382234573364 0.336694598197937 -0.5093528628349304 0.43213072419166565 0.6204399466514587 -0.11728674173355103 -0.06945469230413437 -0.11066585779190063 0.8362434506416321 -0.34917208552360535 -0.2514722943305969 0.1540399044752121 0.3290025293827057 -0.02197182923555374 -0.25138765573501587 0.0898028016090393 0.0787309855222702 -0.42839285731315613 -0.09118908643722534 -0.11128741502761841 -0.254557728767395 -0.07016440480947495 -0.27052369713783264 0.9041547775268555 0.5867473483085632 0.5819873213768005 0.5327309966087341 0.8028362393379211 -0.3059421181678772 0.4074687063694 0.3461417257785797 -0.1091156005859375 -0.4035625755786896 -0.38838398456573486 0.29197487235069275 -0.5302877426147461 0.5036282539367676 -0.27322858572006226 -0.2641339898109436 -0.035894833505153656 -0.1670473963022232 0.49192094802856445 -0.10425511002540588 0.5829864144325256 0.31208327412605286 -0.31804946064949036 0.0030303376261144876 -0.25113022327423096 0.43655893206596375 -0.02685740403831005 0.27180197834968567 0.21377362310886383 0.4128738343715668 -0.5975354313850403 -0.26974985003471375 0.17282937467098236 0.4230286777019501 -0.32520413398742676 0.35875561833381653 -0.37349727749824524 -0.19673125445842743 0.14364047348499298 0.07961108535528183 0.2525019943714142 -0.9009332656860352 0.23455119132995605 -0.04499785229563713 -0.41972675919532776 -0.5770580172538757 0.4141513407230377 0.038543760776519775 -0.7937378883361816 -0.5265113711357117 -0.6002816557884216 -0.21147553622722626 -0.3377366364002228 0.7015082240104675 0.8352230191230774 -0.1431804746389389 -0.5712697505950928 -0.05630098655819893 0.11710204929113388 0.050671160221099854 -0.7802601456642151 -0.6353289484977722 -0.14986306428909302 -0.06799458712339401 -0.00721116503700614 0.3662525713443756 -0.4063583314418793 -0.027777308598160744 -0.06233837082982063 -0.6632199287414551 -0.21149472892284393 -0.5017289519309998 -0.17812462151050568 0.0900503620505333 -0.20416484773159027 -0.8937686085700989 -0.2864737808704376 0.34914711117744446 -0.08030571788549423 -0.549103319644928 0.22855614125728607 -0.7651947140693665 0.27521154284477234 0.1648823767900467 -0.12609615921974182 -0.024679794907569885 -0.11888650804758072 -0.14362666010856628 0.15644267201423645 -0.04571884870529175 -0.15041370689868927 -0.3726264238357544 0.3019624948501587 0.5015504956245422 -0.04560608044266701 -0.7854554057121277 0.0542009063065052 -0.805576503276825 -0.100344218313694 -0.21211504936218262 -0.11675993353128433 0.7787865996360779 -0.4799598455429077 0.4847981929779053 0.14298413693904877 0.2613012492656708 0.23766718804836273 0.04489865526556969 -0.17386913299560547 0.09477058798074722 0.6187238693237305 0.13686704635620117 -0.3371809720993042 -0.08306976407766342 0.5031527876853943 -0.18372498452663422 -0.10125076770782471 0.0007016921299509704 0.634661853313446 -0.0645342469215393 -0.11973194032907486 -0.06400642544031143 0.3081003725528717 0.34473171830177307 0.4279398024082184 0.28676244616508484 0.16500698029994965 -0.2504750192165375 0.048281509429216385 0.43695148825645447 0.5224184989929199 -0.2350536435842514 -0.17817001044750214 -0.3984074890613556 -0.5986976027488708 0.5654842853546143 0.507597029209137 -0.5216763019561768 -0.4398404657840729 0.7913443446159363 -0.015396197326481342 0.3187549114227295 0.3975409269332886 -0.0008692058618180454 0.3727298080921173 -0.5284428596496582 -0.8245368003845215 -0.49335336685180664 0.12254851311445236 -0.22055768966674805 -0.8793931603431702 -0.15534618496894836 0.47194480895996094 1.0010271072387695 0.42150604724884033 -0.5445759296417236 -0.027954859659075737 0.3034283220767975 0.46263644099235535 -0.429953932762146 0.09843309968709946 -0.46793341636657715 -0.016033386811614037 -0.158283531665802 -1.4957036972045898 0.679771900177002 0.2813399136066437 0.0842551663517952 0.1623390167951584 0.4358038008213043 0.15108250081539154 -0.07454660534858704 0.4181447923183441 0.004191294312477112 -0.6688709259033203 -0.7379514575004578 0.2780928611755371 0.3092769384384155 0.05653237923979759 -0.37721335887908936 -0.2947339713573456 -0.8437142968177795 -0.037540048360824585 -0.11952954530715942 -0.394052118062973 -0.18265275657176971 0.1366938203573227 0.12454075366258621 0.48935166001319885 0.162412628531456 -0.004155866801738739 -0.0921127200126648 0.18308846652507782 -0.5402131080627441 -0.3832428455352783 0.6633828282356262 0.23835521936416626 0.14875246584415436 0.48213574290275574 0.102008156478405 -0.10587114840745926\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!fairseq-train \\\n",
        "  /content/drive/MyDrive/NLP/CA5/mbert_data_dir \\\n",
        "  --arch lstm --share-decoder-input-output-embed --share-all-embeddings --encoder-embed-dim 768 --decoder-embed-dim 768 --decoder-out-embed-dim 768 --encoder-embed-path /content/mbert_dict_embeddings_new.txt   \\\n",
        "  --optimizer adam --adam-betas '(0.9,0.98)' --clip-norm 0.0 \\\n",
        "  --lr 2.5e-3 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\n",
        "  --dropout 0.25 --weight-decay 0.0001 \\\n",
        "  --criterion label_smoothed_cross_entropy --label-smoothing 0.2 \\\n",
        "  --max-tokens 4096 \\\n",
        "  --eval-bleu \\\n",
        "  --eval-bleu-args '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}' \\\n",
        "  --eval-bleu-detok moses \\\n",
        "  --eval-bleu-print-samples \\\n",
        "  --best-checkpoint-metric bleu --maximize-best-checkpoint-metric \\\n",
        "  --fp16 --memory-efficient-fp16 \\\n",
        "  --max-epoch 5 \\\n",
        "  --save-dir ./content/drive/MyDrive/mbert/checkpoints/ \\\n",
        "  --tensorboard-logdir ./content/drive/MyDrive/mbert/log/\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttxRxeqF2Y9i",
        "outputId": "05db3690-cea3-408a-eb93-4a0b2ed5d56a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-11 09:34:29.439029: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-06-11 09:34:30 | INFO | numexpr.utils | NumExpr defaulting to 2 threads.\n",
            "2023-06-11 09:34:31 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2023-06-11 09:34:33 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './content/drive/MyDrive/mbert/log/', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': True, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': True, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4096, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4096, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 5, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0025], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './content/drive/MyDrive/mbert/checkpoints/', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir='./content/drive/MyDrive/mbert/log/', wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=True, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', scoring='bleu', task='translation', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4096, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=4096, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='lstm', max_epoch=5, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.0025], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='./content/drive/MyDrive/mbert/checkpoints/', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='bleu', maximize_best_checkpoint_metric=True, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, share_decoder_input_output_embed=True, share_all_embeddings=True, data='/content/drive/MyDrive/NLP/CA5/mbert_data_dir', source_lang=None, target_lang=None, load_alignments=False, left_pad_source=True, left_pad_target=False, max_source_positions=1024, max_target_positions=1024, upsample_primary=-1, truncate_source=False, num_batch_buckets=0, eval_bleu=True, eval_bleu_args='{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_tokenized_bleu=False, eval_bleu_remove_bpe=None, eval_bleu_print_samples=True, label_smoothing=0.2, report_accuracy=False, ignore_prefix_size=0, adam_betas='(0.9,0.98)', adam_eps=1e-08, weight_decay=0.0001, use_old_adam=False, fp16_adam_stats=False, warmup_updates=4000, warmup_init_lr=-1, pad=1, eos=2, unk=3, encoder_embed_dim=768, decoder_embed_dim=768, decoder_out_embed_dim=768, encoder_embed_path='/content/mbert_dict_embeddings_new.txt', dropout=0.25, no_seed_provided=False, encoder_freeze_embed=False, encoder_hidden_size=768, encoder_layers=1, encoder_bidirectional=False, encoder_dropout_in=0.25, encoder_dropout_out=0.25, decoder_embed_path=None, decoder_freeze_embed=False, decoder_hidden_size=768, decoder_layers=1, decoder_attention='1', decoder_dropout_in=0.25, decoder_dropout_out=0.25, adaptive_softmax_cutoff='10000,50000,200000', _name='lstm'), 'task': {'_name': 'translation', 'data': '/content/drive/MyDrive/NLP/CA5/mbert_data_dir', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.2, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0025]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0025]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
            "2023-06-11 09:34:33 | INFO | fairseq.tasks.translation | [en] dictionary: 33216 types\n",
            "2023-06-11 09:34:33 | INFO | fairseq.tasks.translation | [fa] dictionary: 33216 types\n",
            "2023-06-11 09:34:47 | INFO | fairseq.utils | found 33212/33216 types in embedding file\n",
            "2023-06-11 09:34:48 | INFO | fairseq_cli.train | LSTMModel(\n",
            "  (encoder): LSTMEncoder(\n",
            "    (dropout_in_module): FairseqDropout()\n",
            "    (dropout_out_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(33216, 768, padding_idx=1)\n",
            "    (lstm): LSTM(768, 768)\n",
            "  )\n",
            "  (decoder): LSTMDecoder(\n",
            "    (dropout_in_module): FairseqDropout()\n",
            "    (dropout_out_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(33216, 768, padding_idx=1)\n",
            "    (layers): ModuleList(\n",
            "      (0): LSTMCell(1536, 768)\n",
            "    )\n",
            "    (attention): AttentionLayer(\n",
            "      (input_proj): Linear(in_features=768, out_features=768, bias=False)\n",
            "      (output_proj): Linear(in_features=1536, out_features=768, bias=False)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "2023-06-11 09:34:48 | INFO | fairseq_cli.train | task: TranslationTask\n",
            "2023-06-11 09:34:48 | INFO | fairseq_cli.train | model: LSTMModel\n",
            "2023-06-11 09:34:48 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion\n",
            "2023-06-11 09:34:48 | INFO | fairseq_cli.train | num. shared model params: 39,088,128 (num. trained: 39,088,128)\n",
            "2023-06-11 09:34:48 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2023-06-11 09:34:48 | INFO | fairseq.data.data_utils | loaded 4,000 examples from: /content/drive/MyDrive/NLP/CA5/mbert_data_dir/valid.en-fa.en\n",
            "2023-06-11 09:34:49 | INFO | fairseq.data.data_utils | loaded 4,000 examples from: /content/drive/MyDrive/NLP/CA5/mbert_data_dir/valid.en-fa.fa\n",
            "2023-06-11 09:34:49 | INFO | fairseq.tasks.translation | /content/drive/MyDrive/NLP/CA5/mbert_data_dir valid en-fa 4000 examples\n",
            "2023-06-11 09:34:59 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight\n",
            "2023-06-11 09:34:59 | INFO | fairseq.trainer | detected shared parameter: decoder.attention.input_proj.bias <- decoder.attention.output_proj.bias\n",
            "2023-06-11 09:34:59 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2023-06-11 09:34:59 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 14.748 GB ; name = Tesla T4                                \n",
            "2023-06-11 09:34:59 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2023-06-11 09:34:59 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2023-06-11 09:34:59 | INFO | fairseq_cli.train | max tokens per device = 4096 and max sentences per device = None\n",
            "2023-06-11 09:34:59 | INFO | fairseq.trainer | Preparing to load checkpoint ./content/drive/MyDrive/mbert/checkpoints/checkpoint_last.pt\n",
            "2023-06-11 09:34:59 | INFO | fairseq.trainer | No existing checkpoint found ./content/drive/MyDrive/mbert/checkpoints/checkpoint_last.pt\n",
            "2023-06-11 09:34:59 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2023-06-11 09:35:00 | INFO | fairseq.data.data_utils | loaded 670,000 examples from: /content/drive/MyDrive/NLP/CA5/mbert_data_dir/train.en-fa.en\n",
            "2023-06-11 09:35:01 | INFO | fairseq.data.data_utils | loaded 670,000 examples from: /content/drive/MyDrive/NLP/CA5/mbert_data_dir/train.en-fa.fa\n",
            "2023-06-11 09:35:01 | INFO | fairseq.tasks.translation | /content/drive/MyDrive/NLP/CA5/mbert_data_dir train en-fa 670000 examples\n",
            "2023-06-11 09:35:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6648\n",
            "epoch 001:   0% 0/6648 [00:00<?, ?it/s]2023-06-11 09:35:02 | INFO | fairseq.trainer | begin training epoch 1\n",
            "2023-06-11 09:35:02 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "/usr/local/lib/python3.10/dist-packages/fairseq/utils.py:374: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library\n",
            "  warnings.warn(\n",
            "2023-06-11 09:35:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0\n",
            "epoch 001:   0% 1/6648 [00:01<2:46:00,  1.50s/it]2023-06-11 09:35:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0\n",
            "epoch 001:   0% 2/6648 [00:01<1:22:35,  1.34it/s]2023-06-11 09:35:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0\n",
            "epoch 001:   0% 3/6648 [00:01<51:51,  2.14it/s]  2023-06-11 09:35:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0\n",
            "epoch 001:   0% 6/6648 [00:02<32:42,  3.38it/s]2023-06-11 09:35:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0\n",
            "epoch 001: 100% 6647/6648 [17:57<00:00,  5.18it/s, loss=6.596, nll_loss=3.76, ppl=13.55, wps=23551, ups=6.17, wpb=3819.8, bsz=102.4, num_updates=6600, lr=0.00194625, gnorm=0.35, loss_scale=4, train_wall=16, gb_free=12.9, wall=1073]2023-06-11 09:52:59 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:   0% 0/29 [00:00<?, ?it/s]\u001b[A2023-06-11 09:53:00 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] [SEP]\n",
            "2023-06-11 09:53:00 | INFO | fairseq.tasks.translation | example reference: [CLS] خدا ##حافظ, [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:   3% 1/29 [00:00<00:23,  1.17it/s]\u001b[A2023-06-11 09:53:01 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] خوب است? [SEP]\n",
            "2023-06-11 09:53:01 | INFO | fairseq.tasks.translation | example reference: [CLS] آیا آن خوب است? [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:   7% 2/29 [00:01<00:21,  1.24it/s]\u001b[A2023-06-11 09:53:02 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"احمد یک بار, [SEP]\n",
            "2023-06-11 09:53:02 | INFO | fairseq.tasks.translation | example reference: [CLS] او ##ه زمان را گرفت ##م, [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  10% 3/29 [00:02<00:24,  1.04it/s]\u001b[A2023-06-11 09:53:03 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] این ##جا در این ##جا خوب است. [SEP]\n",
            "2023-06-11 09:53:03 | INFO | fairseq.tasks.translation | example reference: [CLS] در این ##جا ظهر خوب خواهد بود. [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  14% 4/29 [00:03<00:22,  1.13it/s]\u001b[A2023-06-11 09:53:03 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] پس ما جمع ##ه ه ##شت ##م ه ##شت ##م را خ ##وا ##هیم داشت [SEP]\n",
            "2023-06-11 09:53:03 | INFO | fairseq.tasks.translation | example reference: [CLS] پس شد جمع ##ه ه ##شت ##م, [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  17% 5/29 [00:04<00:19,  1.23it/s]\u001b[A2023-06-11 09:53:04 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"\" \"\" [SEP]\n",
            "2023-06-11 09:53:04 | INFO | fairseq.tasks.translation | example reference: [CLS] چه چیزی برای شما مناسب است, [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  21% 6/29 [00:04<00:18,  1.27it/s]\u001b[A2023-06-11 09:53:05 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] خدا ##وند هر جمع ##ه خوب است. [SEP]\n",
            "2023-06-11 09:53:05 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##ه, خدا, هر جمع ##ه - ای خوب است. [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  24% 7/29 [00:05<00:17,  1.26it/s]\u001b[A2023-06-11 09:53:05 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] ال ##ه, شما را می ##بین ##ید, [SEP]\n",
            "2023-06-11 09:53:05 | INFO | fairseq.tasks.translation | example reference: [CLS] بسیار خوب, به ام ##ید دید ##ار, خدا ##حافظ, [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  28% 8/29 [00:06<00:14,  1.45it/s]\u001b[A2023-06-11 09:53:06 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] ولی بعد از ظهر بیست و دوم, [SEP]\n",
            "2023-06-11 09:53:06 | INFO | fairseq.tasks.translation | example reference: [CLS] اما, آ ##ه بعد ##از ##ظهر بیست و دوم, [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  31% 9/29 [00:06<00:12,  1.55it/s]\u001b[A2023-06-11 09:53:06 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] و نو ##زدهم وقت ##م آزاد ه ##ست ##م, [SEP]\n",
            "2023-06-11 09:53:06 | INFO | fairseq.tasks.translation | example reference: [CLS] و نو ##زدهم نیز تا ساعت چهار آزاد ه ##ست ##م. [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  34% 10/29 [00:07<00:11,  1.64it/s]\u001b[A2023-06-11 09:53:07 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] روز سه ش ##ن ##به بعد از دو ##از ##دهم, [SEP]\n",
            "2023-06-11 09:53:07 | INFO | fairseq.tasks.translation | example reference: [CLS] سه - ش ##ن ##به, هر زمانی بعد از دو ##از ##ده مناسب خواهد بود, [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  38% 11/29 [00:07<00:10,  1.70it/s]\u001b[A2023-06-11 09:53:07 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] بل ##ه, اگر من به دفتر ##تان ب ##پر ##سی ##د. [SEP]\n",
            "2023-06-11 09:53:07 | INFO | fairseq.tasks.translation | example reference: [CLS] بل ##ه, این خوب است اگر من به دفتر شما بی ##ای ##م. [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  41% 12/29 [00:08<00:09,  1.83it/s]\u001b[A2023-06-11 09:53:08 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"\" \"\" \"\" [SEP]\n",
            "2023-06-11 09:53:08 | INFO | fairseq.tasks.translation | example reference: [CLS] من از سه تا چهار و ن ##یم ج ##لس ##ه دار ##م, [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  45% 13/29 [00:08<00:08,  1.85it/s]\u001b[A2023-06-11 09:53:09 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] در چند هفت ##ه آ ##ینده در چند هفت ##ه آ ##ینده است? [SEP]\n",
            "2023-06-11 09:53:09 | INFO | fairseq.tasks.translation | example reference: [CLS] زمانی در دو هفت ##هی آ ##ینده وجود دارد که شما آزاد با ##شی? [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  48% 14/29 [00:09<00:08,  1.84it/s]\u001b[A2023-06-11 09:53:09 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] من از سی ت سی. [SEP]\n",
            "2023-06-11 09:53:09 | INFO | fairseq.tasks.translation | example reference: [CLS] من از سی ##م تا سوم خارج از شهر ه ##ست ##م. [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  52% 15/29 [00:09<00:07,  1.85it/s]\u001b[A2023-06-11 09:53:10 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] این هفت ##ه پس از هفت ##ه نو ##زدهم? [SEP]\n",
            "2023-06-11 09:53:10 | INFO | fairseq.tasks.translation | example reference: [CLS] او ##ه در مورد هفت ##ه - ی بعد از آن چ ##طور است. هفت ##ه - ی نو ##زدهم? [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  55% 16/29 [00:10<00:07,  1.80it/s]\u001b[A2023-06-11 09:53:10 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] یا ه ##ف ##دهم یا بیست و ه ##ف ##دهم خوب است. \"[SEP]\n",
            "2023-06-11 09:53:10 | INFO | fairseq.tasks.translation | example reference: [CLS] هر دو ##ی ه ##ف ##دهم, یا بیست و چهارم خوب خ ##وا ##هن ##د بود, او ##ه ##وم, [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  59% 17/29 [00:11<00:06,  1.80it/s]\u001b[A2023-06-11 09:53:11 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"\" \"\" \"\" \"\" \"\" \"\" [SEP]\n",
            "2023-06-11 09:53:11 | INFO | fairseq.tasks.translation | example reference: [CLS] او ##م تمام این هفت ##ه ب ##د است. برنامه شما در هفت ##ه آ ##ینده چ ##گونه است. [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  62% 18/29 [00:11<00:05,  1.87it/s]\u001b[A2023-06-11 09:53:11 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] با ##ش ##ه, باید ب ##گو ##یی ##م که دو ##شن ##به, دو ##شن ##به ه ##شت ##م? [SEP]\n",
            "2023-06-11 09:53:11 | INFO | fairseq.tasks.translation | example reference: [CLS] باشد, میتوان ##یم ب ##گو ##یی ##م دو تا چهار? روز دو ##شن ##به, ه ##شت ##م? [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  66% 19/29 [00:12<00:05,  1.87it/s]\u001b[A2023-06-11 09:53:12 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] او گفت: \"بل ##ه, ج ##هن ##م را برای من ا ##ع ##طا میکند.\" [SEP]\n",
            "2023-06-11 09:53:12 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##ه بل ##ه, س ##لام من را به خان ##م ایک ##س با ح ##روف کوچک بر ##سان. ام, [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  69% 20/29 [00:12<00:04,  1.86it/s]\u001b[A2023-06-11 09:53:12 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] در صورت ##ی که من یک ساعت برای ن ##اه ##ار بود ##م, یک ساعت خوب است, [SEP]\n",
            "2023-06-11 09:53:12 | INFO | fairseq.tasks.translation | example reference: [CLS] بنابراین اگر من ساعت ##ی را برای ن ##اه ##ار داشته با ##شم, ساعت یک برای من خوب خواهد بود, [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  72% 21/29 [00:13<00:04,  1.91it/s]\u001b[A2023-06-11 09:53:13 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] من میتوان ##ید شما را با شما مل ##اقات ک ##ن ##م, اما شما می ##خ ##وا ##هی ##د در لیگ کوچک ##ی با من مل ##اقات ک ##ن ##م. [SEP]\n",
            "2023-06-11 09:53:13 | INFO | fairseq.tasks.translation | example reference: [CLS] من شما را ساعت دو می ##بین ##م, اما باید هم ##دی ##گر را در پارک لیگ کوچک ب ##بین ##یم. [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  76% 22/29 [00:13<00:03,  1.97it/s]\u001b[A2023-06-11 09:53:13 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] خ ##یلی خ ##یلی, پنج ##شن ##به, و چهار ##شن ##به بیست و نه ##م, [SEP]\n",
            "2023-06-11 09:53:13 | INFO | fairseq.tasks.translation | example reference: [CLS] ام خ ##یلی زیاد سه - ش ##ن ##به سی - ام و چهار ##شن ##به بیست و نه ##م پر هستند. [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  79% 23/29 [00:14<00:03,  1.95it/s]\u001b[A2023-06-11 09:53:14 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"احمد چ ##طور از چهار ##دهم یا ه ##ف ##دهم یا ه ##ف ##دهم یا ه ##ف ##دهم یا ه ##ف ##دهم یا ه ##ف ##دهم یا ه ##ف ##دهم? [SEP]\n",
            "2023-06-11 09:53:14 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##ه چهار ##دهم یا ه ##ف ##دهم چه ##طور. آیا هیچ ##ک ##دام از آن دو روز, با برنامه ##ریزی شما مناسب است? [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  83% 24/29 [00:14<00:02,  1.91it/s]\u001b[A2023-06-11 09:53:14 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] چهار ##شن ##به برای من خ ##وا ##هن ##د بود. [SEP]\n",
            "2023-06-11 09:53:14 | INFO | fairseq.tasks.translation | example reference: [CLS] من چهار ##شن ##به کامل ##ا آزاد ه ##ست ##م, اگر برای شما مناسب است, عالی است, [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  86% 25/29 [00:15<00:02,  1.87it/s]\u001b[A2023-06-11 09:53:15 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] بل ##ه, مثل \"احمد ##ی\", در روز پنج ##شن ##به, من ن ##می ##دان ##م که در عصر ه ##شت ##م خوب است. [SEP]\n",
            "2023-06-11 09:53:15 | INFO | fairseq.tasks.translation | example reference: [CLS] بل ##ه, مثل, ن ##می ##دان ##م, هر زمان ##ن از بعد از ظهر پنج ##شن ##به ه ##شت ##م برای من مناسب است. [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  90% 26/29 [00:15<00:01,  1.84it/s]\u001b[A2023-06-11 09:53:16 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] من یک س ##مین ##ار را دار ##م که بیست و هفت ##م, یک روز کامل ##ا آزاد نیست ##م. [SEP]\n",
            "2023-06-11 09:53:16 | INFO | fairseq.tasks.translation | example reference: [CLS] من در تمام روز بیست - و هفت ##م یک س ##مین ##ار دار ##م. آن روز ##ی است که در آن هفت ##ه, من به - طور کامل آزاد نیست ##م. [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  93% 27/29 [00:16<00:01,  1.68it/s]\u001b[A2023-06-11 09:53:16 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"احمد ##ی\" خ ##یلی خوب است که ممکن است احتمال ##ا ش ##اید ش ##اید ش ##اید ش ##اید ش ##اید ش ##اید ش ##اید ش ##اید در میدان و ##رزش ##ی, و در ##بار ##ه ت ##جار ##ت و در ##بار ##ه ت ##جار ##ت بحث و گفت ##گو\n",
            "2023-06-11 09:53:16 | INFO | fairseq.tasks.translation | example reference: [CLS] عالی است. ش ##اید ب ##تو ##انی ##م هم ##دی ##گر را ##در ها ##لی ##هان ##ز, باغ و ##رزش یا میدان است ##یش ##ن ب ##بین ##یم و در مورد کار ص ##حبت ک ##نی ##م. [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  97% 28/29 [00:17<00:00,  1.57it/s]\u001b[A2023-06-11 09:53:17 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"احمد من ن ##می ##تو ##انس ##تم ب ##گو ##یی ##م که در این هفت ##ه, به نظر میرسد که در این هفت ##ه به شما نیاز دار ##م تا در این هفت ##ه ب ##گو ##یی ##م که برای شما دو ساعت دیگر برای شما مناسب است. [SEP]\n",
            "2023-06-11 09:53:17 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##ه به - نظر ن ##می ##رس ##د که من ب ##تو ##ان ##م کد ال ##کت ##ریکی را برای اجرا مه ##یا ک ##ن ##م, من نیاز دار ##م که آ ##ه با تو زمانی دوباره برای حدود بیش از دو ساعت, در این هفت ##ه مل ##اقات ک ##ن ##م. کی برای تو خوب است. [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset: 100% 29/29 [00:17<00:00,  1.66it/s]\u001b[A\n",
            "                                                                        \u001b[A2023-06-11 09:53:17 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.1 | nll_loss 3.132 | ppl 8.77 | bleu 34.7 | wps 4240.1 | wpb 2556.5 | bsz 137.9 | num_updates 6643\n",
            "2023-06-11 09:53:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 6643 updates\n",
            "2023-06-11 09:53:17 | INFO | fairseq.trainer | Saving checkpoint to /content/content/drive/MyDrive/mbert/checkpoints/checkpoint1.pt\n",
            "2023-06-11 09:53:19 | INFO | fairseq.trainer | Finished saving checkpoint to /content/content/drive/MyDrive/mbert/checkpoints/checkpoint1.pt\n",
            "2023-06-11 09:53:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./content/drive/MyDrive/mbert/checkpoints/checkpoint1.pt (epoch 1 @ 6643 updates, score 34.7) (writing took 9.576393588000428 seconds)\n",
            "2023-06-11 09:53:27 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n",
            "2023-06-11 09:53:27 | INFO | train | epoch 001 | loss 7.829 | nll_loss 5.277 | ppl 38.78 | wps 22910 | ups 6.02 | wpb 3802.9 | bsz 100.8 | num_updates 6643 | lr 0.00193994 | gnorm 0.843 | loss_scale 4 | train_wall 1052 | gb_free 12.7 | wall 1108\n",
            "2023-06-11 09:53:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6648\n",
            "epoch 002:   0% 0/6648 [00:00<?, ?it/s]2023-06-11 09:53:27 | INFO | fairseq.trainer | begin training epoch 2\n",
            "2023-06-11 09:53:27 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 002: 100% 6647/6648 [18:02<00:00,  7.46it/s, loss=6.243, nll_loss=3.331, ppl=10.07, wps=24147.8, ups=6.33, wpb=3813.4, bsz=105.9, num_updates=13200, lr=0.0013762, gnorm=0.285, loss_scale=4, train_wall=15, gb_free=12.7, wall=2175]2023-06-11 10:11:29 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:   0% 0/29 [00:00<?, ?it/s]\u001b[A2023-06-11 10:11:30 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] و با آن, [SEP]\n",
            "2023-06-11 10:11:30 | INFO | fairseq.tasks.translation | example reference: [CLS] خدا ##حافظ, [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:   3% 1/29 [00:00<00:20,  1.34it/s]\u001b[A2023-06-11 10:11:30 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] آیا خوب است? [SEP]\n",
            "2023-06-11 10:11:30 | INFO | fairseq.tasks.translation | example reference: [CLS] آیا آن خوب است? [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:   7% 2/29 [00:01<00:17,  1.52it/s]\u001b[A2023-06-11 10:11:31 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"\" \"\" \"\" \"[SEP]\n",
            "2023-06-11 10:11:31 | INFO | fairseq.tasks.translation | example reference: [CLS] او ##ه زمان را گرفت ##م, [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  10% 3/29 [00:01<00:16,  1.54it/s]\u001b[A2023-06-11 10:11:31 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] این ##جا در این ##جا خوب است. [SEP]\n",
            "2023-06-11 10:11:31 | INFO | fairseq.tasks.translation | example reference: [CLS] در این ##جا ظهر خوب خواهد بود. [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  14% 4/29 [00:02<00:16,  1.55it/s]\u001b[A2023-06-11 10:11:32 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] پس ما می ##گو ##یی ##م جمع ##ه ه ##شت ##م, [SEP]\n",
            "2023-06-11 10:11:32 | INFO | fairseq.tasks.translation | example reference: [CLS] پس شد جمع ##ه ه ##شت ##م, [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  17% 5/29 [00:03<00:14,  1.63it/s]\u001b[A2023-06-11 10:11:33 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"\" \"\" \"\" \"\" \"\" \"[SEP]\n",
            "2023-06-11 10:11:33 | INFO | fairseq.tasks.translation | example reference: [CLS] چه چیزی برای شما مناسب است, [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  21% 6/29 [00:03<00:13,  1.67it/s]\u001b[A2023-06-11 10:11:33 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"\" \", خدا ##وند هر جمع ##ه خوب است. [SEP]\n",
            "2023-06-11 10:11:33 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##ه, خدا, هر جمع ##ه - ای خوب است. [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  24% 7/29 [00:04<00:14,  1.47it/s]\u001b[A2023-06-11 10:11:34 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] ال ##ان, شما بعد از آن, [SEP]\n",
            "2023-06-11 10:11:34 | INFO | fairseq.tasks.translation | example reference: [CLS] بسیار خوب, به ام ##ید دید ##ار, خدا ##حافظ, [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  28% 8/29 [00:05<00:14,  1.46it/s]\u001b[A2023-06-11 10:11:35 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] اما بعد از ظهر بعد از ظهر بیست و دوم, [SEP]\n",
            "2023-06-11 10:11:35 | INFO | fairseq.tasks.translation | example reference: [CLS] اما, آ ##ه بعد ##از ##ظهر بیست و دوم, [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  31% 9/29 [00:06<00:14,  1.37it/s]\u001b[A2023-06-11 10:11:36 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] و نو ##زدهم من تا ساعت چهار ساعت وقت دار ##م, [SEP]\n",
            "2023-06-11 10:11:36 | INFO | fairseq.tasks.translation | example reference: [CLS] و نو ##زدهم نیز تا ساعت چهار آزاد ه ##ست ##م. [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  34% 10/29 [00:06<00:14,  1.32it/s]\u001b[A2023-06-11 10:11:37 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] در روز سه ش ##ن ##به, هر وقت بعد از دو ##از ##دهم, [SEP]\n",
            "2023-06-11 10:11:37 | INFO | fairseq.tasks.translation | example reference: [CLS] سه - ش ##ن ##به, هر زمانی بعد از دو ##از ##ده مناسب خواهد بود, [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  38% 11/29 [00:07<00:14,  1.28it/s]\u001b[A2023-06-11 10:11:37 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] بل ##ه, خوب است اگر من به دفتر ##تان می ##آ ##یی ##م. [SEP]\n",
            "2023-06-11 10:11:37 | INFO | fairseq.tasks.translation | example reference: [CLS] بل ##ه, این خوب است اگر من به دفتر شما بی ##ای ##م. [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  41% 12/29 [00:08<00:13,  1.30it/s]\u001b[A2023-06-11 10:11:38 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"\" \"\" \"\" \"\" \"[SEP]\n",
            "2023-06-11 10:11:38 | INFO | fairseq.tasks.translation | example reference: [CLS] من از سه تا چهار و ن ##یم ج ##لس ##ه دار ##م, [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  45% 13/29 [00:09<00:12,  1.33it/s]\u001b[A2023-06-11 10:11:39 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] در چند هفت ##ه آ ##ینده, زمانی که شما آزاد ه ##ستی ##د? [SEP]\n",
            "2023-06-11 10:11:39 | INFO | fairseq.tasks.translation | example reference: [CLS] زمانی در دو هفت ##هی آ ##ینده وجود دارد که شما آزاد با ##شی? [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  48% 14/29 [00:09<00:10,  1.41it/s]\u001b[A2023-06-11 10:11:39 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] من از شهر از سی ##زد ##ه از سی ##زد ##ه ه ##ست ##م. [SEP]\n",
            "2023-06-11 10:11:39 | INFO | fairseq.tasks.translation | example reference: [CLS] من از سی ##م تا سوم خارج از شهر ه ##ست ##م. [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  52% 15/29 [00:10<00:09,  1.47it/s]\u001b[A2023-06-11 10:11:40 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"این هفت ##ه پس از آن, هفت ##ه بعد از آن, هفت ##ه ی نو ##زدهم? [SEP]\n",
            "2023-06-11 10:11:40 | INFO | fairseq.tasks.translation | example reference: [CLS] او ##ه در مورد هفت ##ه - ی بعد از آن چ ##طور است. هفت ##ه - ی نو ##زدهم? [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  55% 16/29 [00:11<00:08,  1.48it/s]\u001b[A2023-06-11 10:11:41 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] یا ه ##ف ##دهم, یا بیست و چهارم خوب است. \"[SEP]\n",
            "2023-06-11 10:11:41 | INFO | fairseq.tasks.translation | example reference: [CLS] هر دو ##ی ه ##ف ##دهم, یا بیست و چهارم خوب خ ##وا ##هن ##د بود, او ##ه ##وم, [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  59% 17/29 [00:11<00:07,  1.51it/s]\u001b[A2023-06-11 10:11:41 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"\" \"این هفت ##ه ب ##د است که برنامه ی شما در هفت ##ه آ ##ینده ن ##گاه ک ##نید. [SEP]\n",
            "2023-06-11 10:11:41 | INFO | fairseq.tasks.translation | example reference: [CLS] او ##م تمام این هفت ##ه ب ##د است. برنامه شما در هفت ##ه آ ##ینده چ ##گونه است. [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  62% 18/29 [00:12<00:06,  1.62it/s]\u001b[A2023-06-11 10:11:42 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] با ##ش ##ه, باید ب ##گو ##یی ##م که بین دو و چهار, دو ##شن ##به, دو ##شن ##به ه ##شت ##م? [SEP]\n",
            "2023-06-11 10:11:42 | INFO | fairseq.tasks.translation | example reference: [CLS] باشد, میتوان ##یم ب ##گو ##یی ##م دو تا چهار? روز دو ##شن ##به, ه ##شت ##م? [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  66% 19/29 [00:12<00:06,  1.63it/s]\u001b[A2023-06-11 10:11:42 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"[SEP]\n",
            "2023-06-11 10:11:42 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##ه بل ##ه, س ##لام من را به خان ##م ایک ##س با ح ##روف کوچک بر ##سان. ام, [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  69% 20/29 [00:13<00:05,  1.62it/s]\u001b[A2023-06-11 10:11:43 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] پس اگر من یک ساعت برای ن ##اه ##ار ن ##اه ##ار ب ##گذار ##م, یک ساعت خوب است, [SEP]\n",
            "2023-06-11 10:11:43 | INFO | fairseq.tasks.translation | example reference: [CLS] بنابراین اگر من ساعت ##ی را برای ن ##اه ##ار داشته با ##شم, ساعت یک برای من خوب خواهد بود, [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  72% 21/29 [00:14<00:04,  1.68it/s]\u001b[A2023-06-11 10:11:43 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] من میتوان ##م با شما در دو نفر مل ##اقات ک ##نید, اما شما می ##خ ##وا ##هی ##د من را در یک پارک کوچک مل ##اقات ک ##نید. [SEP]\n",
            "2023-06-11 10:11:43 | INFO | fairseq.tasks.translation | example reference: [CLS] من شما را ساعت دو می ##بین ##م, اما باید هم ##دی ##گر را در پارک لیگ کوچک ب ##بین ##یم. [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  76% 22/29 [00:14<00:04,  1.54it/s]\u001b[A2023-06-11 10:11:44 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"خ ##یلی خ ##یلی زیاد, پنج ش ##ن ##به, و چهار ##شن ##به بیست و نه ##م, کتاب ر ##زر ##و شده است. [SEP]\n",
            "2023-06-11 10:11:44 | INFO | fairseq.tasks.translation | example reference: [CLS] ام خ ##یلی زیاد سه - ش ##ن ##به سی - ام و چهار ##شن ##به بیست و نه ##م پر هستند. [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  79% 23/29 [00:15<00:03,  1.58it/s]\u001b[A2023-06-11 10:11:45 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"\" \"در ##بار ##ه چهار ##دهم یا ه ##ف ##دهم یا ه ##ف ##دهم یا ه ##ف ##دهم یا ه ##ف ##دهم یا ه ##ف ##دهم یا ه ##ف ##دهم. [SEP]\n",
            "2023-06-11 10:11:45 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##ه چهار ##دهم یا ه ##ف ##دهم چه ##طور. آیا هیچ ##ک ##دام از آن دو روز, با برنامه ##ریزی شما مناسب است? [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  83% 24/29 [00:16<00:03,  1.61it/s]\u001b[A2023-06-11 10:11:45 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] روز چهار ##شن ##به, همه برای من آزاد است, بنابراین, برای شما کار خواهد کرد, [SEP]\n",
            "2023-06-11 10:11:45 | INFO | fairseq.tasks.translation | example reference: [CLS] من چهار ##شن ##به کامل ##ا آزاد ه ##ست ##م, اگر برای شما مناسب است, عالی است, [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  86% 25/29 [00:16<00:02,  1.60it/s]\u001b[A2023-06-11 10:11:46 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] بل ##ه, مثل \"احمد, من ن ##می ##دان ##م, هر زمان در بعد از ظهر برای من مناسب است.\" [SEP]\n",
            "2023-06-11 10:11:46 | INFO | fairseq.tasks.translation | example reference: [CLS] بل ##ه, مثل, ن ##می ##دان ##م, هر زمان ##ن از بعد از ظهر پنج ##شن ##به ه ##شت ##م برای من مناسب است. [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  90% 26/29 [00:17<00:01,  1.64it/s]\u001b[A2023-06-11 10:11:47 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] من یک س ##مین ##ار دار ##م, هر روز, بیست و هفت ##م است که یک روز ه ##ست ##م, نه کامل ##ا آزاد است. [SEP]\n",
            "2023-06-11 10:11:47 | INFO | fairseq.tasks.translation | example reference: [CLS] من در تمام روز بیست - و هفت ##م یک س ##مین ##ار دار ##م. آن روز ##ی است که در آن هفت ##ه, من به - طور کامل آزاد نیست ##م. [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  93% 27/29 [00:17<00:01,  1.66it/s]\u001b[A2023-06-11 10:11:47 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] او گفت: \"خ ##یلی خوب است که خ ##یلی خوب است. ما احتمال ##ا ش ##اید ش ##اید ش ##اید ش ##اید ش ##اید ش ##اید در میدان ال ##کت ##رون ##یکی و یا باغ و ##رزش ##ی در میدان ت ##جار ##ت, و در مورد ت ##جار ##ت\n",
            "2023-06-11 10:11:47 | INFO | fairseq.tasks.translation | example reference: [CLS] عالی است. ش ##اید ب ##تو ##انی ##م هم ##دی ##گر را ##در ها ##لی ##هان ##ز, باغ و ##رزش یا میدان است ##یش ##ن ب ##بین ##یم و در مورد کار ص ##حبت ک ##نی ##م. [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  97% 28/29 [00:18<00:00,  1.69it/s]\u001b[A2023-06-11 10:11:48 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"من ن ##می ##تو ##ان ##م به نظر ن ##می ##رس ##م که این قانون تا ک ##نون به منظور ک ##شید ##ن با شما در ##بار ##ه ی دو ساعت دیگر در این هفت ##ه با شما دید ##ار ک ##نید. [SEP]\n",
            "2023-06-11 10:11:48 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##ه به - نظر ن ##می ##رس ##د که من ب ##تو ##ان ##م کد ال ##کت ##ریکی را برای اجرا مه ##یا ک ##ن ##م, من نیاز دار ##م که آ ##ه با تو زمانی دوباره برای حدود بیش از دو ساعت, در این هفت ##ه مل ##اقات ک ##ن ##م. کی برای تو خوب است. [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset: 100% 29/29 [00:18<00:00,  1.90it/s]\u001b[A\n",
            "                                                                        \u001b[A2023-06-11 10:11:48 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 5.864 | nll_loss 2.894 | ppl 7.43 | bleu 42.13 | wps 3985.4 | wpb 2556.5 | bsz 137.9 | num_updates 13291 | best_bleu 42.13\n",
            "2023-06-11 10:11:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 13291 updates\n",
            "2023-06-11 10:11:48 | INFO | fairseq.trainer | Saving checkpoint to /content/content/drive/MyDrive/mbert/checkpoints/checkpoint2.pt\n",
            "2023-06-11 10:11:54 | INFO | fairseq.trainer | Finished saving checkpoint to /content/content/drive/MyDrive/mbert/checkpoints/checkpoint2.pt\n",
            "2023-06-11 10:12:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./content/drive/MyDrive/mbert/checkpoints/checkpoint2.pt (epoch 2 @ 13291 updates, score 42.13) (writing took 12.459240135999607 seconds)\n",
            "2023-06-11 10:12:00 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)\n",
            "2023-06-11 10:12:00 | INFO | train | epoch 002 | loss 6.369 | nll_loss 3.481 | ppl 11.16 | wps 22704.9 | ups 5.97 | wpb 3802.9 | bsz 100.8 | num_updates 13291 | lr 0.00137149 | gnorm 0.307 | loss_scale 4 | train_wall 1056 | gb_free 12.8 | wall 2221\n",
            "2023-06-11 10:12:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6648\n",
            "epoch 003:   0% 0/6648 [00:00<?, ?it/s]2023-06-11 10:12:00 | INFO | fairseq.trainer | begin training epoch 3\n",
            "2023-06-11 10:12:00 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 003: 100% 6646/6648 [18:03<00:00,  6.35it/s, loss=6.096, nll_loss=3.152, ppl=8.89, wps=23202.5, ups=6.09, wpb=3807.5, bsz=102.8, num_updates=19900, lr=0.00112084, gnorm=0.27, loss_scale=8, train_wall=16, gb_free=12.8, wall=3299]2023-06-11 10:30:04 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:   0% 0/29 [00:00<?, ?it/s]\u001b[A2023-06-11 10:30:05 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] با آن, [SEP]\n",
            "2023-06-11 10:30:05 | INFO | fairseq.tasks.translation | example reference: [CLS] خدا ##حافظ, [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:   3% 1/29 [00:00<00:20,  1.39it/s]\u001b[A2023-06-11 10:30:06 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] آیا خوب است? [SEP]\n",
            "2023-06-11 10:30:06 | INFO | fairseq.tasks.translation | example reference: [CLS] آیا آن خوب است? [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:   7% 2/29 [00:01<00:17,  1.57it/s]\u001b[A2023-06-11 10:30:06 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"احمد یک زمان را انتخاب کرد, [SEP]\n",
            "2023-06-11 10:30:06 | INFO | fairseq.tasks.translation | example reference: [CLS] او ##ه زمان را گرفت ##م, [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  10% 3/29 [00:01<00:16,  1.58it/s]\u001b[A2023-06-11 10:30:07 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] این ##جا ج ##ری ##مه ن ##خواهد بود. [SEP]\n",
            "2023-06-11 10:30:07 | INFO | fairseq.tasks.translation | example reference: [CLS] در این ##جا ظهر خوب خواهد بود. [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  14% 4/29 [00:02<00:15,  1.60it/s]\u001b[A2023-06-11 10:30:07 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] خ ##ب ما جمع ##ه ه ##شت ##م را جمع خ ##وا ##هیم کرد, [SEP]\n",
            "2023-06-11 10:30:07 | INFO | fairseq.tasks.translation | example reference: [CLS] پس شد جمع ##ه ه ##شت ##م, [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  17% 5/29 [00:03<00:14,  1.68it/s]\u001b[A2023-06-11 10:30:08 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"\" \"\" \"\" \"\" [SEP]\n",
            "2023-06-11 10:30:08 | INFO | fairseq.tasks.translation | example reference: [CLS] چه چیزی برای شما مناسب است, [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  21% 6/29 [00:03<00:13,  1.71it/s]\u001b[A2023-06-11 10:30:09 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"احمد هر جمع ##ه, خدا ج ##ری ##مه است. [SEP]\n",
            "2023-06-11 10:30:09 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##ه, خدا, هر جمع ##ه - ای خوب است. [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  24% 7/29 [00:04<00:13,  1.67it/s]\u001b[A2023-06-11 10:30:09 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] خوب, ب ##بین ##ید که شما آن را با آن می ##بین ##ید, [SEP]\n",
            "2023-06-11 10:30:09 | INFO | fairseq.tasks.translation | example reference: [CLS] بسیار خوب, به ام ##ید دید ##ار, خدا ##حافظ, [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  28% 8/29 [00:04<00:11,  1.76it/s]\u001b[A2023-06-11 10:30:10 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] اما بعد از ظهر بیست و دوم, [SEP]\n",
            "2023-06-11 10:30:10 | INFO | fairseq.tasks.translation | example reference: [CLS] اما, آ ##ه بعد ##از ##ظهر بیست و دوم, [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  31% 9/29 [00:05<00:12,  1.62it/s]\u001b[A2023-06-11 10:30:10 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] و نو ##زدهم من تا ساعت چهار وقت آزاد ه ##ست ##م, [SEP]\n",
            "2023-06-11 10:30:10 | INFO | fairseq.tasks.translation | example reference: [CLS] و نو ##زدهم نیز تا ساعت چهار آزاد ه ##ست ##م. [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  34% 10/29 [00:06<00:12,  1.50it/s]\u001b[A2023-06-11 10:30:11 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] روز سه ش ##ن ##به, هر وقت پس از دو ##از ##دهم, [SEP]\n",
            "2023-06-11 10:30:11 | INFO | fairseq.tasks.translation | example reference: [CLS] سه - ش ##ن ##به, هر زمانی بعد از دو ##از ##ده مناسب خواهد بود, [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  38% 11/29 [00:07<00:12,  1.42it/s]\u001b[A2023-06-11 10:30:12 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] بل ##ه, خوب است اگر من به دفتر ##تان بی ##ای ##م. [SEP]\n",
            "2023-06-11 10:30:12 | INFO | fairseq.tasks.translation | example reference: [CLS] بل ##ه, این خوب است اگر من به دفتر شما بی ##ای ##م. [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  41% 12/29 [00:07<00:11,  1.45it/s]\u001b[A2023-06-11 10:30:13 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"احمد من, یک ن ##ش ##ست از سه تا سی و یک ##م, [SEP]\n",
            "2023-06-11 10:30:13 | INFO | fairseq.tasks.translation | example reference: [CLS] من از سه تا چهار و ن ##یم ج ##لس ##ه دار ##م, [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  45% 13/29 [00:08<00:11,  1.37it/s]\u001b[A2023-06-11 10:30:14 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] در چند هفت ##ه ی آ ##ینده, زمانی که شما آزاد ه ##ستی ##د? [SEP]\n",
            "2023-06-11 10:30:14 | INFO | fairseq.tasks.translation | example reference: [CLS] زمانی در دو هفت ##هی آ ##ینده وجود دارد که شما آزاد با ##شی? [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  48% 14/29 [00:09<00:11,  1.32it/s]\u001b[A2023-06-11 10:30:14 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] من از سی ##ام از سی ##زدهم بیرون می ##آ ##مد ##م. [SEP]\n",
            "2023-06-11 10:30:14 | INFO | fairseq.tasks.translation | example reference: [CLS] من از سی ##م تا سوم خارج از شهر ه ##ست ##م. [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  52% 15/29 [00:10<00:10,  1.28it/s]\u001b[A2023-06-11 10:30:15 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] هفت ##ه پس از آن, هفت ##ه بعد از آن, هفت ##ه نو ##زدهم, هفت ##ه نو ##زدهم? [SEP]\n",
            "2023-06-11 10:30:15 | INFO | fairseq.tasks.translation | example reference: [CLS] او ##ه در مورد هفت ##ه - ی بعد از آن چ ##طور است. هفت ##ه - ی نو ##زدهم? [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  55% 16/29 [00:11<00:10,  1.21it/s]\u001b[A2023-06-11 10:30:16 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] یا ه ##ف ##دهم, یا بیست و چهارم خوب است. \"[SEP]\n",
            "2023-06-11 10:30:16 | INFO | fairseq.tasks.translation | example reference: [CLS] هر دو ##ی ه ##ف ##دهم, یا بیست و چهارم خوب خ ##وا ##هن ##د بود, او ##ه ##وم, [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  59% 17/29 [00:11<00:09,  1.32it/s]\u001b[A2023-06-11 10:30:17 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"این هفت ##ه ب ##د است.\" [SEP]\n",
            "2023-06-11 10:30:17 | INFO | fairseq.tasks.translation | example reference: [CLS] او ##م تمام این هفت ##ه ب ##د است. برنامه شما در هفت ##ه آ ##ینده چ ##گونه است. [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  62% 18/29 [00:12<00:07,  1.46it/s]\u001b[A2023-06-11 10:30:17 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] با ##ش ##ه, باید ب ##گو ##یی ##م که بین دو, دو و چهار, دو ##شن ##به ه ##شت ##م? [SEP]\n",
            "2023-06-11 10:30:17 | INFO | fairseq.tasks.translation | example reference: [CLS] باشد, میتوان ##یم ب ##گو ##یی ##م دو تا چهار? روز دو ##شن ##به, ه ##شت ##م? [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  66% 19/29 [00:12<00:06,  1.52it/s]\u001b[A2023-06-11 10:30:18 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"بل ##ه بل ##ه, س ##لام, س ##لام را برای من ف ##رس ##تاد ##ه است.\" [SEP]\n",
            "2023-06-11 10:30:18 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##ه بل ##ه, س ##لام من را به خان ##م ایک ##س با ح ##روف کوچک بر ##سان. ام, [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  69% 20/29 [00:13<00:05,  1.55it/s]\u001b[A2023-06-11 10:30:18 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] پس اگر من یک ساعت برای ن ##اه ##ار داشت ##م, یک ساعت خوب است, [SEP]\n",
            "2023-06-11 10:30:18 | INFO | fairseq.tasks.translation | example reference: [CLS] بنابراین اگر من ساعت ##ی را برای ن ##اه ##ار داشته با ##شم, ساعت یک برای من خوب خواهد بود, [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  72% 21/29 [00:14<00:04,  1.64it/s]\u001b[A2023-06-11 10:30:19 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] من میتوان ##م با شما مل ##اقات ک ##ن ##م, اما شما می ##خ ##وا ##هی ##د با من در پارک ##ی کوچک مل ##اقات ک ##نید. [SEP]\n",
            "2023-06-11 10:30:19 | INFO | fairseq.tasks.translation | example reference: [CLS] من شما را ساعت دو می ##بین ##م, اما باید هم ##دی ##گر را در پارک لیگ کوچک ب ##بین ##یم. [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  76% 22/29 [00:14<00:04,  1.71it/s]\u001b[A2023-06-11 10:30:19 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"آ ##دم خ ##یلی, پنج ##شن ##به سی ##زدهم و چهار ##شن ##به بیست و نه ##م, کتاب ر ##زر ##و شده است.\" [SEP]\n",
            "2023-06-11 10:30:19 | INFO | fairseq.tasks.translation | example reference: [CLS] ام خ ##یلی زیاد سه - ش ##ن ##به سی - ام و چهار ##شن ##به بیست و نه ##م پر هستند. [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  79% 23/29 [00:15<00:03,  1.70it/s]\u001b[A2023-06-11 10:30:20 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"احمد چ ##طور در ##بار ##ه چهار ##دهم یا ه ##ف ##دهم یا ه ##ف ##دهم یا ه ##ف ##دهم یا ه ##ف ##دهم. یا این دو روز, با برنامه ی شما مناسب است? [SEP]\n",
            "2023-06-11 10:30:20 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##ه چهار ##دهم یا ه ##ف ##دهم چه ##طور. آیا هیچ ##ک ##دام از آن دو روز, با برنامه ##ریزی شما مناسب است? [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  83% 24/29 [00:15<00:02,  1.68it/s]\u001b[A2023-06-11 10:30:21 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] روز چهار ##شن ##به همه برای من آزاد است, بنابراین, خ ##یلی خوب خواهد بود, [SEP]\n",
            "2023-06-11 10:30:21 | INFO | fairseq.tasks.translation | example reference: [CLS] من چهار ##شن ##به کامل ##ا آزاد ه ##ست ##م, اگر برای شما مناسب است, عالی است, [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  86% 25/29 [00:16<00:02,  1.65it/s]\u001b[A2023-06-11 10:30:21 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] بل ##ه, مانند \"احمد, من ن ##می ##دان ##م, در بعد از ظهر, پنج ##شن ##به ه ##شت ##م خوب است.\" [SEP]\n",
            "2023-06-11 10:30:21 | INFO | fairseq.tasks.translation | example reference: [CLS] بل ##ه, مثل, ن ##می ##دان ##م, هر زمان ##ن از بعد از ظهر پنج ##شن ##به ه ##شت ##م برای من مناسب است. [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  90% 26/29 [00:16<00:01,  1.68it/s]\u001b[A2023-06-11 10:30:22 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] من یک س ##مین ##ار را دار ##م, در روز بیست و هفت ##م, یک روز بیست و هفت ##م است که من کامل ##ا آزاد ه ##ست ##م. [SEP]\n",
            "2023-06-11 10:30:22 | INFO | fairseq.tasks.translation | example reference: [CLS] من در تمام روز بیست - و هفت ##م یک س ##مین ##ار دار ##م. آن روز ##ی است که در آن هفت ##ه, من به - طور کامل آزاد نیست ##م. [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  93% 27/29 [00:17<00:01,  1.70it/s]\u001b[A2023-06-11 10:30:22 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"احمد ##ی که خ ##یلی خوب خواهد بود, ممکن است با هم ش ##اید با هم ش ##اید با هم ش ##اید با هم ش ##اید در میدان و ##رزش ##ی, و در مورد ت ##جار ##ت م ##ذا ##کر ##ه ک ##نی ##م.\" [SEP]\n",
            "2023-06-11 10:30:22 | INFO | fairseq.tasks.translation | example reference: [CLS] عالی است. ش ##اید ب ##تو ##انی ##م هم ##دی ##گر را ##در ها ##لی ##هان ##ز, باغ و ##رزش یا میدان است ##یش ##ن ب ##بین ##یم و در مورد کار ص ##حبت ک ##نی ##م. [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  97% 28/29 [00:18<00:00,  1.73it/s]\u001b[A2023-06-11 10:30:23 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"من ن ##می ##تو ##ان ##م به نظر ن ##می ##رس ##م که کد ##ام یک از این م ##قرر ##ات را به دست آورد ##م.\" [SEP]\n",
            "2023-06-11 10:30:23 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##ه به - نظر ن ##می ##رس ##د که من ب ##تو ##ان ##م کد ال ##کت ##ریکی را برای اجرا مه ##یا ک ##ن ##م, من نیاز دار ##م که آ ##ه با تو زمانی دوباره برای حدود بیش از دو ساعت, در این هفت ##ه مل ##اقات ک ##ن ##م. کی برای تو خوب است. [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset: 100% 29/29 [00:18<00:00,  1.97it/s]\u001b[A\n",
            "                                                                        \u001b[A2023-06-11 10:30:23 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 5.761 | nll_loss 2.766 | ppl 6.8 | bleu 44.51 | wps 4056.1 | wpb 2556.5 | bsz 137.9 | num_updates 19939 | best_bleu 44.51\n",
            "2023-06-11 10:30:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 19939 updates\n",
            "2023-06-11 10:30:23 | INFO | fairseq.trainer | Saving checkpoint to /content/content/drive/MyDrive/mbert/checkpoints/checkpoint3.pt\n",
            "2023-06-11 10:30:25 | INFO | fairseq.trainer | Finished saving checkpoint to /content/content/drive/MyDrive/mbert/checkpoints/checkpoint3.pt\n",
            "2023-06-11 10:30:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./content/drive/MyDrive/mbert/checkpoints/checkpoint3.pt (epoch 3 @ 19939 updates, score 44.51) (writing took 8.140729212999759 seconds)\n",
            "2023-06-11 10:30:31 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)\n",
            "2023-06-11 10:30:31 | INFO | train | epoch 003 | loss 6.13 | nll_loss 3.189 | ppl 9.12 | wps 22761.3 | ups 5.99 | wpb 3802.9 | bsz 100.8 | num_updates 19939 | lr 0.00111974 | gnorm 0.275 | loss_scale 8 | train_wall 1058 | gb_free 12.7 | wall 3332\n",
            "2023-06-11 10:30:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6648\n",
            "epoch 004:   0% 0/6648 [00:00<?, ?it/s]2023-06-11 10:30:31 | INFO | fairseq.trainer | begin training epoch 4\n",
            "2023-06-11 10:30:31 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 004: 100% 6647/6648 [18:09<00:00,  6.22it/s, loss=6.033, nll_loss=3.077, ppl=8.44, wps=22235.6, ups=5.94, wpb=3744.3, bsz=99.8, num_updates=26500, lr=0.000971286, gnorm=0.278, loss_scale=8, train_wall=16, gb_free=12.9, wall=4409]2023-06-11 10:48:41 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:   0% 0/29 [00:00<?, ?it/s]\u001b[A2023-06-11 10:48:42 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] تا ب ##بین ##ید, [SEP]\n",
            "2023-06-11 10:48:42 | INFO | fairseq.tasks.translation | example reference: [CLS] خدا ##حافظ, [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:   3% 1/29 [00:01<00:33,  1.21s/it]\u001b[A2023-06-11 10:48:43 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] آیا خوب است? [SEP]\n",
            "2023-06-11 10:48:43 | INFO | fairseq.tasks.translation | example reference: [CLS] آیا آن خوب است? [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:   7% 2/29 [00:01<00:24,  1.11it/s]\u001b[A2023-06-11 10:48:43 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] او یک زمان را انتخاب میکند, [SEP]\n",
            "2023-06-11 10:48:43 | INFO | fairseq.tasks.translation | example reference: [CLS] او ##ه زمان را گرفت ##م, [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  10% 3/29 [00:02<00:19,  1.31it/s]\u001b[A2023-06-11 10:48:44 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] ظهر در این ##جا خوب است. [SEP]\n",
            "2023-06-11 10:48:44 | INFO | fairseq.tasks.translation | example reference: [CLS] در این ##جا ظهر خوب خواهد بود. [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  14% 4/29 [00:03<00:17,  1.42it/s]\u001b[A2023-06-11 10:48:45 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] پس ما جمع ##ه ه ##شت ##م را جمع می ##کن ##یم, [SEP]\n",
            "2023-06-11 10:48:45 | INFO | fairseq.tasks.translation | example reference: [CLS] پس شد جمع ##ه ه ##شت ##م, [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  17% 5/29 [00:03<00:15,  1.55it/s]\u001b[A2023-06-11 10:48:45 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"\" \"برای شما خوب است, [SEP]\n",
            "2023-06-11 10:48:45 | INFO | fairseq.tasks.translation | example reference: [CLS] چه چیزی برای شما مناسب است, [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  21% 6/29 [00:04<00:14,  1.59it/s]\u001b[A2023-06-11 10:48:46 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"احمد هر جمع ##ه خوب است.\" [SEP]\n",
            "2023-06-11 10:48:46 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##ه, خدا, هر جمع ##ه - ای خوب است. [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  24% 7/29 [00:04<00:13,  1.59it/s]\u001b[A2023-06-11 10:48:46 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] خوب, بعد از آن, [SEP]\n",
            "2023-06-11 10:48:46 | INFO | fairseq.tasks.translation | example reference: [CLS] بسیار خوب, به ام ##ید دید ##ار, خدا ##حافظ, [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  28% 8/29 [00:05<00:12,  1.69it/s]\u001b[A2023-06-11 10:48:47 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] اما بعد از ظهر بیست و دوم, [SEP]\n",
            "2023-06-11 10:48:47 | INFO | fairseq.tasks.translation | example reference: [CLS] اما, آ ##ه بعد ##از ##ظهر بیست و دوم, [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  31% 9/29 [00:05<00:11,  1.69it/s]\u001b[A2023-06-11 10:48:48 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] و نو ##زدهم وقت ##م آزاد است, [SEP]\n",
            "2023-06-11 10:48:48 | INFO | fairseq.tasks.translation | example reference: [CLS] و نو ##زدهم نیز تا ساعت چهار آزاد ه ##ست ##م. [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  34% 10/29 [00:06<00:11,  1.71it/s]\u001b[A2023-06-11 10:48:48 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] روز سه ش ##ن ##به, هر زمان که دو ##از ##ده خ ##وا ##هن ##د بود, [SEP]\n",
            "2023-06-11 10:48:48 | INFO | fairseq.tasks.translation | example reference: [CLS] سه - ش ##ن ##به, هر زمانی بعد از دو ##از ##ده مناسب خواهد بود, [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  38% 11/29 [00:07<00:11,  1.51it/s]\u001b[A2023-06-11 10:48:49 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] بل ##ه, خوب است اگر به دفتر ##تان بی ##اید. [SEP]\n",
            "2023-06-11 10:48:49 | INFO | fairseq.tasks.translation | example reference: [CLS] بل ##ه, این خوب است اگر من به دفتر شما بی ##ای ##م. [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  41% 12/29 [00:07<00:10,  1.63it/s]\u001b[A2023-06-11 10:48:49 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"\" \"\" \"\" \"\" \"\" \"[SEP]\n",
            "2023-06-11 10:48:49 | INFO | fairseq.tasks.translation | example reference: [CLS] من از سه تا چهار و ن ##یم ج ##لس ##ه دار ##م, [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  45% 13/29 [00:08<00:09,  1.64it/s]\u001b[A2023-06-11 10:48:50 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] هر زمان در چند هفت ##ه ی آ ##ینده وقت دار ##ید? [SEP]\n",
            "2023-06-11 10:48:50 | INFO | fairseq.tasks.translation | example reference: [CLS] زمانی در دو هفت ##هی آ ##ینده وجود دارد که شما آزاد با ##شی? [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  48% 14/29 [00:09<00:09,  1.65it/s]\u001b[A2023-06-11 10:48:51 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] من از سی - ام از سی ##زدهم بیرون می ##آ ##مد ##م. [SEP]\n",
            "2023-06-11 10:48:51 | INFO | fairseq.tasks.translation | example reference: [CLS] من از سی ##م تا سوم خارج از شهر ه ##ست ##م. [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  52% 15/29 [00:09<00:08,  1.66it/s]\u001b[A2023-06-11 10:48:51 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] این هفت ##ه بعد از آن هفت ##ه نو ##زدهم? [SEP]\n",
            "2023-06-11 10:48:51 | INFO | fairseq.tasks.translation | example reference: [CLS] او ##ه در مورد هفت ##ه - ی بعد از آن چ ##طور است. هفت ##ه - ی نو ##زدهم? [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  55% 16/29 [00:10<00:08,  1.62it/s]\u001b[A2023-06-11 10:48:52 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] یا ه ##ف ##دهم, یا بیست و چهارم خوب خواهد بود. [SEP]\n",
            "2023-06-11 10:48:52 | INFO | fairseq.tasks.translation | example reference: [CLS] هر دو ##ی ه ##ف ##دهم, یا بیست و چهارم خوب خ ##وا ##هن ##د بود, او ##ه ##وم, [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  59% 17/29 [00:10<00:07,  1.64it/s]\u001b[A2023-06-11 10:48:52 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"\" \"\" \"\" \"\" \"\" این هفت ##ه ب ##د است. \"[SEP]\n",
            "2023-06-11 10:48:52 | INFO | fairseq.tasks.translation | example reference: [CLS] او ##م تمام این هفت ##ه ب ##د است. برنامه شما در هفت ##ه آ ##ینده چ ##گونه است. [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  62% 18/29 [00:11<00:06,  1.72it/s]\u001b[A2023-06-11 10:48:53 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] با ##ش ##ه, باید ب ##گو ##یی ##م که بین دو و چهار, دو ##شن ##به ه ##شت ##م? [SEP]\n",
            "2023-06-11 10:48:53 | INFO | fairseq.tasks.translation | example reference: [CLS] باشد, میتوان ##یم ب ##گو ##یی ##م دو تا چهار? روز دو ##شن ##به, ه ##شت ##م? [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  66% 19/29 [00:12<00:06,  1.57it/s]\u001b[A2023-06-11 10:48:54 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"[SEP]\n",
            "2023-06-11 10:48:54 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##ه بل ##ه, س ##لام من را به خان ##م ایک ##س با ح ##روف کوچک بر ##سان. ام, [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  69% 20/29 [00:13<00:06,  1.46it/s]\u001b[A2023-06-11 10:48:55 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] پس اگر یک ساعت برای ن ##اه ##ار ن ##اه ##ار داشته با ##شم, یک ساعت خوب است, [SEP]\n",
            "2023-06-11 10:48:55 | INFO | fairseq.tasks.translation | example reference: [CLS] بنابراین اگر من ساعت ##ی را برای ن ##اه ##ار داشته با ##شم, ساعت یک برای من خوب خواهد بود, [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  72% 21/29 [00:13<00:05,  1.43it/s]\u001b[A2023-06-11 10:48:55 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] من میتوان ##م در دو ساعت با شما مل ##اقات ک ##نید, اما شما باید در پارک ##ی کوچک مل ##اقات ک ##نید. [SEP]\n",
            "2023-06-11 10:48:55 | INFO | fairseq.tasks.translation | example reference: [CLS] من شما را ساعت دو می ##بین ##م, اما باید هم ##دی ##گر را در پارک لیگ کوچک ب ##بین ##یم. [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  76% 22/29 [00:14<00:04,  1.42it/s]\u001b[A2023-06-11 10:48:56 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"\" \"\" \"پنج ##شن ##به سی - ام, پنج ##شن ##به و چهار ##شن ##به بیست و نه ##م, کتاب ر ##زر ##و شده است.\" [SEP]\n",
            "2023-06-11 10:48:56 | INFO | fairseq.tasks.translation | example reference: [CLS] ام خ ##یلی زیاد سه - ش ##ن ##به سی - ام و چهار ##شن ##به بیست و نه ##م پر هستند. [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  79% 23/29 [00:15<00:04,  1.35it/s]\u001b[A2023-06-11 10:48:57 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"چ ##طور چهار ##دهم یا ه ##ف ##دهم یا ه ##ف ##دهم یا ه ##ف ##دهم یا ه ##ف ##دهم یا ه ##ف ##دهم یا ه ##ف ##دهم انجام میشود.\" [SEP]\n",
            "2023-06-11 10:48:57 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##ه چهار ##دهم یا ه ##ف ##دهم چه ##طور. آیا هیچ ##ک ##دام از آن دو روز, با برنامه ##ریزی شما مناسب است? [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  83% 24/29 [00:16<00:03,  1.29it/s]\u001b[A2023-06-11 10:48:58 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] چهار ##شن ##به برای من آزاد است, بنابراین, این کار برای شما خوب خواهد بود, [SEP]\n",
            "2023-06-11 10:48:58 | INFO | fairseq.tasks.translation | example reference: [CLS] من چهار ##شن ##به کامل ##ا آزاد ه ##ست ##م, اگر برای شما مناسب است, عالی است, [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  86% 25/29 [00:16<00:03,  1.27it/s]\u001b[A2023-06-11 10:48:59 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] بل ##ه, مثل \"احمد, من ن ##می ##دان ##م, در بعد از ظهر, پنج ##شن ##به ه ##شت ##م خوب است. [SEP]\n",
            "2023-06-11 10:48:59 | INFO | fairseq.tasks.translation | example reference: [CLS] بل ##ه, مثل, ن ##می ##دان ##م, هر زمان ##ن از بعد از ظهر پنج ##شن ##به ه ##شت ##م برای من مناسب است. [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  90% 26/29 [00:17<00:02,  1.37it/s]\u001b[A2023-06-11 10:48:59 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] من یک س ##مین ##ار دار ##م, همه روز بیست و هفت ##م است که یک روز کامل ##ا آزاد ه ##ست ##م, نه کامل ##ا آن هفت ##ه. [SEP]\n",
            "2023-06-11 10:48:59 | INFO | fairseq.tasks.translation | example reference: [CLS] من در تمام روز بیست - و هفت ##م یک س ##مین ##ار دار ##م. آن روز ##ی است که در آن هفت ##ه, من به - طور کامل آزاد نیست ##م. [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  93% 27/29 [00:18<00:01,  1.47it/s]\u001b[A2023-06-11 10:49:00 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"\" \"خ ##یلی خوب خواهد بود. احتمال ##ا ش ##اید ش ##اید ش ##اید ش ##اید در و ##رزش ##گاه و ##رزش ##ی\" ها ##لی \", در میدان و ##رزش ##ی, و در ##بار ##ه ت ##جار ##ت بحث و گفت ##گو کند. [SEP]\n",
            "2023-06-11 10:49:00 | INFO | fairseq.tasks.translation | example reference: [CLS] عالی است. ش ##اید ب ##تو ##انی ##م هم ##دی ##گر را ##در ها ##لی ##هان ##ز, باغ و ##رزش یا میدان است ##یش ##ن ب ##بین ##یم و در مورد کار ص ##حبت ک ##نی ##م. [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  97% 28/29 [00:18<00:00,  1.55it/s]\u001b[A2023-06-11 10:49:00 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"\" \"\" \"\" \"\" ن ##می ##تو ##ان ##م به نظر ن ##می ##رس ##د که کد ##ام یک از این م ##قرر ##ات را برای آ ##ماد ##ه ساز ##ی با شما در ##بار ##ه ی دو ساعت دیگر در هفت ##ه ی ام ##سا ##ل انجام ده ##م. \"[SEP]\n",
            "2023-06-11 10:49:00 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##ه به - نظر ن ##می ##رس ##د که من ب ##تو ##ان ##م کد ال ##کت ##ریکی را برای اجرا مه ##یا ک ##ن ##م, من نیاز دار ##م که آ ##ه با تو زمانی دوباره برای حدود بیش از دو ساعت, در این هفت ##ه مل ##اقات ک ##ن ##م. کی برای تو خوب است. [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset: 100% 29/29 [00:19<00:00,  1.78it/s]\u001b[A\n",
            "                                                                        \u001b[A2023-06-11 10:49:00 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 5.678 | nll_loss 2.648 | ppl 6.27 | bleu 43.91 | wps 4021.7 | wpb 2556.5 | bsz 137.9 | num_updates 26587 | best_bleu 44.51\n",
            "2023-06-11 10:49:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 26587 updates\n",
            "2023-06-11 10:49:00 | INFO | fairseq.trainer | Saving checkpoint to /content/content/drive/MyDrive/mbert/checkpoints/checkpoint4.pt\n",
            "2023-06-11 10:49:02 | INFO | fairseq.trainer | Finished saving checkpoint to /content/content/drive/MyDrive/mbert/checkpoints/checkpoint4.pt\n",
            "2023-06-11 10:49:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./content/drive/MyDrive/mbert/checkpoints/checkpoint4.pt (epoch 4 @ 26587 updates, score 43.91) (writing took 4.369141165000656 seconds)\n",
            "2023-06-11 10:49:04 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)\n",
            "2023-06-11 10:49:04 | INFO | train | epoch 004 | loss 6.011 | nll_loss 3.044 | ppl 8.25 | wps 22703 | ups 5.97 | wpb 3802.9 | bsz 100.8 | num_updates 26587 | lr 0.000969695 | gnorm 0.264 | loss_scale 8 | train_wall 1063 | gb_free 12.8 | wall 4445\n",
            "2023-06-11 10:49:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6648\n",
            "epoch 005:   0% 0/6648 [00:00<?, ?it/s]2023-06-11 10:49:04 | INFO | fairseq.trainer | begin training epoch 5\n",
            "2023-06-11 10:49:04 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 005: 100% 6646/6648 [18:14<00:00,  6.98it/s, loss=5.945, nll_loss=2.97, ppl=7.83, wps=22458.4, ups=5.98, wpb=3756.1, bsz=92.5, num_updates=33200, lr=0.000867763, gnorm=0.257, loss_scale=16, train_wall=16, gb_free=12.9, wall=5535]2023-06-11 11:07:20 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:   0% 0/29 [00:00<?, ?it/s]\u001b[A2023-06-11 11:07:20 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] با آن, [SEP]\n",
            "2023-06-11 11:07:20 | INFO | fairseq.tasks.translation | example reference: [CLS] خدا ##حافظ, [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:   3% 1/29 [00:00<00:21,  1.28it/s]\u001b[A2023-06-11 11:07:21 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] آیا خوب است? [SEP]\n",
            "2023-06-11 11:07:21 | INFO | fairseq.tasks.translation | example reference: [CLS] آیا آن خوب است? [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:   7% 2/29 [00:01<00:18,  1.48it/s]\u001b[A2023-06-11 11:07:22 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"احمد یک زمان را انتخاب میکند, [SEP]\n",
            "2023-06-11 11:07:22 | INFO | fairseq.tasks.translation | example reference: [CLS] او ##ه زمان را گرفت ##م, [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  10% 3/29 [00:02<00:19,  1.30it/s]\u001b[A2023-06-11 11:07:23 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] ظهر در این ##جا ج ##ری ##مه خواهد شد. [SEP]\n",
            "2023-06-11 11:07:23 | INFO | fairseq.tasks.translation | example reference: [CLS] در این ##جا ظهر خوب خواهد بود. [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  14% 4/29 [00:03<00:20,  1.24it/s]\u001b[A2023-06-11 11:07:23 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] پس ما جمع ##ه ه ##شت ##م را جمع خ ##وا ##هیم کرد, [SEP]\n",
            "2023-06-11 11:07:23 | INFO | fairseq.tasks.translation | example reference: [CLS] پس شد جمع ##ه ه ##شت ##م, [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  17% 5/29 [00:03<00:19,  1.25it/s]\u001b[A2023-06-11 11:07:24 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"احمد ##ی که برای شما خوب است, [SEP]\n",
            "2023-06-11 11:07:24 | INFO | fairseq.tasks.translation | example reference: [CLS] چه چیزی برای شما مناسب است, [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  21% 6/29 [00:04<00:18,  1.24it/s]\u001b[A2023-06-11 11:07:25 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"احمد هر جمع ##ه, خدا ج ##ری ##مه است. [SEP]\n",
            "2023-06-11 11:07:25 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##ه, خدا, هر جمع ##ه - ای خوب است. [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  24% 7/29 [00:05<00:18,  1.19it/s]\u001b[A2023-06-11 11:07:26 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] به طور کامل, آن ##گاه شما را با آن می ##بین ##ید [SEP]\n",
            "2023-06-11 11:07:26 | INFO | fairseq.tasks.translation | example reference: [CLS] بسیار خوب, به ام ##ید دید ##ار, خدا ##حافظ, [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  28% 8/29 [00:06<00:16,  1.24it/s]\u001b[A2023-06-11 11:07:27 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] اما, \"بعد از ظهر بیست و دوم, [SEP]\n",
            "2023-06-11 11:07:27 | INFO | fairseq.tasks.translation | example reference: [CLS] اما, آ ##ه بعد ##از ##ظهر بیست و دوم, [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  31% 9/29 [00:07<00:18,  1.06it/s]\u001b[A2023-06-11 11:07:28 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] و نو ##زدهم وقت ##م آزاد است, [SEP]\n",
            "2023-06-11 11:07:28 | INFO | fairseq.tasks.translation | example reference: [CLS] و نو ##زدهم نیز تا ساعت چهار آزاد ه ##ست ##م. [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  34% 10/29 [00:08<00:17,  1.10it/s]\u001b[A2023-06-11 11:07:29 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] روز سه ش ##ن ##به, هر زمان بعد از دو ##از ##ده ساعت به طور کامل, [SEP]\n",
            "2023-06-11 11:07:29 | INFO | fairseq.tasks.translation | example reference: [CLS] سه - ش ##ن ##به, هر زمانی بعد از دو ##از ##ده مناسب خواهد بود, [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  38% 11/29 [00:09<00:15,  1.14it/s]\u001b[A2023-06-11 11:07:30 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] بل ##ه, خوب است اگر به دفتر ##تان بی ##اید. [SEP]\n",
            "2023-06-11 11:07:30 | INFO | fairseq.tasks.translation | example reference: [CLS] بل ##ه, این خوب است اگر من به دفتر شما بی ##ای ##م. [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  41% 12/29 [00:09<00:14,  1.20it/s]\u001b[A2023-06-11 11:07:30 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"\" \"\" \"\" \"\" \"\" \"\" [SEP]\n",
            "2023-06-11 11:07:30 | INFO | fairseq.tasks.translation | example reference: [CLS] من از سه تا چهار و ن ##یم ج ##لس ##ه دار ##م, [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  45% 13/29 [00:10<00:13,  1.19it/s]\u001b[A2023-06-11 11:07:31 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] آیا در چند هفت ##ه ی آ ##ینده زمانی که شما آزاد ه ##ستی ##د? [SEP]\n",
            "2023-06-11 11:07:31 | INFO | fairseq.tasks.translation | example reference: [CLS] زمانی در دو هفت ##هی آ ##ینده وجود دارد که شما آزاد با ##شی? [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  48% 14/29 [00:11<00:12,  1.20it/s]\u001b[A2023-06-11 11:07:32 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] من از سی - ام بیرون از شهر ه ##ست ##م. [SEP]\n",
            "2023-06-11 11:07:32 | INFO | fairseq.tasks.translation | example reference: [CLS] من از سی ##م تا سوم خارج از شهر ه ##ست ##م. [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  52% 15/29 [00:12<00:10,  1.32it/s]\u001b[A2023-06-11 11:07:32 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"هفت ##ه بعد از آن, هفت ##ه نو ##زدهم چ ##طور است? [SEP]\n",
            "2023-06-11 11:07:32 | INFO | fairseq.tasks.translation | example reference: [CLS] او ##ه در مورد هفت ##ه - ی بعد از آن چ ##طور است. هفت ##ه - ی نو ##زدهم? [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  55% 16/29 [00:12<00:09,  1.37it/s]\u001b[A2023-06-11 11:07:33 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] ه ##ف ##دهم, یا بیست و چهارم خوب خواهد بود. \"[SEP]\n",
            "2023-06-11 11:07:33 | INFO | fairseq.tasks.translation | example reference: [CLS] هر دو ##ی ه ##ف ##دهم, یا بیست و چهارم خوب خ ##وا ##هن ##د بود, او ##ه ##وم, [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  59% 17/29 [00:13<00:08,  1.43it/s]\u001b[A2023-06-11 11:07:34 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"\" \"\" \"\" \"\" \"\" \"این هفت ##ه ب ##د است. برنامه ی شما در هفت ##ه آ ##ینده به نظر میرسد.\" [SEP]\n",
            "2023-06-11 11:07:34 | INFO | fairseq.tasks.translation | example reference: [CLS] او ##م تمام این هفت ##ه ب ##د است. برنامه شما در هفت ##ه آ ##ینده چ ##گونه است. [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  62% 18/29 [00:14<00:07,  1.55it/s]\u001b[A2023-06-11 11:07:34 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] با ##ش ##ه, باید ب ##گو ##یی ##م که بین دو و چهار نفر, دو ##شن ##به ه ##شت ##م? [SEP]\n",
            "2023-06-11 11:07:34 | INFO | fairseq.tasks.translation | example reference: [CLS] باشد, میتوان ##یم ب ##گو ##یی ##م دو تا چهار? روز دو ##شن ##به, ه ##شت ##م? [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  66% 19/29 [00:14<00:06,  1.56it/s]\u001b[A2023-06-11 11:07:35 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"بل ##ه, س ##لام س ##لام برای من س ##لام ک ##ن.\" \"\" [SEP]\n",
            "2023-06-11 11:07:35 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##ه بل ##ه, س ##لام من را به خان ##م ایک ##س با ح ##روف کوچک بر ##سان. ام, [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  69% 20/29 [00:15<00:05,  1.58it/s]\u001b[A2023-06-11 11:07:35 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] پس اگر من یک ساعت برای ن ##اه ##ار داشت ##م, یک ساعت برای من خوب است, [SEP]\n",
            "2023-06-11 11:07:35 | INFO | fairseq.tasks.translation | example reference: [CLS] بنابراین اگر من ساعت ##ی را برای ن ##اه ##ار داشته با ##شم, ساعت یک برای من خوب خواهد بود, [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  72% 21/29 [00:15<00:04,  1.65it/s]\u001b[A2023-06-11 11:07:36 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] من میتوان ##م با دو نفر مل ##اقات ک ##ن ##م, اما شما می ##خ ##وا ##هی ##د با م ##را در پارک لیگ کوچک مل ##اقات ک ##ن ##م. [SEP]\n",
            "2023-06-11 11:07:36 | INFO | fairseq.tasks.translation | example reference: [CLS] من شما را ساعت دو می ##بین ##م, اما باید هم ##دی ##گر را در پارک لیگ کوچک ب ##بین ##یم. [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  76% 22/29 [00:16<00:04,  1.71it/s]\u001b[A2023-06-11 11:07:37 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"\" \"\" \"\" \"\" روز پنج ##شن ##به سی - ام, و چهار ##شن ##به بیست و نه ##م, کتاب ر ##زر ##و شده است. \"[SEP]\n",
            "2023-06-11 11:07:37 | INFO | fairseq.tasks.translation | example reference: [CLS] ام خ ##یلی زیاد سه - ش ##ن ##به سی - ام و چهار ##شن ##به بیست و نه ##م پر هستند. [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  79% 23/29 [00:17<00:03,  1.65it/s]\u001b[A2023-06-11 11:07:37 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"احمد چ ##طور در ##بار ##ه چهار ##دهم یا ه ##ف ##دهم یا ه ##ف ##دهم یا هر دو این دو روز, متن ##اسب با برنامه شما مناسب است? [SEP]\n",
            "2023-06-11 11:07:37 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##ه چهار ##دهم یا ه ##ف ##دهم چه ##طور. آیا هیچ ##ک ##دام از آن دو روز, با برنامه ##ریزی شما مناسب است? [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  83% 24/29 [00:17<00:03,  1.50it/s]\u001b[A2023-06-11 11:07:38 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] روز چهار ##شن ##به برای من آزاد است, بنابراین این کار برای شما خوب خواهد بود, [SEP]\n",
            "2023-06-11 11:07:38 | INFO | fairseq.tasks.translation | example reference: [CLS] من چهار ##شن ##به کامل ##ا آزاد ه ##ست ##م, اگر برای شما مناسب است, عالی است, [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  86% 25/29 [00:18<00:02,  1.37it/s]\u001b[A2023-06-11 11:07:39 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] بل ##ه, مانند \"احمد, من هیچ وقت در بعد از ظهر برای من خوب نیست ##م, پنج ##شن ##به ه ##شت ##م, پنج ##شن ##به ه ##شت ##م خوب است.\" [SEP]\n",
            "2023-06-11 11:07:39 | INFO | fairseq.tasks.translation | example reference: [CLS] بل ##ه, مثل, ن ##می ##دان ##م, هر زمان ##ن از بعد از ظهر پنج ##شن ##به ه ##شت ##م برای من مناسب است. [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  90% 26/29 [00:19<00:02,  1.33it/s]\u001b[A2023-06-11 11:07:40 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] من یک س ##مین ##ار دار ##م, همه روز, بیست و هفت ##م است که من آن هفت ##ه ه ##ست ##م, نه کامل ##ا آن هفت ##ه. [SEP]\n",
            "2023-06-11 11:07:40 | INFO | fairseq.tasks.translation | example reference: [CLS] من در تمام روز بیست - و هفت ##م یک س ##مین ##ار دار ##م. آن روز ##ی است که در آن هفت ##ه, من به - طور کامل آزاد نیست ##م. [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  93% 27/29 [00:20<00:01,  1.32it/s]\u001b[A2023-06-11 11:07:41 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"احمد ##ی است که ش ##اید ش ##اید ش ##اید ش ##اید ش ##اید ش ##اید ش ##اید ش ##اید ش ##اید هم ش ##اید ش ##اید در\" هو ##لی ##هان \"یا\" باغ و ##رزش ##ی \", در میدان و ##رزش ##ی, در میدان و ##رزش ##ی\n",
            "2023-06-11 11:07:41 | INFO | fairseq.tasks.translation | example reference: [CLS] عالی است. ش ##اید ب ##تو ##انی ##م هم ##دی ##گر را ##در ها ##لی ##هان ##ز, باغ و ##رزش یا میدان است ##یش ##ن ب ##بین ##یم و در مورد کار ص ##حبت ک ##نی ##م. [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  97% 28/29 [00:21<00:00,  1.29it/s]\u001b[A2023-06-11 11:07:41 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"[SEP]\n",
            "2023-06-11 11:07:41 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##ه به - نظر ن ##می ##رس ##د که من ب ##تو ##ان ##م کد ال ##کت ##ریکی را برای اجرا مه ##یا ک ##ن ##م, من نیاز دار ##م که آ ##ه با تو زمانی دوباره برای حدود بیش از دو ساعت, در این هفت ##ه مل ##اقات ک ##ن ##م. کی برای تو خوب است. [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset: 100% 29/29 [00:21<00:00,  1.41it/s]\u001b[A\n",
            "                                                                        \u001b[A2023-06-11 11:07:41 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 5.655 | nll_loss 2.609 | ppl 6.1 | bleu 45.24 | wps 3431.4 | wpb 2556.5 | bsz 137.9 | num_updates 33235 | best_bleu 45.24\n",
            "2023-06-11 11:07:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 33235 updates\n",
            "2023-06-11 11:07:41 | INFO | fairseq.trainer | Saving checkpoint to /content/content/drive/MyDrive/mbert/checkpoints/checkpoint5.pt\n",
            "2023-06-11 11:07:44 | INFO | fairseq.trainer | Finished saving checkpoint to /content/content/drive/MyDrive/mbert/checkpoints/checkpoint5.pt\n",
            "2023-06-11 11:07:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./content/drive/MyDrive/mbert/checkpoints/checkpoint5.pt (epoch 5 @ 33235 updates, score 45.24) (writing took 6.8856554409994715 seconds)\n",
            "2023-06-11 11:07:48 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)\n",
            "2023-06-11 11:07:48 | INFO | train | epoch 005 | loss 5.934 | nll_loss 2.952 | ppl 7.74 | wps 22497.1 | ups 5.92 | wpb 3802.9 | bsz 100.8 | num_updates 33235 | lr 0.000867306 | gnorm 0.259 | loss_scale 16 | train_wall 1068 | gb_free 12.7 | wall 5569\n",
            "2023-06-11 11:07:48 | INFO | fairseq_cli.train | done training in 5566.5 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!fairseq-generate \\\n",
        "    /content/drive/MyDrive/NLP/CA5/mbert_data_dir \\\n",
        "    --batch-size 128 \\\n",
        "    --path \"./content/drive/MyDrive/mbert/checkpoints/checkpoint_best.pt\" \\\n",
        "    --beam 5 > \"./content/drive/MyDrive/mbert/new_eval.txt\""
      ],
      "metadata": {
        "id": "dSKnYEBc9T7r",
        "outputId": "40bcfb64-af1f-4030-88a8-b639aad02d9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-11 11:18:50.196899: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-06-11 11:18:54 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2023-06-11 11:18:57 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': './content/drive/MyDrive/mbert/checkpoints/checkpoint_best.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 128, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 128, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}, 'task': {'_name': 'translation', 'data': '/content/drive/MyDrive/NLP/CA5/mbert_data_dir', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
            "2023-06-11 11:18:57 | INFO | fairseq.tasks.translation | [en] dictionary: 33216 types\n",
            "2023-06-11 11:18:57 | INFO | fairseq.tasks.translation | [fa] dictionary: 33216 types\n",
            "2023-06-11 11:18:57 | INFO | fairseq_cli.generate | loading model(s) from ./content/drive/MyDrive/mbert/checkpoints/checkpoint_best.pt\n",
            "2023-06-11 11:19:15 | INFO | fairseq.utils | found 33212/33216 types in embedding file\n",
            "2023-06-11 11:19:16 | INFO | fairseq.data.data_utils | loaded 10,000 examples from: /content/drive/MyDrive/NLP/CA5/mbert_data_dir/test.en-fa.en\n",
            "2023-06-11 11:19:16 | INFO | fairseq.data.data_utils | loaded 10,000 examples from: /content/drive/MyDrive/NLP/CA5/mbert_data_dir/test.en-fa.fa\n",
            "2023-06-11 11:19:16 | INFO | fairseq.tasks.translation | /content/drive/MyDrive/NLP/CA5/mbert_data_dir test en-fa 10000 examples\n",
            "2023-06-11 11:20:53 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2023-06-11 11:20:53 | INFO | fairseq_cli.generate | Translated 10,000 sentences (168,943 tokens) in 39.3s (254.13 sentences/s, 4293.41 tokens/s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp ./mbert_dict_embeddings_new.txt /content/drive/MyDrive/NLP/CA5/mbert_tokenized_data"
      ],
      "metadata": {
        "id": "_37KtA6KvlHg"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/content/drive/MyDrive/mbert /content/drive/MyDrive/mbert_new\n",
        "!cp  /content/content/drive/MyDrive/mbert/new_eval.txt /content/drive/MyDrive/mbert_new/new_eval.txt"
      ],
      "metadata": {
        "id": "DOp41W0Z8oGh"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!fairseq-train \\\n",
        "  /content/drive/MyDrive/NLP/CA5/mbert_data_dir \\\n",
        "  --arch lstm --encoder-freeze-embed --decoder-freeze-embed --share-decoder-input-output-embed --share-all-embeddings --encoder-embed-dim 768 --decoder-embed-dim 768 --decoder-out-embed-dim 768 --encoder-embed-path /content/mbert_dict_embeddings_new.txt   \\\n",
        "  --optimizer adam --adam-betas '(0.9,0.98)' --clip-norm 0.0 \\\n",
        "  --lr 2.5e-3 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\n",
        "  --dropout 0.25 --weight-decay 0.0001 \\\n",
        "  --criterion label_smoothed_cross_entropy --label-smoothing 0.2 \\\n",
        "  --max-tokens 4096 \\\n",
        "  --eval-bleu \\\n",
        "  --eval-bleu-args '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}' \\\n",
        "  --eval-bleu-detok moses \\\n",
        "  --eval-bleu-print-samples \\\n",
        "  --best-checkpoint-metric bleu --maximize-best-checkpoint-metric \\\n",
        "  --fp16 --memory-efficient-fp16 \\\n",
        "  --max-epoch 5 \\\n",
        "  --save-dir ./content/drive/MyDrive/mbert_frozen/checkpoints/ \\\n",
        "  --tensorboard-logdir ./content/drive/MyDrive/mbert_frozen/log/\n",
        "\n"
      ],
      "metadata": {
        "id": "mdSRkPht-jKY",
        "outputId": "a467199a-38fe-45bb-85fa-badda019b165",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-11 11:23:31.174400: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-06-11 11:23:33 | INFO | numexpr.utils | NumExpr defaulting to 2 threads.\n",
            "2023-06-11 11:23:33 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2023-06-11 11:23:36 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './content/drive/MyDrive/mbert_frozen/log/', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': True, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': True, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4096, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4096, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 5, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0025], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './content/drive/MyDrive/mbert_frozen/checkpoints/', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir='./content/drive/MyDrive/mbert_frozen/log/', wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=True, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', scoring='bleu', task='translation', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4096, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=4096, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='lstm', max_epoch=5, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.0025], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='./content/drive/MyDrive/mbert_frozen/checkpoints/', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='bleu', maximize_best_checkpoint_metric=True, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, share_decoder_input_output_embed=True, share_all_embeddings=True, data='/content/drive/MyDrive/NLP/CA5/mbert_data_dir', source_lang=None, target_lang=None, load_alignments=False, left_pad_source=True, left_pad_target=False, max_source_positions=1024, max_target_positions=1024, upsample_primary=-1, truncate_source=False, num_batch_buckets=0, eval_bleu=True, eval_bleu_args='{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_tokenized_bleu=False, eval_bleu_remove_bpe=None, eval_bleu_print_samples=True, label_smoothing=0.2, report_accuracy=False, ignore_prefix_size=0, adam_betas='(0.9,0.98)', adam_eps=1e-08, weight_decay=0.0001, use_old_adam=False, fp16_adam_stats=False, warmup_updates=4000, warmup_init_lr=-1, pad=1, eos=2, unk=3, encoder_freeze_embed=True, decoder_freeze_embed=True, encoder_embed_dim=768, decoder_embed_dim=768, decoder_out_embed_dim=768, encoder_embed_path='/content/mbert_dict_embeddings_new.txt', dropout=0.25, no_seed_provided=False, encoder_hidden_size=768, encoder_layers=1, encoder_bidirectional=False, encoder_dropout_in=0.25, encoder_dropout_out=0.25, decoder_embed_path=None, decoder_hidden_size=768, decoder_layers=1, decoder_attention='1', decoder_dropout_in=0.25, decoder_dropout_out=0.25, adaptive_softmax_cutoff='10000,50000,200000', _name='lstm'), 'task': {'_name': 'translation', 'data': '/content/drive/MyDrive/NLP/CA5/mbert_data_dir', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.2, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0025]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0025]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
            "2023-06-11 11:23:36 | INFO | fairseq.tasks.translation | [en] dictionary: 33216 types\n",
            "2023-06-11 11:23:36 | INFO | fairseq.tasks.translation | [fa] dictionary: 33216 types\n",
            "2023-06-11 11:23:54 | INFO | fairseq.utils | found 33212/33216 types in embedding file\n",
            "2023-06-11 11:23:55 | INFO | fairseq_cli.train | LSTMModel(\n",
            "  (encoder): LSTMEncoder(\n",
            "    (dropout_in_module): FairseqDropout()\n",
            "    (dropout_out_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(33216, 768, padding_idx=1)\n",
            "    (lstm): LSTM(768, 768)\n",
            "  )\n",
            "  (decoder): LSTMDecoder(\n",
            "    (dropout_in_module): FairseqDropout()\n",
            "    (dropout_out_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(33216, 768, padding_idx=1)\n",
            "    (layers): ModuleList(\n",
            "      (0): LSTMCell(1536, 768)\n",
            "    )\n",
            "    (attention): AttentionLayer(\n",
            "      (input_proj): Linear(in_features=768, out_features=768, bias=False)\n",
            "      (output_proj): Linear(in_features=1536, out_features=768, bias=False)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "2023-06-11 11:23:55 | INFO | fairseq_cli.train | task: TranslationTask\n",
            "2023-06-11 11:23:55 | INFO | fairseq_cli.train | model: LSTMModel\n",
            "2023-06-11 11:23:55 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion\n",
            "2023-06-11 11:23:55 | INFO | fairseq_cli.train | num. shared model params: 39,088,128 (num. trained: 13,578,240)\n",
            "2023-06-11 11:23:55 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2023-06-11 11:23:55 | INFO | fairseq.data.data_utils | loaded 4,000 examples from: /content/drive/MyDrive/NLP/CA5/mbert_data_dir/valid.en-fa.en\n",
            "2023-06-11 11:23:55 | INFO | fairseq.data.data_utils | loaded 4,000 examples from: /content/drive/MyDrive/NLP/CA5/mbert_data_dir/valid.en-fa.fa\n",
            "2023-06-11 11:23:55 | INFO | fairseq.tasks.translation | /content/drive/MyDrive/NLP/CA5/mbert_data_dir valid en-fa 4000 examples\n",
            "2023-06-11 11:23:59 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight\n",
            "2023-06-11 11:23:59 | INFO | fairseq.trainer | detected shared parameter: decoder.attention.input_proj.bias <- decoder.attention.output_proj.bias\n",
            "2023-06-11 11:23:59 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2023-06-11 11:23:59 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 14.748 GB ; name = Tesla T4                                \n",
            "2023-06-11 11:23:59 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2023-06-11 11:23:59 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2023-06-11 11:23:59 | INFO | fairseq_cli.train | max tokens per device = 4096 and max sentences per device = None\n",
            "2023-06-11 11:23:59 | INFO | fairseq.trainer | Preparing to load checkpoint ./content/drive/MyDrive/mbert_frozen/checkpoints/checkpoint_last.pt\n",
            "2023-06-11 11:23:59 | INFO | fairseq.trainer | No existing checkpoint found ./content/drive/MyDrive/mbert_frozen/checkpoints/checkpoint_last.pt\n",
            "2023-06-11 11:23:59 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2023-06-11 11:23:59 | INFO | fairseq.data.data_utils | loaded 670,000 examples from: /content/drive/MyDrive/NLP/CA5/mbert_data_dir/train.en-fa.en\n",
            "2023-06-11 11:24:00 | INFO | fairseq.data.data_utils | loaded 670,000 examples from: /content/drive/MyDrive/NLP/CA5/mbert_data_dir/train.en-fa.fa\n",
            "2023-06-11 11:24:00 | INFO | fairseq.tasks.translation | /content/drive/MyDrive/NLP/CA5/mbert_data_dir train en-fa 670000 examples\n",
            "2023-06-11 11:24:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6648\n",
            "epoch 001:   0% 0/6648 [00:00<?, ?it/s]2023-06-11 11:24:00 | INFO | fairseq.trainer | begin training epoch 1\n",
            "2023-06-11 11:24:00 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "/usr/local/lib/python3.10/dist-packages/fairseq/utils.py:374: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library\n",
            "  warnings.warn(\n",
            "2023-06-11 11:24:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0\n",
            "epoch 001:   0% 1/6648 [00:01<2:46:05,  1.50s/it]2023-06-11 11:24:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0\n",
            "epoch 001:   0% 2/6648 [00:01<1:21:54,  1.35it/s]2023-06-11 11:24:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0\n",
            "epoch 001:   0% 3/6648 [00:01<50:26,  2.20it/s]  2023-06-11 11:24:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0\n",
            "epoch 001:   0% 6/6648 [00:02<28:48,  3.84it/s]2023-06-11 11:24:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0\n",
            "epoch 001: 100% 6647/6648 [15:35<00:00,  4.78it/s, loss=7.915, nll_loss=5.227, ppl=37.44, wps=26337.2, ups=6.89, wpb=3819.8, bsz=102.4, num_updates=6600, lr=0.00194625, gnorm=0.435, loss_scale=4, train_wall=14, gb_free=13.1, wall=930]2023-06-11 11:39:35 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:   0% 0/29 [00:00<?, ?it/s]\u001b[A2023-06-11 11:39:37 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] توسط, [SEP]\n",
            "2023-06-11 11:39:37 | INFO | fairseq.tasks.translation | example reference: [CLS] خدا ##حافظ, [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:   3% 1/29 [00:01<00:39,  1.40s/it]\u001b[A2023-06-11 11:39:37 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] آیا این م ##س ##أ ##له خوب است? [SEP]\n",
            "2023-06-11 11:39:37 | INFO | fairseq.tasks.translation | example reference: [CLS] آیا آن خوب است? [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:   7% 2/29 [00:02<00:25,  1.06it/s]\u001b[A2023-06-11 11:39:38 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"یک زمان, [SEP]\n",
            "2023-06-11 11:39:38 | INFO | fairseq.tasks.translation | example reference: [CLS] او ##ه زمان را گرفت ##م, [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  10% 3/29 [00:03<00:25,  1.03it/s]\u001b[A2023-06-11 11:39:39 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] در این ##جا خواهد بود. [SEP]\n",
            "2023-06-11 11:39:39 | INFO | fairseq.tasks.translation | example reference: [CLS] در این ##جا ظهر خوب خواهد بود. [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  14% 4/29 [00:03<00:21,  1.18it/s]\u001b[A2023-06-11 11:39:40 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] ما روز جمع ##ه ه ##شت ##م, [SEP]\n",
            "2023-06-11 11:39:40 | INFO | fairseq.tasks.translation | example reference: [CLS] پس شد جمع ##ه ه ##شت ##م, [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  17% 5/29 [00:04<00:17,  1.34it/s]\u001b[A2023-06-11 11:39:40 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"خ ##یلی خوب است, [SEP]\n",
            "2023-06-11 11:39:40 | INFO | fairseq.tasks.translation | example reference: [CLS] چه چیزی برای شما مناسب است, [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  21% 6/29 [00:04<00:15,  1.44it/s]\u001b[A2023-06-11 11:39:41 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"خ ##ب, هر جمع ##ه روز جمع ##ه است. [SEP]\n",
            "2023-06-11 11:39:41 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##ه, خدا, هر جمع ##ه - ای خوب است. [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  24% 7/29 [00:05<00:14,  1.49it/s]\u001b[A2023-06-11 11:39:41 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] ال ##ان, [SEP]\n",
            "2023-06-11 11:39:41 | INFO | fairseq.tasks.translation | example reference: [CLS] بسیار خوب, به ام ##ید دید ##ار, خدا ##حافظ, [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  28% 8/29 [00:05<00:13,  1.61it/s]\u001b[A2023-06-11 11:39:42 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] اما یک ش ##ن ##به, [SEP]\n",
            "2023-06-11 11:39:42 | INFO | fairseq.tasks.translation | example reference: [CLS] اما, آ ##ه بعد ##از ##ظهر بیست و دوم, [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  31% 9/29 [00:06<00:12,  1.63it/s]\u001b[A2023-06-11 11:39:43 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] و من تا چهار ##شن ##به را می ##کن ##م, [SEP]\n",
            "2023-06-11 11:39:43 | INFO | fairseq.tasks.translation | example reference: [CLS] و نو ##زدهم نیز تا ساعت چهار آزاد ه ##ست ##م. [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  34% 10/29 [00:07<00:11,  1.66it/s]\u001b[A2023-06-11 11:39:43 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] در روز سه ش ##ن ##به پس از اینکه نه نفر, [SEP]\n",
            "2023-06-11 11:39:43 | INFO | fairseq.tasks.translation | example reference: [CLS] سه - ش ##ن ##به, هر زمانی بعد از دو ##از ##ده مناسب خواهد بود, [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  38% 11/29 [00:07<00:10,  1.67it/s]\u001b[A2023-06-11 11:39:44 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] بل ##ه, خوب است. [SEP]\n",
            "2023-06-11 11:39:44 | INFO | fairseq.tasks.translation | example reference: [CLS] بل ##ه, این خوب است اگر من به دفتر شما بی ##ای ##م. [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  41% 12/29 [00:08<00:09,  1.72it/s]\u001b[A2023-06-11 11:39:44 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] من یک ج ##لس ##ه را از سه تا چهار ش ##ن ##به, [SEP]\n",
            "2023-06-11 11:39:44 | INFO | fairseq.tasks.translation | example reference: [CLS] من از سه تا چهار و ن ##یم ج ##لس ##ه دار ##م, [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  45% 13/29 [00:08<00:09,  1.68it/s]\u001b[A2023-06-11 11:39:45 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] آیا زمانی که شما می ##خ ##وا ##هی ##د را آزاد ک ##ن ##م? [SEP]\n",
            "2023-06-11 11:39:45 | INFO | fairseq.tasks.translation | example reference: [CLS] زمانی در دو هفت ##هی آ ##ینده وجود دارد که شما آزاد با ##شی? [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  48% 14/29 [00:09<00:08,  1.67it/s]\u001b[A2023-06-11 11:39:45 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] من از این شهر از طریق سوم ##ین م ##ح ##کو ##م کرد ##م. [SEP]\n",
            "2023-06-11 11:39:45 | INFO | fairseq.tasks.translation | example reference: [CLS] من از سی ##م تا سوم خارج از شهر ه ##ست ##م. [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  52% 15/29 [00:10<00:08,  1.67it/s]\u001b[A2023-06-11 11:39:46 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] در این هفت ##ه, این هفت ##ه پس از آن چ ##یست? [SEP]\n",
            "2023-06-11 11:39:46 | INFO | fairseq.tasks.translation | example reference: [CLS] او ##ه در مورد هفت ##ه - ی بعد از آن چ ##طور است. هفت ##ه - ی نو ##زدهم? [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  55% 16/29 [00:10<00:07,  1.63it/s]\u001b[A2023-06-11 11:39:47 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] یا بیست و شش ##م یا بیست و شش ##م, [SEP]\n",
            "2023-06-11 11:39:47 | INFO | fairseq.tasks.translation | example reference: [CLS] هر دو ##ی ه ##ف ##دهم, یا بیست و چهارم خوب خ ##وا ##هن ##د بود, او ##ه ##وم, [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  59% 17/29 [00:11<00:07,  1.56it/s]\u001b[A2023-06-11 11:39:48 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] در این هفت ##ه, این هفت ##ه در این هفت ##ه است. [SEP]\n",
            "2023-06-11 11:39:48 | INFO | fairseq.tasks.translation | example reference: [CLS] او ##م تمام این هفت ##ه ب ##د است. برنامه شما در هفت ##ه آ ##ینده چ ##گونه است. [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  62% 18/29 [00:12<00:07,  1.51it/s]\u001b[A2023-06-11 11:39:48 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] آیا باید ب ##گو ##یی ##م, بین ه ##شت ##م و چهار چ ##یست? [SEP]\n",
            "2023-06-11 11:39:48 | INFO | fairseq.tasks.translation | example reference: [CLS] باشد, میتوان ##یم ب ##گو ##یی ##م دو تا چهار? روز دو ##شن ##به, ه ##شت ##م? [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  66% 19/29 [00:12<00:07,  1.41it/s]\u001b[A2023-06-11 11:39:49 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"خ ##وا ##هن ##د بود. [SEP]\n",
            "2023-06-11 11:39:49 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##ه بل ##ه, س ##لام من را به خان ##م ایک ##س با ح ##روف کوچک بر ##سان. ام, [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  69% 20/29 [00:13<00:06,  1.33it/s]\u001b[A2023-06-11 11:39:50 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] در صورت ##ی که من در مورد یک ساعت با من با من خ ##وا ##هن ##د بود, [SEP]\n",
            "2023-06-11 11:39:50 | INFO | fairseq.tasks.translation | example reference: [CLS] بنابراین اگر من ساعت ##ی را برای ن ##اه ##ار داشته با ##شم, ساعت یک برای من خوب خواهد بود, [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  72% 21/29 [00:14<00:05,  1.34it/s]\u001b[A2023-06-11 11:39:51 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] من میتوان ##ید در دو تن از شما ب ##گو ##یی ##د, اما شما می ##خ ##وا ##هی ##د تا من را به من می ##پ ##ذیر ##م. [SEP]\n",
            "2023-06-11 11:39:51 | INFO | fairseq.tasks.translation | example reference: [CLS] من شما را ساعت دو می ##بین ##م, اما باید هم ##دی ##گر را در پارک لیگ کوچک ب ##بین ##یم. [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  76% 22/29 [00:15<00:05,  1.33it/s]\u001b[A2023-06-11 11:39:52 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"ا ##ف ##زون بر آن, پنج ##شن ##به, ش ##ن ##به و پنج ##شن ##به ه ##شت ##م. [SEP]\n",
            "2023-06-11 11:39:52 | INFO | fairseq.tasks.translation | example reference: [CLS] ام خ ##یلی زیاد سه - ش ##ن ##به سی - ام و چهار ##شن ##به بیست و نه ##م پر هستند. [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  79% 23/29 [00:16<00:04,  1.29it/s]\u001b[A2023-06-11 11:39:52 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"چ ##گونه ه ##شت یا ه ##شت ##م یا هفت روز, به برنامه ی شما به برنامه ی شما به برنامه شما به برنامه ی شما می ##پ ##ذیر ##د? [SEP]\n",
            "2023-06-11 11:39:52 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##ه چهار ##دهم یا ه ##ف ##دهم چه ##طور. آیا هیچ ##ک ##دام از آن دو روز, با برنامه ##ریزی شما مناسب است? [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  83% 24/29 [00:17<00:04,  1.25it/s]\u001b[A2023-06-11 11:39:53 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] روز چهار ##شن ##به, همه چیز آزاد است, [SEP]\n",
            "2023-06-11 11:39:53 | INFO | fairseq.tasks.translation | example reference: [CLS] من چهار ##شن ##به کامل ##ا آزاد ه ##ست ##م, اگر برای شما مناسب است, عالی است, [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  86% 25/29 [00:17<00:03,  1.29it/s]\u001b[A2023-06-11 11:39:54 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] بل ##ه, مانند \"من ن ##می ##دان ##م, هیچ روز پنج ش ##ن ##به ن ##می ##دان ##م, روز پنج ش ##ن ##به ه ##شت ##م. [SEP]\n",
            "2023-06-11 11:39:54 | INFO | fairseq.tasks.translation | example reference: [CLS] بل ##ه, مثل, ن ##می ##دان ##م, هر زمان ##ن از بعد از ظهر پنج ##شن ##به ه ##شت ##م برای من مناسب است. [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  90% 26/29 [00:18<00:02,  1.38it/s]\u001b[A2023-06-11 11:39:54 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] من در روز پنج ##شن ##به, همه روز هفت ##م, که یک روز ه ##ست ##م, که یک روز ه ##ست ##م, ن ##می ##دان ##م که یک روز ه ##ست ##م. [SEP]\n",
            "2023-06-11 11:39:54 | INFO | fairseq.tasks.translation | example reference: [CLS] من در تمام روز بیست - و هفت ##م یک س ##مین ##ار دار ##م. آن روز ##ی است که در آن هفت ##ه, من به - طور کامل آزاد نیست ##م. [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  93% 27/29 [00:18<00:01,  1.45it/s]\u001b[A2023-06-11 11:39:55 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] او گفت: \"خ ##وا ##هن ##د بود که ما ممکن است ب ##تو ##انی ##م با هم ب ##گو ##یی ##م. [SEP]\n",
            "2023-06-11 11:39:55 | INFO | fairseq.tasks.translation | example reference: [CLS] عالی است. ش ##اید ب ##تو ##انی ##م هم ##دی ##گر را ##در ها ##لی ##هان ##ز, باغ و ##رزش یا میدان است ##یش ##ن ب ##بین ##یم و در مورد کار ص ##حبت ک ##نی ##م. [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  97% 28/29 [00:19<00:00,  1.50it/s]\u001b[A2023-06-11 11:39:55 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"من ن ##می ##تو ##ان ##م به این م ##س ##أ ##له ف ##کر ک ##ن ##م که این ف ##ر ##صت را در این هفت ##ه می ##خ ##وا ##هن ##د که در این هفت ##ه با ##شی ##م. [SEP]\n",
            "2023-06-11 11:39:55 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##ه به - نظر ن ##می ##رس ##د که من ب ##تو ##ان ##م کد ال ##کت ##ریکی را برای اجرا مه ##یا ک ##ن ##م, من نیاز دار ##م که آ ##ه با تو زمانی دوباره برای حدود بیش از دو ساعت, در این هفت ##ه مل ##اقات ک ##ن ##م. کی برای تو خوب است. [SEP]\n",
            "\n",
            "epoch 001 | valid on 'valid' subset: 100% 29/29 [00:19<00:00,  1.70it/s]\u001b[A\n",
            "                                                                        \u001b[A2023-06-11 11:39:55 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.161 | nll_loss 4.325 | ppl 20.04 | bleu 31.14 | wps 3856.6 | wpb 2556.5 | bsz 137.9 | num_updates 6643\n",
            "2023-06-11 11:39:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 6643 updates\n",
            "2023-06-11 11:39:55 | INFO | fairseq.trainer | Saving checkpoint to /content/content/drive/MyDrive/mbert_frozen/checkpoints/checkpoint1.pt\n",
            "2023-06-11 11:40:02 | INFO | fairseq.trainer | Finished saving checkpoint to /content/content/drive/MyDrive/mbert_frozen/checkpoints/checkpoint1.pt\n",
            "2023-06-11 11:40:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./content/drive/MyDrive/mbert_frozen/checkpoints/checkpoint1.pt (epoch 1 @ 6643 updates, score 31.14) (writing took 9.057053024000197 seconds)\n",
            "2023-06-11 11:40:04 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n",
            "2023-06-11 11:40:04 | INFO | train | epoch 001 | loss 8.923 | nll_loss 6.503 | ppl 90.73 | wps 26245.9 | ups 6.9 | wpb 3802.9 | bsz 100.8 | num_updates 6643 | lr 0.00193994 | gnorm 0.866 | loss_scale 4 | train_wall 908 | gb_free 12.9 | wall 966\n",
            "2023-06-11 11:40:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6648\n",
            "epoch 002:   0% 0/6648 [00:00<?, ?it/s]2023-06-11 11:40:05 | INFO | fairseq.trainer | begin training epoch 2\n",
            "2023-06-11 11:40:05 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 002: 100% 6647/6648 [15:37<00:00,  9.04it/s, loss=7.575, nll_loss=4.797, ppl=27.81, wps=28377.2, ups=7.44, wpb=3813.4, bsz=105.9, num_updates=13200, lr=0.0013762, gnorm=0.416, loss_scale=4, train_wall=13, gb_free=12.9, wall=1890]2023-06-11 11:55:42 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:   0% 0/29 [00:00<?, ?it/s]\u001b[A2023-06-11 11:55:43 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] با این حال, [SEP]\n",
            "2023-06-11 11:55:43 | INFO | fairseq.tasks.translation | example reference: [CLS] خدا ##حافظ, [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:   3% 1/29 [00:00<00:21,  1.28it/s]\u001b[A2023-06-11 11:55:43 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] خ ##یلی خوب است? [SEP]\n",
            "2023-06-11 11:55:43 | INFO | fairseq.tasks.translation | example reference: [CLS] آیا آن خوب است? [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:   7% 2/29 [00:01<00:18,  1.44it/s]\u001b[A2023-06-11 11:55:44 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"یک زمان, [SEP]\n",
            "2023-06-11 11:55:44 | INFO | fairseq.tasks.translation | example reference: [CLS] او ##ه زمان را گرفت ##م, [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  10% 3/29 [00:02<00:17,  1.47it/s]\u001b[A2023-06-11 11:55:45 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] هیچ ##کس این ##جا خوب نیست. [SEP]\n",
            "2023-06-11 11:55:45 | INFO | fairseq.tasks.translation | example reference: [CLS] در این ##جا ظهر خوب خواهد بود. [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  14% 4/29 [00:02<00:16,  1.49it/s]\u001b[A2023-06-11 11:55:45 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] پس ما جمع ##ه ه ##شت ##م, [SEP]\n",
            "2023-06-11 11:55:45 | INFO | fairseq.tasks.translation | example reference: [CLS] پس شد جمع ##ه ه ##شت ##م, [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  17% 5/29 [00:03<00:15,  1.58it/s]\u001b[A2023-06-11 11:55:46 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"\" \"\" \"\" \"\" \"\" \"\" [SEP]\n",
            "2023-06-11 11:55:46 | INFO | fairseq.tasks.translation | example reference: [CLS] چه چیزی برای شما مناسب است, [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  21% 6/29 [00:04<00:15,  1.50it/s]\u001b[A2023-06-11 11:55:47 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] او گفت: \"خ ##وا ##ست ##ار روز جمع ##ه خوب است. [SEP]\n",
            "2023-06-11 11:55:47 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##ه, خدا, هر جمع ##ه - ای خوب است. [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  24% 7/29 [00:04<00:16,  1.34it/s]\u001b[A2023-06-11 11:55:47 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] و آن را ب ##بین ##ید, [SEP]\n",
            "2023-06-11 11:55:47 | INFO | fairseq.tasks.translation | example reference: [CLS] بسیار خوب, به ام ##ید دید ##ار, خدا ##حافظ, [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  28% 8/29 [00:05<00:15,  1.34it/s]\u001b[A2023-06-11 11:55:48 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] اما در بعد از ظهر بیست و دوم, [SEP]\n",
            "2023-06-11 11:55:48 | INFO | fairseq.tasks.translation | example reference: [CLS] اما, آ ##ه بعد ##از ##ظهر بیست و دوم, [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  31% 9/29 [00:06<00:15,  1.28it/s]\u001b[A2023-06-11 11:55:49 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] و بیست و شش ##م را آزاد می ##کن ##م, [SEP]\n",
            "2023-06-11 11:55:49 | INFO | fairseq.tasks.translation | example reference: [CLS] و نو ##زدهم نیز تا ساعت چهار آزاد ه ##ست ##م. [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  34% 10/29 [00:07<00:15,  1.25it/s]\u001b[A2023-06-11 11:55:50 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] روز سه ش ##ن ##به, هر کسی پس از اینکه نه تن از آنها, [SEP]\n",
            "2023-06-11 11:55:50 | INFO | fairseq.tasks.translation | example reference: [CLS] سه - ش ##ن ##به, هر زمانی بعد از دو ##از ##ده مناسب خواهد بود, [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  38% 11/29 [00:08<00:14,  1.21it/s]\u001b[A2023-06-11 11:55:51 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] بل ##ه, در صورت ##ی که من به دفتر شما می ##خ ##وا ##هم. [SEP]\n",
            "2023-06-11 11:55:51 | INFO | fairseq.tasks.translation | example reference: [CLS] بل ##ه, این خوب است اگر من به دفتر شما بی ##ای ##م. [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  41% 12/29 [00:09<00:13,  1.22it/s]\u001b[A2023-06-11 11:55:52 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" [SEP]\n",
            "2023-06-11 11:55:52 | INFO | fairseq.tasks.translation | example reference: [CLS] من از سه تا چهار و ن ##یم ج ##لس ##ه دار ##م, [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  45% 13/29 [00:09<00:12,  1.24it/s]\u001b[A2023-06-11 11:55:52 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] هر زمان در سه هفت ##ه آ ##ینده زمانی که شما آزاد ه ##ستی ##د? [SEP]\n",
            "2023-06-11 11:55:52 | INFO | fairseq.tasks.translation | example reference: [CLS] زمانی در دو هفت ##هی آ ##ینده وجود دارد که شما آزاد با ##شی? [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  48% 14/29 [00:10<00:11,  1.31it/s]\u001b[A2023-06-11 11:55:53 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] من از این شهر از \"خ ##ش ##ونت از طریق سوم از سوم\" از از بین رفت ##ن. [SEP]\n",
            "2023-06-11 11:55:53 | INFO | fairseq.tasks.translation | example reference: [CLS] من از سی ##م تا سوم خارج از شهر ه ##ست ##م. [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  52% 15/29 [00:11<00:10,  1.38it/s]\u001b[A2023-06-11 11:55:54 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] او گفت: \"در این هفت ##ه, این هفت ##ه پس از آن, هفت ##ه بیست و شش ##م? [SEP]\n",
            "2023-06-11 11:55:54 | INFO | fairseq.tasks.translation | example reference: [CLS] او ##ه در مورد هفت ##ه - ی بعد از آن چ ##طور است. هفت ##ه - ی نو ##زدهم? [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  55% 16/29 [00:11<00:09,  1.39it/s]\u001b[A2023-06-11 11:55:54 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] یا یا یا بیست و چهارم یا بیست و چهارم یا بیست و پنج ##م خوب است. \"[SEP]\n",
            "2023-06-11 11:55:54 | INFO | fairseq.tasks.translation | example reference: [CLS] هر دو ##ی ه ##ف ##دهم, یا بیست و چهارم خوب خ ##وا ##هن ##د بود, او ##ه ##وم, [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  59% 17/29 [00:12<00:08,  1.43it/s]\u001b[A2023-06-11 11:55:55 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] او گفت: \"در این هفت ##ه, این هفت ##ه ب ##د است. [SEP]\n",
            "2023-06-11 11:55:55 | INFO | fairseq.tasks.translation | example reference: [CLS] او ##م تمام این هفت ##ه ب ##د است. برنامه شما در هفت ##ه آ ##ینده چ ##گونه است. [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  62% 18/29 [00:13<00:07,  1.52it/s]\u001b[A2023-06-11 11:55:56 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] خوب, باید ب ##گو ##یی ##م, بین دو و چهار تن, دو ##شن ##به ه ##شت ##م? [SEP]\n",
            "2023-06-11 11:55:56 | INFO | fairseq.tasks.translation | example reference: [CLS] باشد, میتوان ##یم ب ##گو ##یی ##م دو تا چهار? روز دو ##شن ##به, ه ##شت ##م? [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  66% 19/29 [00:13<00:06,  1.52it/s]\u001b[A2023-06-11 11:55:56 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\"\n",
            "2023-06-11 11:55:56 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##ه بل ##ه, س ##لام من را به خان ##م ایک ##س با ح ##روف کوچک بر ##سان. ام, [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  69% 20/29 [00:14<00:05,  1.53it/s]\u001b[A2023-06-11 11:55:57 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] در صورت ##ی که من در ##بار ##ه یک ساعت در یک ساعت برای خ ##وش ##حال بود ##م, [SEP]\n",
            "2023-06-11 11:55:57 | INFO | fairseq.tasks.translation | example reference: [CLS] بنابراین اگر من ساعت ##ی را برای ن ##اه ##ار داشته با ##شم, ساعت یک برای من خوب خواهد بود, [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  72% 21/29 [00:15<00:05,  1.44it/s]\u001b[A2023-06-11 11:55:58 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] من میتوان ##ید شما را در دو تن را بر ##گذار ک ##ن ##م, اما شما باید در پارک های کوچک در پارک کوچک به من ب ##پر ##دا ##زند. [SEP]\n",
            "2023-06-11 11:55:58 | INFO | fairseq.tasks.translation | example reference: [CLS] من شما را ساعت دو می ##بین ##م, اما باید هم ##دی ##گر را در پارک لیگ کوچک ب ##بین ##یم. [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  76% 22/29 [00:15<00:04,  1.52it/s]\u001b[A2023-06-11 11:55:58 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] او گفت: \"خ ##وش ##حال است, پنج ##شن ##به, پنج ##شن ##به, و چهار ##شن ##به بیست و شش ##م, کتاب, کتاب ##ها, کتاب ##ها را افزایش داده است. [SEP]\n",
            "2023-06-11 11:55:58 | INFO | fairseq.tasks.translation | example reference: [CLS] ام خ ##یلی زیاد سه - ش ##ن ##به سی - ام و چهار ##شن ##به بیست و نه ##م پر هستند. [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  79% 23/29 [00:16<00:03,  1.55it/s]\u001b[A2023-06-11 11:55:59 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\n",
            "2023-06-11 11:55:59 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##ه چهار ##دهم یا ه ##ف ##دهم چه ##طور. آیا هیچ ##ک ##دام از آن دو روز, با برنامه ##ریزی شما مناسب است? [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  83% 24/29 [00:16<00:03,  1.56it/s]\u001b[A2023-06-11 11:55:59 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] روز چهار ##شن ##به, همه برای من برای من است, بنابراین, برای شما, این کار برای شما است, [SEP]\n",
            "2023-06-11 11:55:59 | INFO | fairseq.tasks.translation | example reference: [CLS] من چهار ##شن ##به کامل ##ا آزاد ه ##ست ##م, اگر برای شما مناسب است, عالی است, [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  86% 25/29 [00:17<00:02,  1.54it/s]\u001b[A2023-06-11 11:56:00 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] بل ##ه, مانند \"خ ##وش ##حال ##م, هیچ ##کس در ص ##بح روز پنج ش ##ن ##به با من ن ##می ##دان ##م. [SEP]\n",
            "2023-06-11 11:56:00 | INFO | fairseq.tasks.translation | example reference: [CLS] بل ##ه, مثل, ن ##می ##دان ##م, هر زمان ##ن از بعد از ظهر پنج ##شن ##به ه ##شت ##م برای من مناسب است. [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  90% 26/29 [00:18<00:01,  1.55it/s]\u001b[A2023-06-11 11:56:01 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] من یک س ##مین ##ار س ##مین ##ار را در این روز, بیست و هفت ##م, که یک روز ه ##ست ##م, نه کامل ##ا آزاد ه ##ست ##م. [SEP]\n",
            "2023-06-11 11:56:01 | INFO | fairseq.tasks.translation | example reference: [CLS] من در تمام روز بیست - و هفت ##م یک س ##مین ##ار دار ##م. آن روز ##ی است که در آن هفت ##ه, من به - طور کامل آزاد نیست ##م. [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  93% 27/29 [00:18<00:01,  1.59it/s]\u001b[A2023-06-11 11:56:01 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] او گفت: \"خ ##وا ##هن ##د بود که ب ##تو ##انی ##م ب ##تو ##انی ##م ب ##تو ##انی ##م ب ##تو ##انی ##م ب ##تو ##انی ##م ب ##تو ##انی ##م در ح ##وم ##ه, و در ##بار ##ه ت ##جار ##ت, و در ##بار ##ه تجاری و\n",
            "2023-06-11 11:56:01 | INFO | fairseq.tasks.translation | example reference: [CLS] عالی است. ش ##اید ب ##تو ##انی ##م هم ##دی ##گر را ##در ها ##لی ##هان ##ز, باغ و ##رزش یا میدان است ##یش ##ن ب ##بین ##یم و در مورد کار ص ##حبت ک ##نی ##م. [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  97% 28/29 [00:19<00:00,  1.60it/s]\u001b[A2023-06-11 11:56:02 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"من ن ##می ##تو ##ان ##م به این ن ##کت ##ه ن ##گاه ک ##ن ##م که ن ##می ##تو ##انی ##م در این هفت ##ه ب ##گو ##یی ##د:\" ن ##می ##تو ##ان ##م به این ترتیب ب ##خ ##وا ##هم که در این هفت ##ه با شما ب ##گو ##یی ##د. \"[SEP]\n",
            "2023-06-11 11:56:02 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##ه به - نظر ن ##می ##رس ##د که من ب ##تو ##ان ##م کد ال ##کت ##ریکی را برای اجرا مه ##یا ک ##ن ##م, من نیاز دار ##م که آ ##ه با تو زمانی دوباره برای حدود بیش از دو ساعت, در این هفت ##ه مل ##اقات ک ##ن ##م. کی برای تو خوب است. [SEP]\n",
            "\n",
            "epoch 002 | valid on 'valid' subset: 100% 29/29 [00:19<00:00,  1.71it/s]\u001b[A\n",
            "                                                                        \u001b[A2023-06-11 11:56:02 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 6.906 | nll_loss 4.065 | ppl 16.73 | bleu 34.29 | wps 3735.8 | wpb 2556.5 | bsz 137.9 | num_updates 13291 | best_bleu 34.29\n",
            "2023-06-11 11:56:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 13291 updates\n",
            "2023-06-11 11:56:02 | INFO | fairseq.trainer | Saving checkpoint to /content/content/drive/MyDrive/mbert_frozen/checkpoints/checkpoint2.pt\n",
            "2023-06-11 11:56:03 | INFO | fairseq.trainer | Finished saving checkpoint to /content/content/drive/MyDrive/mbert_frozen/checkpoints/checkpoint2.pt\n",
            "2023-06-11 11:56:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./content/drive/MyDrive/mbert_frozen/checkpoints/checkpoint2.pt (epoch 2 @ 13291 updates, score 34.29) (writing took 4.611503672998879 seconds)\n",
            "2023-06-11 11:56:06 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)\n",
            "2023-06-11 11:56:06 | INFO | train | epoch 002 | loss 7.711 | nll_loss 4.967 | ppl 31.28 | wps 26281.7 | ups 6.91 | wpb 3802.9 | bsz 100.8 | num_updates 13291 | lr 0.00137149 | gnorm 0.423 | loss_scale 4 | train_wall 909 | gb_free 13 | wall 1928\n",
            "2023-06-11 11:56:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6648\n",
            "epoch 003:   0% 0/6648 [00:00<?, ?it/s]2023-06-11 11:56:06 | INFO | fairseq.trainer | begin training epoch 3\n",
            "2023-06-11 11:56:06 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 003: 100% 6646/6648 [15:24<00:00,  6.07it/s, loss=7.446, nll_loss=4.634, ppl=24.83, wps=28165.1, ups=7.4, wpb=3807.5, bsz=102.8, num_updates=19900, lr=0.00112084, gnorm=0.411, loss_scale=8, train_wall=13, gb_free=13, wall=2847]2023-06-11 12:11:31 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:   0% 0/29 [00:00<?, ?it/s]\u001b[A2023-06-11 12:11:32 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] توسط, [SEP]\n",
            "2023-06-11 12:11:32 | INFO | fairseq.tasks.translation | example reference: [CLS] خدا ##حافظ, [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:   3% 1/29 [00:00<00:21,  1.32it/s]\u001b[A2023-06-11 12:11:33 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] آیا این خ ##یلی خوب است? [SEP]\n",
            "2023-06-11 12:11:33 | INFO | fairseq.tasks.translation | example reference: [CLS] آیا آن خوب است? [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:   7% 2/29 [00:01<00:18,  1.44it/s]\u001b[A2023-06-11 12:11:33 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"یک زمان, [SEP]\n",
            "2023-06-11 12:11:33 | INFO | fairseq.tasks.translation | example reference: [CLS] او ##ه زمان را گرفت ##م, [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  10% 3/29 [00:02<00:17,  1.48it/s]\u001b[A2023-06-11 12:11:34 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] در این ##جا خوب نیست. [SEP]\n",
            "2023-06-11 12:11:34 | INFO | fairseq.tasks.translation | example reference: [CLS] در این ##جا ظهر خوب خواهد بود. [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  14% 4/29 [00:02<00:16,  1.51it/s]\u001b[A2023-06-11 12:11:35 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] پس ما روز جمع ##ه ه ##شت ##م, [SEP]\n",
            "2023-06-11 12:11:35 | INFO | fairseq.tasks.translation | example reference: [CLS] پس شد جمع ##ه ه ##شت ##م, [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  17% 5/29 [00:03<00:15,  1.59it/s]\u001b[A2023-06-11 12:11:35 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"خ ##یلی خوب است, [SEP]\n",
            "2023-06-11 12:11:35 | INFO | fairseq.tasks.translation | example reference: [CLS] چه چیزی برای شما مناسب است, [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  21% 6/29 [00:03<00:14,  1.62it/s]\u001b[A2023-06-11 12:11:36 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\n",
            "2023-06-11 12:11:36 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##ه, خدا, هر جمع ##ه - ای خوب است. [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  24% 7/29 [00:04<00:13,  1.59it/s]\u001b[A2023-06-11 12:11:36 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] و پس از آن, شما با این م ##س ##أ ##له, [SEP]\n",
            "2023-06-11 12:11:36 | INFO | fairseq.tasks.translation | example reference: [CLS] بسیار خوب, به ام ##ید دید ##ار, خدا ##حافظ, [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  28% 8/29 [00:05<00:12,  1.65it/s]\u001b[A2023-06-11 12:11:37 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] اما در بعد از ظهر بیست و دوم, [SEP]\n",
            "2023-06-11 12:11:37 | INFO | fairseq.tasks.translation | example reference: [CLS] اما, آ ##ه بعد ##از ##ظهر بیست و دوم, [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  31% 9/29 [00:05<00:12,  1.65it/s]\u001b[A2023-06-11 12:11:38 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] و بیست و هفت ##م, [SEP]\n",
            "2023-06-11 12:11:38 | INFO | fairseq.tasks.translation | example reference: [CLS] و نو ##زدهم نیز تا ساعت چهار آزاد ه ##ست ##م. [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  34% 10/29 [00:06<00:11,  1.64it/s]\u001b[A2023-06-11 12:11:38 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] در روز سه ش ##ن ##به, هر کسی پس از آن, [SEP]\n",
            "2023-06-11 12:11:38 | INFO | fairseq.tasks.translation | example reference: [CLS] سه - ش ##ن ##به, هر زمانی بعد از دو ##از ##ده مناسب خواهد بود, [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  38% 11/29 [00:06<00:10,  1.64it/s]\u001b[A2023-06-11 12:11:39 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] بل ##ه, در صورت ##ی که من به دفتر خود می ##رفت ##م. [SEP]\n",
            "2023-06-11 12:11:39 | INFO | fairseq.tasks.translation | example reference: [CLS] بل ##ه, این خوب است اگر من به دفتر شما بی ##ای ##م. [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  41% 12/29 [00:07<00:10,  1.69it/s]\u001b[A2023-06-11 12:11:39 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"من یک ج ##لس ##ه را از سه تا چهار تا از سه تا چهار نفر, [SEP]\n",
            "2023-06-11 12:11:39 | INFO | fairseq.tasks.translation | example reference: [CLS] من از سه تا چهار و ن ##یم ج ##لس ##ه دار ##م, [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  45% 13/29 [00:08<00:09,  1.66it/s]\u001b[A2023-06-11 12:11:40 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] هر زمان در چند هفت ##ه آ ##ینده, زمانی که شما آزاد ه ##ستی ##د? [SEP]\n",
            "2023-06-11 12:11:40 | INFO | fairseq.tasks.translation | example reference: [CLS] زمانی در دو هفت ##هی آ ##ینده وجود دارد که شما آزاد با ##شی? [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  48% 14/29 [00:08<00:10,  1.47it/s]\u001b[A2023-06-11 12:11:41 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] من از این شهر از از بین برد ##ن م ##ح ##کو ##می ##ت از \"ا ##ف ##زو ##د.\" [SEP]\n",
            "2023-06-11 12:11:41 | INFO | fairseq.tasks.translation | example reference: [CLS] من از سی ##م تا سوم خارج از شهر ه ##ست ##م. [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  52% 15/29 [00:09<00:09,  1.50it/s]\u001b[A2023-06-11 12:11:42 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] در این هفت ##ه, این هفت ##ه پس از آن, این هفت ##ه پس از آن چ ##یست? [SEP]\n",
            "2023-06-11 12:11:42 | INFO | fairseq.tasks.translation | example reference: [CLS] او ##ه در مورد هفت ##ه - ی بعد از آن چ ##طور است. هفت ##ه - ی نو ##زدهم? [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  55% 16/29 [00:10<00:09,  1.40it/s]\u001b[A2023-06-11 12:11:43 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] هر هفت ه ##ف ##دهم, یا بیست و پنج ##م, [SEP]\n",
            "2023-06-11 12:11:43 | INFO | fairseq.tasks.translation | example reference: [CLS] هر دو ##ی ه ##ف ##دهم, یا بیست و چهارم خوب خ ##وا ##هن ##د بود, او ##ه ##وم, [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  59% 17/29 [00:11<00:09,  1.31it/s]\u001b[A2023-06-11 12:11:43 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] در این هفت ##ه, این هفت ##ه در این هفت ##ه ب ##د است. [SEP]\n",
            "2023-06-11 12:11:43 | INFO | fairseq.tasks.translation | example reference: [CLS] او ##م تمام این هفت ##ه ب ##د است. برنامه شما در هفت ##ه آ ##ینده چ ##گونه است. [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  62% 18/29 [00:12<00:08,  1.33it/s]\u001b[A2023-06-11 12:11:44 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] خوب, باید ب ##گو ##یی ##م, دو تن, دو ##شن ##به ه ##شت ##م? [SEP]\n",
            "2023-06-11 12:11:44 | INFO | fairseq.tasks.translation | example reference: [CLS] باشد, میتوان ##یم ب ##گو ##یی ##م دو تا چهار? روز دو ##شن ##به, ه ##شت ##م? [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  66% 19/29 [00:12<00:07,  1.28it/s]\u001b[A2023-06-11 12:11:45 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\"\n",
            "2023-06-11 12:11:45 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##ه بل ##ه, س ##لام من را به خان ##م ایک ##س با ح ##روف کوچک بر ##سان. ام, [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  69% 20/29 [00:13<00:07,  1.25it/s]\u001b[A2023-06-11 12:11:46 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] در صورت ##ی که من در ##بار ##ه یک ساعت برای من ف ##کر می ##کن ##م, یک ساعت با من خوب است, [SEP]\n",
            "2023-06-11 12:11:46 | INFO | fairseq.tasks.translation | example reference: [CLS] بنابراین اگر من ساعت ##ی را برای ن ##اه ##ار داشته با ##شم, ساعت یک برای من خوب خواهد بود, [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  72% 21/29 [00:14<00:06,  1.25it/s]\u001b[A2023-06-11 12:11:47 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] من میتوان ##م در دو تن با شما ب ##بین ##ید, اما شما می ##خ ##وا ##هی ##د ب ##تو ##انی ##د در پارک های کم ##پی ##ن ک ##ن ##م. [SEP]\n",
            "2023-06-11 12:11:47 | INFO | fairseq.tasks.translation | example reference: [CLS] من شما را ساعت دو می ##بین ##م, اما باید هم ##دی ##گر را در پارک لیگ کوچک ب ##بین ##یم. [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  76% 22/29 [00:15<00:05,  1.25it/s]\u001b[A2023-06-11 12:11:47 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\"\n",
            "2023-06-11 12:11:47 | INFO | fairseq.tasks.translation | example reference: [CLS] ام خ ##یلی زیاد سه - ش ##ن ##به سی - ام و چهار ##شن ##به بیست و نه ##م پر هستند. [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  79% 23/29 [00:16<00:04,  1.25it/s]\u001b[A2023-06-11 12:11:48 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\n",
            "2023-06-11 12:11:48 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##ه چهار ##دهم یا ه ##ف ##دهم چه ##طور. آیا هیچ ##ک ##دام از آن دو روز, با برنامه ##ریزی شما مناسب است? [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  83% 24/29 [00:16<00:03,  1.32it/s]\u001b[A2023-06-11 12:11:49 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] در روز چهار ##شن ##به, همه این ##ها برای من آزاد است, به این دلیل که این کار برای شما کار میکند, [SEP]\n",
            "2023-06-11 12:11:49 | INFO | fairseq.tasks.translation | example reference: [CLS] من چهار ##شن ##به کامل ##ا آزاد ه ##ست ##م, اگر برای شما مناسب است, عالی است, [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  86% 25/29 [00:17<00:02,  1.37it/s]\u001b[A2023-06-11 12:11:49 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] بل ##ه, مانند \"من, من ن ##می ##دان ##م, در بعد از ظهر, در روز پنج ##شن ##به ه ##شت ##م. [SEP]\n",
            "2023-06-11 12:11:49 | INFO | fairseq.tasks.translation | example reference: [CLS] بل ##ه, مثل, ن ##می ##دان ##م, هر زمان ##ن از بعد از ظهر پنج ##شن ##به ه ##شت ##م برای من مناسب است. [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  90% 26/29 [00:18<00:02,  1.42it/s]\u001b[A2023-06-11 12:11:50 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] من یک س ##مین ##ار را در هر روز, بیست و هفت ##م, که یک روز است, یک روز ه ##ست ##م که یک روز است, نه کامل ##ا آزاد بود ##م. [SEP]\n",
            "2023-06-11 12:11:50 | INFO | fairseq.tasks.translation | example reference: [CLS] من در تمام روز بیست - و هفت ##م یک س ##مین ##ار دار ##م. آن روز ##ی است که در آن هفت ##ه, من به - طور کامل آزاد نیست ##م. [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  93% 27/29 [00:18<00:01,  1.47it/s]\u001b[A2023-06-11 12:11:51 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\n",
            "2023-06-11 12:11:51 | INFO | fairseq.tasks.translation | example reference: [CLS] عالی است. ش ##اید ب ##تو ##انی ##م هم ##دی ##گر را ##در ها ##لی ##هان ##ز, باغ و ##رزش یا میدان است ##یش ##ن ب ##بین ##یم و در مورد کار ص ##حبت ک ##نی ##م. [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  97% 28/29 [00:19<00:00,  1.51it/s]\u001b[A2023-06-11 12:11:51 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"من ن ##می ##تو ##انی ##م به این ترتیب ب ##تو ##انی ##م به این م ##س ##أ ##له ف ##کر ک ##ن ##م که در این هفت ##ه, من به ش ##یو ##ه ای که در این هفت ##ه نیاز دار ##ید با شما در این هفت ##ه با شما ب ##تو ##انی ##د ب ##تو ##انی ##د ب ##تو ##انی ##د\n",
            "2023-06-11 12:11:51 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##ه به - نظر ن ##می ##رس ##د که من ب ##تو ##ان ##م کد ال ##کت ##ریکی را برای اجرا مه ##یا ک ##ن ##م, من نیاز دار ##م که آ ##ه با تو زمانی دوباره برای حدود بیش از دو ساعت, در این هفت ##ه مل ##اقات ک ##ن ##م. کی برای تو خوب است. [SEP]\n",
            "\n",
            "epoch 003 | valid on 'valid' subset: 100% 29/29 [00:19<00:00,  1.71it/s]\u001b[A\n",
            "                                                                        \u001b[A2023-06-11 12:11:51 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 6.776 | nll_loss 3.88 | ppl 14.72 | bleu 34.66 | wps 3784.7 | wpb 2556.5 | bsz 137.9 | num_updates 19939 | best_bleu 34.66\n",
            "2023-06-11 12:11:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 19939 updates\n",
            "2023-06-11 12:11:51 | INFO | fairseq.trainer | Saving checkpoint to /content/content/drive/MyDrive/mbert_frozen/checkpoints/checkpoint3.pt\n",
            "2023-06-11 12:11:52 | INFO | fairseq.trainer | Finished saving checkpoint to /content/content/drive/MyDrive/mbert_frozen/checkpoints/checkpoint3.pt\n",
            "2023-06-11 12:11:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./content/drive/MyDrive/mbert_frozen/checkpoints/checkpoint3.pt (epoch 3 @ 19939 updates, score 34.66) (writing took 4.138571875000707 seconds)\n",
            "2023-06-11 12:11:55 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)\n",
            "2023-06-11 12:11:55 | INFO | train | epoch 003 | loss 7.493 | nll_loss 4.691 | ppl 25.84 | wps 26647.8 | ups 7.01 | wpb 3802.9 | bsz 100.8 | num_updates 19939 | lr 0.00111974 | gnorm 0.425 | loss_scale 8 | train_wall 899 | gb_free 12.9 | wall 2876\n",
            "2023-06-11 12:11:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6648\n",
            "epoch 004:   0% 0/6648 [00:00<?, ?it/s]2023-06-11 12:11:55 | INFO | fairseq.trainer | begin training epoch 4\n",
            "2023-06-11 12:11:55 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 004: 100% 6647/6648 [15:23<00:00,  8.85it/s, loss=7.391, nll_loss=4.566, ppl=23.68, wps=26977.8, ups=7.2, wpb=3744.3, bsz=99.8, num_updates=26500, lr=0.000971286, gnorm=0.415, loss_scale=8, train_wall=14, gb_free=13.1, wall=3789]2023-06-11 12:27:19 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:   0% 0/29 [00:00<?, ?it/s]\u001b[A2023-06-11 12:27:20 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] از سوی دیگر, [SEP]\n",
            "2023-06-11 12:27:20 | INFO | fairseq.tasks.translation | example reference: [CLS] خدا ##حافظ, [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:   3% 1/29 [00:00<00:21,  1.30it/s]\u001b[A2023-06-11 12:27:20 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] آیا این خوب است? [SEP]\n",
            "2023-06-11 12:27:20 | INFO | fairseq.tasks.translation | example reference: [CLS] آیا آن خوب است? [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:   7% 2/29 [00:01<00:17,  1.50it/s]\u001b[A2023-06-11 12:27:21 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"یک زمان, [SEP]\n",
            "2023-06-11 12:27:21 | INFO | fairseq.tasks.translation | example reference: [CLS] او ##ه زمان را گرفت ##م, [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  10% 3/29 [00:02<00:17,  1.45it/s]\u001b[A2023-06-11 12:27:22 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] در این ##جا خوب است. [SEP]\n",
            "2023-06-11 12:27:22 | INFO | fairseq.tasks.translation | example reference: [CLS] در این ##جا ظهر خوب خواهد بود. [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  14% 4/29 [00:02<00:18,  1.35it/s]\u001b[A2023-06-11 12:27:23 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] پس ما روز جمع ##ه ه ##شت ##م, [SEP]\n",
            "2023-06-11 12:27:23 | INFO | fairseq.tasks.translation | example reference: [CLS] پس شد جمع ##ه ه ##شت ##م, [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  17% 5/29 [00:03<00:17,  1.36it/s]\u001b[A2023-06-11 12:27:23 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"من برای شما خوب است, [SEP]\n",
            "2023-06-11 12:27:23 | INFO | fairseq.tasks.translation | example reference: [CLS] چه چیزی برای شما مناسب است, [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  21% 6/29 [00:04<00:17,  1.34it/s]\u001b[A2023-06-11 12:27:24 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"ا ##ف ##زون بر آن, هر روز جمع ##ه خوب است. [SEP]\n",
            "2023-06-11 12:27:24 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##ه, خدا, هر جمع ##ه - ای خوب است. [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  24% 7/29 [00:05<00:17,  1.28it/s]\u001b[A2023-06-11 12:27:25 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] ال ##ان می ##بین ##ید, [SEP]\n",
            "2023-06-11 12:27:25 | INFO | fairseq.tasks.translation | example reference: [CLS] بسیار خوب, به ام ##ید دید ##ار, خدا ##حافظ, [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  28% 8/29 [00:05<00:15,  1.31it/s]\u001b[A2023-06-11 12:27:26 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] اما \"بعد از ظهر بیست و دوم, [SEP]\n",
            "2023-06-11 12:27:26 | INFO | fairseq.tasks.translation | example reference: [CLS] اما, آ ##ه بعد ##از ##ظهر بیست و دوم, [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  31% 9/29 [00:06<00:15,  1.27it/s]\u001b[A2023-06-11 12:27:27 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] و بیست و یک ##م من آزاد ه ##ست ##م, [SEP]\n",
            "2023-06-11 12:27:27 | INFO | fairseq.tasks.translation | example reference: [CLS] و نو ##زدهم نیز تا ساعت چهار آزاد ه ##ست ##م. [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  34% 10/29 [00:07<00:15,  1.26it/s]\u001b[A2023-06-11 12:27:27 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] در روز سه ش ##ن ##به, هر زمان پس از آن, [SEP]\n",
            "2023-06-11 12:27:27 | INFO | fairseq.tasks.translation | example reference: [CLS] سه - ش ##ن ##به, هر زمانی بعد از دو ##از ##ده مناسب خواهد بود, [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  38% 11/29 [00:08<00:14,  1.24it/s]\u001b[A2023-06-11 12:27:28 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] بل ##ه, خوب است. [SEP]\n",
            "2023-06-11 12:27:28 | INFO | fairseq.tasks.translation | example reference: [CLS] بل ##ه, این خوب است اگر من به دفتر شما بی ##ای ##م. [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  41% 12/29 [00:08<00:12,  1.39it/s]\u001b[A2023-06-11 12:27:29 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"من یک ج ##لس ##ه را از سه تا چهار ش ##ن ##به, [SEP]\n",
            "2023-06-11 12:27:29 | INFO | fairseq.tasks.translation | example reference: [CLS] من از سه تا چهار و ن ##یم ج ##لس ##ه دار ##م, [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  45% 13/29 [00:09<00:10,  1.47it/s]\u001b[A2023-06-11 12:27:29 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] آیا در چند هفت ##ه آ ##ینده, زمانی که شما آزاد ه ##ستی ##د? [SEP]\n",
            "2023-06-11 12:27:29 | INFO | fairseq.tasks.translation | example reference: [CLS] زمانی در دو هفت ##هی آ ##ینده وجود دارد که شما آزاد با ##شی? [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  48% 14/29 [00:10<00:09,  1.51it/s]\u001b[A2023-06-11 12:27:30 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] من از این شهر از از بین رفت ##ن از از بین رفت ##م. [SEP]\n",
            "2023-06-11 12:27:30 | INFO | fairseq.tasks.translation | example reference: [CLS] من از سی ##م تا سوم خارج از شهر ه ##ست ##م. [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  52% 15/29 [00:10<00:09,  1.55it/s]\u001b[A2023-06-11 12:27:31 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"در این هفت ##ه, هفت ##ه پس از آن, هفت ##ه ی بیست و یک ##م? [SEP]\n",
            "2023-06-11 12:27:31 | INFO | fairseq.tasks.translation | example reference: [CLS] او ##ه در مورد هفت ##ه - ی بعد از آن چ ##طور است. هفت ##ه - ی نو ##زدهم? [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  55% 16/29 [00:11<00:08,  1.53it/s]\u001b[A2023-06-11 12:27:31 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] یا یا بیست و پنج ##م یا بیست و چهارم خوبی خواهد بود. \"[SEP]\n",
            "2023-06-11 12:27:31 | INFO | fairseq.tasks.translation | example reference: [CLS] هر دو ##ی ه ##ف ##دهم, یا بیست و چهارم خوب خ ##وا ##هن ##د بود, او ##ه ##وم, [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  59% 17/29 [00:12<00:07,  1.55it/s]\u001b[A2023-06-11 12:27:32 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"در این هفت ##ه, این هفت ##ه ب ##د است که برنامه شما در هفت ##ه آ ##ینده به نظر می ##رسی ##د. [SEP]\n",
            "2023-06-11 12:27:32 | INFO | fairseq.tasks.translation | example reference: [CLS] او ##م تمام این هفت ##ه ب ##د است. برنامه شما در هفت ##ه آ ##ینده چ ##گونه است. [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  62% 18/29 [00:12<00:06,  1.62it/s]\u001b[A2023-06-11 12:27:32 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] خوب, باید ب ##گو ##یی ##م, بین دو, دو ##شن ##به, دو ##شن ##به ه ##شت ##م? [SEP]\n",
            "2023-06-11 12:27:32 | INFO | fairseq.tasks.translation | example reference: [CLS] باشد, میتوان ##یم ب ##گو ##یی ##م دو تا چهار? روز دو ##شن ##به, ه ##شت ##م? [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  66% 19/29 [00:13<00:06,  1.62it/s]\u001b[A2023-06-11 12:27:33 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"ا ##ف ##زو ##د:\" خ ##وا ##ب, ب ##گو ##یی ##د که ب ##خ ##وا ##هی ##د برای من به من ب ##پر ##دا ##زند. \"[SEP]\n",
            "2023-06-11 12:27:33 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##ه بل ##ه, س ##لام من را به خان ##م ایک ##س با ح ##روف کوچک بر ##سان. ام, [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  69% 20/29 [00:13<00:05,  1.62it/s]\u001b[A2023-06-11 12:27:34 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] در صورت ##ی که در ##بار ##ه یک ساعت از یک ساعت برای خ ##وا ##ب بود ##م, یک ساعت با من خوب خواهد بود, [SEP]\n",
            "2023-06-11 12:27:34 | INFO | fairseq.tasks.translation | example reference: [CLS] بنابراین اگر من ساعت ##ی را برای ن ##اه ##ار داشته با ##شم, ساعت یک برای من خوب خواهد بود, [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  72% 21/29 [00:14<00:04,  1.68it/s]\u001b[A2023-06-11 12:27:34 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] من میتوان ##م در دو, اما شما می ##خ ##وا ##هی ##د در پارک کوچک با شما مل ##اقات ک ##ن ##م. [SEP]\n",
            "2023-06-11 12:27:34 | INFO | fairseq.tasks.translation | example reference: [CLS] من شما را ساعت دو می ##بین ##م, اما باید هم ##دی ##گر را در پارک لیگ کوچک ب ##بین ##یم. [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  76% 22/29 [00:14<00:04,  1.72it/s]\u001b[A2023-06-11 12:27:35 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\"\n",
            "2023-06-11 12:27:35 | INFO | fairseq.tasks.translation | example reference: [CLS] ام خ ##یلی زیاد سه - ش ##ن ##به سی - ام و چهار ##شن ##به بیست و نه ##م پر هستند. [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  79% 23/29 [00:15<00:03,  1.55it/s]\u001b[A2023-06-11 12:27:36 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\n",
            "2023-06-11 12:27:36 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##ه چهار ##دهم یا ه ##ف ##دهم چه ##طور. آیا هیچ ##ک ##دام از آن دو روز, با برنامه ##ریزی شما مناسب است? [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  83% 24/29 [00:16<00:03,  1.42it/s]\u001b[A2023-06-11 12:27:37 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] روز چهار ##شن ##به همه آزاد برای من است, بنابراین, \"اگر این کار را انجام ده ##ند,\" [SEP]\n",
            "2023-06-11 12:27:37 | INFO | fairseq.tasks.translation | example reference: [CLS] من چهار ##شن ##به کامل ##ا آزاد ه ##ست ##م, اگر برای شما مناسب است, عالی است, [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  86% 25/29 [00:17<00:03,  1.32it/s]\u001b[A2023-06-11 12:27:37 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] بل ##ه, مثل \"من, من ن ##می ##دان ##م که در بعد از ظهر, روز پنج ش ##ن ##به با من خوب است.\" [SEP]\n",
            "2023-06-11 12:27:37 | INFO | fairseq.tasks.translation | example reference: [CLS] بل ##ه, مثل, ن ##می ##دان ##م, هر زمان ##ن از بعد از ظهر پنج ##شن ##به ه ##شت ##م برای من مناسب است. [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  90% 26/29 [00:18<00:02,  1.26it/s]\u001b[A2023-06-11 12:27:38 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] من یک س ##مین ##ار یک س ##مین ##ار را دار ##م, بیست و هفت ##م, که یک روز ه ##ست ##م, نه کامل ##ا آزاد ه ##ست ##م. [SEP]\n",
            "2023-06-11 12:27:38 | INFO | fairseq.tasks.translation | example reference: [CLS] من در تمام روز بیست - و هفت ##م یک س ##مین ##ار دار ##م. آن روز ##ی است که در آن هفت ##ه, من به - طور کامل آزاد نیست ##م. [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  93% 27/29 [00:19<00:01,  1.23it/s]\u001b[A2023-06-11 12:27:39 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"ا ##ف ##زون بر آن, ما میتوان ##یم ب ##تو ##انی ##م ب ##تو ##انی ##م ب ##تو ##انی ##م ب ##تو ##انی ##م ب ##تو ##انی ##م ش ##اید در ح ##وم ##ه ای, یا در میدان و ##رزش ##ی, و در ##بار ##ه ت ##جار ##ت و\n",
            "2023-06-11 12:27:39 | INFO | fairseq.tasks.translation | example reference: [CLS] عالی است. ش ##اید ب ##تو ##انی ##م هم ##دی ##گر را ##در ها ##لی ##هان ##ز, باغ و ##رزش یا میدان است ##یش ##ن ب ##بین ##یم و در مورد کار ص ##حبت ک ##نی ##م. [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  97% 28/29 [00:20<00:00,  1.21it/s]\u001b[A2023-06-11 12:27:40 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" من ن ##می ##تو ##ان ##م به این ترتیب ب ##گو ##یی ##م که به ش ##یو ##ه ای که در این هفت ##ه نیاز دار ##م با شما ب ##خ ##وا ##هم با شما با شما ب ##خ ##وا ##هی ##د. \"[SEP]\n",
            "2023-06-11 12:27:40 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##ه به - نظر ن ##می ##رس ##د که من ب ##تو ##ان ##م کد ال ##کت ##ریکی را برای اجرا مه ##یا ک ##ن ##م, من نیاز دار ##م که آ ##ه با تو زمانی دوباره برای حدود بیش از دو ساعت, در این هفت ##ه مل ##اقات ک ##ن ##م. کی برای تو خوب است. [SEP]\n",
            "\n",
            "epoch 004 | valid on 'valid' subset: 100% 29/29 [00:20<00:00,  1.31it/s]\u001b[A\n",
            "                                                                        \u001b[A2023-06-11 12:27:40 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 6.65 | nll_loss 3.68 | ppl 12.82 | bleu 37.2 | wps 3599.6 | wpb 2556.5 | bsz 137.9 | num_updates 26587 | best_bleu 37.2\n",
            "2023-06-11 12:27:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 26587 updates\n",
            "2023-06-11 12:27:40 | INFO | fairseq.trainer | Saving checkpoint to /content/content/drive/MyDrive/mbert_frozen/checkpoints/checkpoint4.pt\n",
            "2023-06-11 12:27:41 | INFO | fairseq.trainer | Finished saving checkpoint to /content/content/drive/MyDrive/mbert_frozen/checkpoints/checkpoint4.pt\n",
            "2023-06-11 12:27:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./content/drive/MyDrive/mbert_frozen/checkpoints/checkpoint4.pt (epoch 4 @ 26587 updates, score 37.2) (writing took 4.404078778999974 seconds)\n",
            "2023-06-11 12:27:44 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)\n",
            "2023-06-11 12:27:44 | INFO | train | epoch 004 | loss 7.38 | nll_loss 4.548 | ppl 23.39 | wps 26639.5 | ups 7 | wpb 3802.9 | bsz 100.8 | num_updates 26587 | lr 0.000969695 | gnorm 0.421 | loss_scale 8 | train_wall 898 | gb_free 13 | wall 3825\n",
            "2023-06-11 12:27:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6648\n",
            "epoch 005:   0% 0/6648 [00:00<?, ?it/s]2023-06-11 12:27:44 | INFO | fairseq.trainer | begin training epoch 5\n",
            "2023-06-11 12:27:44 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 005: 100% 6647/6648 [15:22<00:00,  8.95it/s, loss=7.31, nll_loss=4.46, ppl=22.01, wps=26598.4, ups=7.08, wpb=3756.1, bsz=92.5, num_updates=33200, lr=0.000867763, gnorm=0.414, loss_scale=16, train_wall=14, gb_free=13.1, wall=4744]2023-06-11 12:43:07 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:   0% 0/29 [00:00<?, ?it/s]\u001b[A2023-06-11 12:43:08 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] که [SEP]\n",
            "2023-06-11 12:43:08 | INFO | fairseq.tasks.translation | example reference: [CLS] خدا ##حافظ, [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:   3% 1/29 [00:00<00:21,  1.29it/s]\u001b[A2023-06-11 12:43:08 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] آیا خ ##یلی خوب است? [SEP]\n",
            "2023-06-11 12:43:08 | INFO | fairseq.tasks.translation | example reference: [CLS] آیا آن خوب است? [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:   7% 2/29 [00:01<00:18,  1.46it/s]\u001b[A2023-06-11 12:43:09 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\n",
            "2023-06-11 12:43:09 | INFO | fairseq.tasks.translation | example reference: [CLS] او ##ه زمان را گرفت ##م, [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  10% 3/29 [00:02<00:17,  1.50it/s]\u001b[A2023-06-11 12:43:10 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] هیچ ##کس در این ##جا خوب نیست. [SEP]\n",
            "2023-06-11 12:43:10 | INFO | fairseq.tasks.translation | example reference: [CLS] در این ##جا ظهر خوب خواهد بود. [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  14% 4/29 [00:02<00:16,  1.52it/s]\u001b[A2023-06-11 12:43:10 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] بنابراین ما روز جمع ##ه ه ##شت ##م را خ ##وا ##هیم گفت, [SEP]\n",
            "2023-06-11 12:43:10 | INFO | fairseq.tasks.translation | example reference: [CLS] پس شد جمع ##ه ه ##شت ##م, [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  17% 5/29 [00:03<00:15,  1.60it/s]\u001b[A2023-06-11 12:43:11 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\n",
            "2023-06-11 12:43:11 | INFO | fairseq.tasks.translation | example reference: [CLS] چه چیزی برای شما مناسب است, [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  21% 6/29 [00:03<00:14,  1.62it/s]\u001b[A2023-06-11 12:43:11 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\n",
            "2023-06-11 12:43:11 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##ه, خدا, هر جمع ##ه - ای خوب است. [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  24% 7/29 [00:04<00:13,  1.58it/s]\u001b[A2023-06-11 12:43:12 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] ال ##ان, ب ##بین ##ید, و پس از آن, [SEP]\n",
            "2023-06-11 12:43:12 | INFO | fairseq.tasks.translation | example reference: [CLS] بسیار خوب, به ام ##ید دید ##ار, خدا ##حافظ, [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  28% 8/29 [00:05<00:13,  1.52it/s]\u001b[A2023-06-11 12:43:13 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] اما, \"بعد از ظهر بیست و دوم, [SEP]\n",
            "2023-06-11 12:43:13 | INFO | fairseq.tasks.translation | example reference: [CLS] اما, آ ##ه بعد ##از ##ظهر بیست و دوم, [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  31% 9/29 [00:06<00:16,  1.23it/s]\u001b[A2023-06-11 12:43:14 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] و بیست و یک ##م من آزاد ه ##ست ##م, [SEP]\n",
            "2023-06-11 12:43:14 | INFO | fairseq.tasks.translation | example reference: [CLS] و نو ##زدهم نیز تا ساعت چهار آزاد ه ##ست ##م. [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  34% 10/29 [00:07<00:15,  1.23it/s]\u001b[A2023-06-11 12:43:15 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] در روز سه ش ##ن ##به, هر زمان پس از اینکه نه تن از آنها, [SEP]\n",
            "2023-06-11 12:43:15 | INFO | fairseq.tasks.translation | example reference: [CLS] سه - ش ##ن ##به, هر زمانی بعد از دو ##از ##ده مناسب خواهد بود, [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  38% 11/29 [00:08<00:14,  1.21it/s]\u001b[A2023-06-11 12:43:16 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] بل ##ه, اگر من به دفتر ##تان می ##آ ##مد. [SEP]\n",
            "2023-06-11 12:43:16 | INFO | fairseq.tasks.translation | example reference: [CLS] بل ##ه, این خوب است اگر من به دفتر شما بی ##ای ##م. [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  41% 12/29 [00:08<00:13,  1.24it/s]\u001b[A2023-06-11 12:43:17 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\n",
            "2023-06-11 12:43:17 | INFO | fairseq.tasks.translation | example reference: [CLS] من از سه تا چهار و ن ##یم ج ##لس ##ه دار ##م, [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  45% 13/29 [00:09<00:13,  1.21it/s]\u001b[A2023-06-11 12:43:17 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] در سه هفت ##ه آ ##ینده, زمانی که شما آزاد ه ##ستی ##د? [SEP]\n",
            "2023-06-11 12:43:17 | INFO | fairseq.tasks.translation | example reference: [CLS] زمانی در دو هفت ##هی آ ##ینده وجود دارد که شما آزاد با ##شی? [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  48% 14/29 [00:10<00:11,  1.29it/s]\u001b[A2023-06-11 12:43:18 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] من از شهر م ##ح ##کو ##م شده ##ای ##م. [SEP]\n",
            "2023-06-11 12:43:18 | INFO | fairseq.tasks.translation | example reference: [CLS] من از سی ##م تا سوم خارج از شهر ه ##ست ##م. [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  52% 15/29 [00:10<00:10,  1.37it/s]\u001b[A2023-06-11 12:43:19 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"در این هفت ##ه, هفت ##ه پس از آن, این هفت ##ه پس از آن است? [SEP]\n",
            "2023-06-11 12:43:19 | INFO | fairseq.tasks.translation | example reference: [CLS] او ##ه در مورد هفت ##ه - ی بعد از آن چ ##طور است. هفت ##ه - ی نو ##زدهم? [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  55% 16/29 [00:11<00:09,  1.38it/s]\u001b[A2023-06-11 12:43:19 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] هر هفت ه ##ف ##ده, یا بیست و چهارم یا بیست و چهارم خوبی خواهد بود. \"[SEP]\n",
            "2023-06-11 12:43:19 | INFO | fairseq.tasks.translation | example reference: [CLS] هر دو ##ی ه ##ف ##دهم, یا بیست و چهارم خوب خ ##وا ##هن ##د بود, او ##ه ##وم, [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  59% 17/29 [00:12<00:08,  1.43it/s]\u001b[A2023-06-11 12:43:20 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"در این هفت ##ه, این هفت ##ه ب ##د است که برنامه شما را در هفت ##ه آ ##ینده به نظر می ##رسی ##د. [SEP]\n",
            "2023-06-11 12:43:20 | INFO | fairseq.tasks.translation | example reference: [CLS] او ##م تمام این هفت ##ه ب ##د است. برنامه شما در هفت ##ه آ ##ینده چ ##گونه است. [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  62% 18/29 [00:12<00:07,  1.52it/s]\u001b[A2023-06-11 12:43:20 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] خوب, باید ب ##گو ##یی ##م, بین دو, دو ##شن ##به, دو ##شن ##به, دو ##شن ##به ه ##شت ##م? [SEP]\n",
            "2023-06-11 12:43:20 | INFO | fairseq.tasks.translation | example reference: [CLS] باشد, میتوان ##یم ب ##گو ##یی ##م دو تا چهار? روز دو ##شن ##به, ه ##شت ##م? [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  66% 19/29 [00:13<00:06,  1.53it/s]\u001b[A2023-06-11 12:43:21 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\"\n",
            "2023-06-11 12:43:21 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##ه بل ##ه, س ##لام من را به خان ##م ایک ##س با ح ##روف کوچک بر ##سان. ام, [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  69% 20/29 [00:14<00:05,  1.55it/s]\u001b[A2023-06-11 12:43:22 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] پس اگر من در ##بار ##ه یک ساعت به مدت یک ساعت برای خ ##وش ش ##انس بود ##م, یکی از ساعت ##ها با من, [SEP]\n",
            "2023-06-11 12:43:22 | INFO | fairseq.tasks.translation | example reference: [CLS] بنابراین اگر من ساعت ##ی را برای ن ##اه ##ار داشته با ##شم, ساعت یک برای من خوب خواهد بود, [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  72% 21/29 [00:14<00:05,  1.59it/s]\u001b[A2023-06-11 12:43:22 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] من میتوان ##م در دو تن با شما دید ##ار ک ##ن ##م, اما شما می ##خ ##وا ##هی ##د در کم ##پ کم ##پی ##ن در پارک کو ##د ##ک دید ##ار ک ##ن ##م. [SEP]\n",
            "2023-06-11 12:43:22 | INFO | fairseq.tasks.translation | example reference: [CLS] من شما را ساعت دو می ##بین ##م, اما باید هم ##دی ##گر را در پارک لیگ کوچک ب ##بین ##یم. [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  76% 22/29 [00:15<00:04,  1.64it/s]\u001b[A2023-06-11 12:43:23 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"\" \"\" \"خ ##یلی خوب, پنج ##شن ##به, روز پنج ##شن ##به, و چهار ##شن ##به بیست و نه ##م, و چهار ##شن ##به بیست و نه ##م, کتاب,\n",
            "2023-06-11 12:43:23 | INFO | fairseq.tasks.translation | example reference: [CLS] ام خ ##یلی زیاد سه - ش ##ن ##به سی - ام و چهار ##شن ##به بیست و نه ##م پر هستند. [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  79% 23/29 [00:15<00:03,  1.62it/s]\u001b[A2023-06-11 12:43:24 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\n",
            "2023-06-11 12:43:24 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##ه چهار ##دهم یا ه ##ف ##دهم چه ##طور. آیا هیچ ##ک ##دام از آن دو روز, با برنامه ##ریزی شما مناسب است? [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  83% 24/29 [00:16<00:03,  1.60it/s]\u001b[A2023-06-11 12:43:24 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] روز چهار ##شن ##به, همه برای من آزاد است, بنابراین, \"احمد اگر برای شما کار ک ##ن ##م,\" [SEP]\n",
            "2023-06-11 12:43:24 | INFO | fairseq.tasks.translation | example reference: [CLS] من چهار ##شن ##به کامل ##ا آزاد ه ##ست ##م, اگر برای شما مناسب است, عالی است, [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  86% 25/29 [00:17<00:02,  1.55it/s]\u001b[A2023-06-11 12:43:25 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] بل ##ه, مانند \"آ ##هن, من ن ##می ##دان ##م که در بعد از ظهر, در روز پنج ش ##ن ##به, ه ##شت ##م با من خوب است. [SEP]\n",
            "2023-06-11 12:43:25 | INFO | fairseq.tasks.translation | example reference: [CLS] بل ##ه, مثل, ن ##می ##دان ##م, هر زمان ##ن از بعد از ظهر پنج ##شن ##به ه ##شت ##م برای من مناسب است. [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  90% 26/29 [00:17<00:01,  1.56it/s]\u001b[A2023-06-11 12:43:25 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] من یک س ##مین ##ار س ##مین ##اره ##ای دار ##م, بیست و هفت ##م, بیست و هفت ##م, که یک روز ه ##ست ##م که یک روز ه ##ست ##م, نه کامل ##ا آزاد بود ##م. [SEP]\n",
            "2023-06-11 12:43:25 | INFO | fairseq.tasks.translation | example reference: [CLS] من در تمام روز بیست - و هفت ##م یک س ##مین ##ار دار ##م. آن روز ##ی است که در آن هفت ##ه, من به - طور کامل آزاد نیست ##م. [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  93% 27/29 [00:18<00:01,  1.58it/s]\u001b[A2023-06-11 12:43:26 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"ا ##ف ##زون بر آن, ما میتوان ##یم ش ##اید ب ##تو ##انی ##م ش ##اید ب ##تو ##انی ##م ش ##اید ب ##تو ##انی ##م ش ##اید ب ##تو ##انی ##م ب ##تو ##انی ##م ش ##اید ب ##تو ##انی ##م در ح ##وم ##ه ی ح ##ما ##س و\n",
            "2023-06-11 12:43:26 | INFO | fairseq.tasks.translation | example reference: [CLS] عالی است. ش ##اید ب ##تو ##انی ##م هم ##دی ##گر را ##در ها ##لی ##هان ##ز, باغ و ##رزش یا میدان است ##یش ##ن ب ##بین ##یم و در مورد کار ص ##حبت ک ##نی ##م. [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  97% 28/29 [00:19<00:00,  1.60it/s]\u001b[A2023-06-11 12:43:27 | INFO | fairseq.tasks.translation | example hypothesis: [CLS] \"\" من ن ##می ##تو ##ان ##م به نظر ن ##می ##رس ##د که ب ##تو ##ان ##م به آن ف ##کر ک ##ن ##م که ب ##تو ##ان ##م ب ##تو ##ان ##م در این هفت ##ه با شما ب ##خ ##وا ##هم با شما ب ##تو ##ان ##م با دو ساعت دیگر با شما ب ##خ ##وا ##هی ##د. \"[SEP]\n",
            "2023-06-11 12:43:27 | INFO | fairseq.tasks.translation | example reference: [CLS] آ ##ه به - نظر ن ##می ##رس ##د که من ب ##تو ##ان ##م کد ال ##کت ##ریکی را برای اجرا مه ##یا ک ##ن ##م, من نیاز دار ##م که آ ##ه با تو زمانی دوباره برای حدود بیش از دو ساعت, در این هفت ##ه مل ##اقات ک ##ن ##م. کی برای تو خوب است. [SEP]\n",
            "\n",
            "epoch 005 | valid on 'valid' subset: 100% 29/29 [00:19<00:00,  1.79it/s]\u001b[A\n",
            "                                                                        \u001b[A2023-06-11 12:43:27 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 6.644 | nll_loss 3.702 | ppl 13.01 | bleu 36.71 | wps 3823.8 | wpb 2556.5 | bsz 137.9 | num_updates 33235 | best_bleu 37.2\n",
            "2023-06-11 12:43:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 33235 updates\n",
            "2023-06-11 12:43:27 | INFO | fairseq.trainer | Saving checkpoint to /content/content/drive/MyDrive/mbert_frozen/checkpoints/checkpoint5.pt\n",
            "2023-06-11 12:43:33 | INFO | fairseq.trainer | Finished saving checkpoint to /content/content/drive/MyDrive/mbert_frozen/checkpoints/checkpoint5.pt\n",
            "2023-06-11 12:43:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./content/drive/MyDrive/mbert_frozen/checkpoints/checkpoint5.pt (epoch 5 @ 33235 updates, score 36.71) (writing took 10.854688404000626 seconds)\n",
            "2023-06-11 12:43:37 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)\n",
            "2023-06-11 12:43:37 | INFO | train | epoch 005 | loss 7.303 | nll_loss 4.451 | ppl 21.87 | wps 26524.2 | ups 6.97 | wpb 3802.9 | bsz 100.8 | num_updates 33235 | lr 0.000867306 | gnorm 0.414 | loss_scale 16 | train_wall 897 | gb_free 12.9 | wall 4778\n",
            "2023-06-11 12:43:37 | INFO | fairseq_cli.train | done training in 4777.6 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!fairseq-generate \\\n",
        "    /content/drive/MyDrive/NLP/CA5/mbert_data_dir \\\n",
        "    --batch-size 128 \\\n",
        "    --path \"./content/drive/MyDrive/mbert_frozen/checkpoints/checkpoint_best.pt\" \\\n",
        "    --beam 5 > \"./content/drive/MyDrive/mbert_frozen/new_eval.txt\""
      ],
      "metadata": {
        "id": "mh8j21-KRog0",
        "outputId": "8ae5da51-2d5f-4a0e-a51d-e0eb60939ada",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-11 12:46:04.724955: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-06-11 12:46:07 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2023-06-11 12:46:11 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': './content/drive/MyDrive/mbert_frozen/checkpoints/checkpoint_best.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 128, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 128, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}, 'task': {'_name': 'translation', 'data': '/content/drive/MyDrive/NLP/CA5/mbert_data_dir', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
            "2023-06-11 12:46:11 | INFO | fairseq.tasks.translation | [en] dictionary: 33216 types\n",
            "2023-06-11 12:46:11 | INFO | fairseq.tasks.translation | [fa] dictionary: 33216 types\n",
            "2023-06-11 12:46:11 | INFO | fairseq_cli.generate | loading model(s) from ./content/drive/MyDrive/mbert_frozen/checkpoints/checkpoint_best.pt\n",
            "2023-06-11 12:46:27 | INFO | fairseq.utils | found 33212/33216 types in embedding file\n",
            "2023-06-11 12:46:28 | INFO | fairseq.data.data_utils | loaded 10,000 examples from: /content/drive/MyDrive/NLP/CA5/mbert_data_dir/test.en-fa.en\n",
            "2023-06-11 12:46:28 | INFO | fairseq.data.data_utils | loaded 10,000 examples from: /content/drive/MyDrive/NLP/CA5/mbert_data_dir/test.en-fa.fa\n",
            "2023-06-11 12:46:28 | INFO | fairseq.tasks.translation | /content/drive/MyDrive/NLP/CA5/mbert_data_dir test en-fa 10000 examples\n",
            "2023-06-11 12:47:58 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2023-06-11 12:47:58 | INFO | fairseq_cli.generate | Translated 10,000 sentences (170,926 tokens) in 49.6s (201.65 sentences/s, 3446.76 tokens/s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/content/drive/MyDrive/mbert_frozen /content/drive/MyDrive/mbert_new\n"
      ],
      "metadata": {
        "id": "_mVLsKGVReEX"
      },
      "execution_count": 29,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "defa8a7621ea4993967121114c146499": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8eb7bd730bb74276859a4f204dae5d17",
              "IPY_MODEL_808de31f902945a1a38c4b16e3d23ffa",
              "IPY_MODEL_ac32f43e197a4b9fa3ac6e30fa1dfbf1"
            ],
            "layout": "IPY_MODEL_5e6b9def822d4db68b2b2fe920cfaea3"
          }
        },
        "8eb7bd730bb74276859a4f204dae5d17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6a04155a1754a00a54594e5b097c568",
            "placeholder": "​",
            "style": "IPY_MODEL_dd6e2e4d5f1a44cd832020c789013689",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "808de31f902945a1a38c4b16e3d23ffa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d8f9ade5daf4a00a299e76d2124135a",
            "max": 995526,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e754850b7c694a63908f4491433e56d4",
            "value": 995526
          }
        },
        "ac32f43e197a4b9fa3ac6e30fa1dfbf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7325c30853364a96aa55753cf906d97f",
            "placeholder": "​",
            "style": "IPY_MODEL_6c08a212c54c4e9ba4fa8d54ee357be6",
            "value": " 996k/996k [00:00&lt;00:00, 9.92MB/s]"
          }
        },
        "5e6b9def822d4db68b2b2fe920cfaea3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6a04155a1754a00a54594e5b097c568": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd6e2e4d5f1a44cd832020c789013689": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d8f9ade5daf4a00a299e76d2124135a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e754850b7c694a63908f4491433e56d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7325c30853364a96aa55753cf906d97f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c08a212c54c4e9ba4fa8d54ee357be6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b76965f144aa4191b4e2be4d42b9edb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_87645528668642d0a0ba1996877a9021",
              "IPY_MODEL_6caf71546b404003821ab34cfe3c7269",
              "IPY_MODEL_45705017ebfa4983b4ec1db763b5c0f5"
            ],
            "layout": "IPY_MODEL_542f393ec78341b28d165a82a500a52c"
          }
        },
        "87645528668642d0a0ba1996877a9021": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_452a862ab95940b8842727c2d5dc6057",
            "placeholder": "​",
            "style": "IPY_MODEL_4b26dcf3c290411288eff1c46d9e2b9e",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "6caf71546b404003821ab34cfe3c7269": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_313d098bf2bc40c2bd9c10d3924348fa",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_423464abe96f4496b66a5b9df9c5c490",
            "value": 29
          }
        },
        "45705017ebfa4983b4ec1db763b5c0f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dba9c07d97214e8c93cc744a2dd4bb7d",
            "placeholder": "​",
            "style": "IPY_MODEL_f67c3b2585e04ef2882296ea24b87201",
            "value": " 29.0/29.0 [00:00&lt;00:00, 520B/s]"
          }
        },
        "542f393ec78341b28d165a82a500a52c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "452a862ab95940b8842727c2d5dc6057": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b26dcf3c290411288eff1c46d9e2b9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "313d098bf2bc40c2bd9c10d3924348fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "423464abe96f4496b66a5b9df9c5c490": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dba9c07d97214e8c93cc744a2dd4bb7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f67c3b2585e04ef2882296ea24b87201": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a12f23d11624a09900e04ba76bb9075": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a8e5d2f305fc44cfa8fc8eb79b95125f",
              "IPY_MODEL_15e8f0191ceb43f1a94724333ca3e704",
              "IPY_MODEL_0181b9f8c6df476d9552d95549369995"
            ],
            "layout": "IPY_MODEL_b4cd50f844754bcdbc5ea08d336daf69"
          }
        },
        "a8e5d2f305fc44cfa8fc8eb79b95125f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1587849b4ae41fab74ee9968e6104e1",
            "placeholder": "​",
            "style": "IPY_MODEL_4d983cf96dcb4e599b01814a472fde4a",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "15e8f0191ceb43f1a94724333ca3e704": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5f2bc91d94a4dc2a7776c807ca1acb8",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_53e5d0dca7d140c8bd5acb48b387b78c",
            "value": 625
          }
        },
        "0181b9f8c6df476d9552d95549369995": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_350df379276b41698d80701c2064da4d",
            "placeholder": "​",
            "style": "IPY_MODEL_1be4633bb2334ae198e9f016df86c5c5",
            "value": " 625/625 [00:00&lt;00:00, 7.15kB/s]"
          }
        },
        "b4cd50f844754bcdbc5ea08d336daf69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1587849b4ae41fab74ee9968e6104e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d983cf96dcb4e599b01814a472fde4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5f2bc91d94a4dc2a7776c807ca1acb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53e5d0dca7d140c8bd5acb48b387b78c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "350df379276b41698d80701c2064da4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1be4633bb2334ae198e9f016df86c5c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9765a34ded2f4f2fa626d9e73182fc35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d122dfded5b14f4ab01c433151b10b1f",
              "IPY_MODEL_e9af5a4c6bc3464aa7a0a3ec1f70ee08",
              "IPY_MODEL_b7c1be6541324315bdcce2de748c2e4a"
            ],
            "layout": "IPY_MODEL_c024f6ba398749c7bf347f468a679f0a"
          }
        },
        "d122dfded5b14f4ab01c433151b10b1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd5a2b907cc14b9dbb7ad515d6c1c572",
            "placeholder": "​",
            "style": "IPY_MODEL_1352ba20dce54a39b83ad7fab437aa41",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "e9af5a4c6bc3464aa7a0a3ec1f70ee08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68c5b5b0c9d24310bd8adfa4073f5151",
            "max": 714290682,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d0fbc9e9d0704f1bbc3b2b0da14758da",
            "value": 714290682
          }
        },
        "b7c1be6541324315bdcce2de748c2e4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8a614e2f6eb4b2a979670929cb5fb20",
            "placeholder": "​",
            "style": "IPY_MODEL_a0b10cdf93e04b548c8673be804846ef",
            "value": " 714M/714M [00:09&lt;00:00, 72.0MB/s]"
          }
        },
        "c024f6ba398749c7bf347f468a679f0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd5a2b907cc14b9dbb7ad515d6c1c572": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1352ba20dce54a39b83ad7fab437aa41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68c5b5b0c9d24310bd8adfa4073f5151": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0fbc9e9d0704f1bbc3b2b0da14758da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e8a614e2f6eb4b2a979670929cb5fb20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0b10cdf93e04b548c8673be804846ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}